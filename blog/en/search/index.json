[{"content":"In recent years, Many novel programming languages have emergerd, and new concepts continued to appear. I always wanted to learn about various new programming languages, and it would be nice to master one more language if it is prospective. Therefore, this article summarizes my understanding of some popular modern languages and their various characteristics. If you are also interested in trying a new language, then I hope this article can help you~\nFor the popularity of languages, we can refer to TIOBE rankings, Github rankings and StackOverflow rankings. I won\u0026rsquo;t go into details in this post about the language features, since they\u0026rsquo;re still evolving over time. And for the same reason, the comments on each language only reflects my impression on each language listed here.\nThis post focuses on general programming languange. For Domain-Specific Languages (DSL) like SQL, I won\u0026rsquo;t include them cuz you have to learn them only when needed.\nIn terms of the history of the programming languages, there\u0026rsquo;s a very interesting picture below (source here), if you\u0026rsquo;re interested in the details, you can refer to the wikipedia pages about the history and the timeline (highly recommend the second one!), or refer to this website.\nFeatures of a modern languange Before the summary, first I should introduce some programming concepts for a better understanding of the languages. The comparison in depth of the concepts can be also found in wikipedia. Here the introduction is also very brief, you can search these keywords for further information.\nObject-Oriented: This should familiar to you if you have attended any class about programming. Object-oriented programming usually means that the core logic of the code is built around \u0026ldquo;classes\u0026rdquo;. A class contains a definition of an object and some associated methods, an derived class can be used to simplify the code. Dynamic / Static Types: Static typing requires the program to specify the type of each variable while for dynamic typing that\u0026rsquo;s not a requirement. These two options are trade-off between the flexibilty and the safety of the program. A similar naming of this choice is strong / weak typing. In weak typing languages, there\u0026rsquo;s a concept called \u0026ldquo;Duck-typing\u0026rdquo;, which means we only care about what interface the object/type provides, rather than ensure that the object has a specific type. Meta-Programming / Generic Type: Meta-programming means that we can generate code with some \u0026ldquo;meta\u0026rdquo; code, a representative case is the template in C++. Meanwhile, generic types are similar to meta-programming, but it won\u0026rsquo;t generate code explicitly, it\u0026rsquo;s just some code supporting types as parameters. Imperative / Declarative / Functional: In imperative Languages, you instruct the program, step by step, to do something; In declarative Languages, you only tell the program what you want to do; In functional Languages, the function is the first-class citizen and the program will achieve the goal by call functions sequentially. The functions usually can be stored in variables as well. Parallelism: Parallelism means that the program supports running multiple code blocks in parallel (including processes, threads and coroutines) Data Science: Some programming Languages are designed for data scientists, which mainly features the built-in support for high-precision and high-dimensional data. Test-driven Development (TDD) / Design by Contract (Doc): These are two different paradigm for building the program. Test-driving means that the target of coding is to passing some tests, while design by contract means the program has to meet some constraints during coding. Support for tests and contracts are not critical for programming languages, but in modern complex programs, they can drastically improve the efficiency and safety of the development. Virtual Machine / Intermediate Language: A few languages support cross-platform compatibility through languange virtual machine, which will convert the intermediate codes to machine codes. The representatives are JVM, CLR and LLVM. Garbage Collection (GC): Garbage collection is a feature built in some languages\u0026rsquo; runtime. With this feature, you don\u0026rsquo;t need to worry about the lifetime of variables, since the garbage collector handles the deconstruction for you. Now I will lists the 1-line comments of the mainstream programming languages selected from the rankings mentioned above.\nWhy to choose this languange in (about) 1 sentence C: All time god which is closest to assembly languange with little dependency and high performance. The ABI written with C can be called from most other languages CoffeeScript: Javascript with syntax sugar C++: One of the most powerful Languages with full support of object-oriented programming and meta-programming, and full compatibility with C C#: Full of syntax sugar and faster than Java. The recent advancements in open-source provide more resources. D: Aiming at replacing C++ with many modern features including design by contract Dart: Backed by Google and aiming at replacing Javascript, but that\u0026rsquo;s it F#: Functional version of C# Fortran: Old but blazing fast language, even faster than C Go: Fast compilation with great coroutine support and produces single file executable without dependencies Groovy: Dynamic typing version of Java built by Apache, similar goal to Ruby Haskell: Representative of functional language Java: Widely used in server applications with tons of available packages, equipped with garbage collector Javascript: Popular in both front-end and backend development, being very flexible and supported by most browsers. Also comes with tons of availabe packages. Julia: Science-computing oriented languange with builtin support to n-dimensional tensor and fast speed. Has the potential to be the next Fortran Kotlin: Java with modern syntax sugar developed by JetBrains, compile to Java or JS Matlab: Designed for engineers and scientists with many engineering packages. The Simulink package has no alternatives by now. Objective-C: Any pros? Perl: Suitable to be used as scripting or glue language, with great string processing utilites. PHP: Server-oriented languange that can be embedded into HTML, flexible and simple Python: Very flexible with everything being an object. Great readability and interoperability with C/C++. Tons of available packages R: Designed for statistics with rich domain-specific packages Ruby: Chained calling, sugar syntax and as flexible as Python Rust: Memory safety ensured in language level. No garbage collector means that it\u0026rsquo;s fast! Scala: Scala is like C++ on JVM, while Kotlin is like C# on JVM Swift: Replacement for Obj-C developed by Apple. Similar to Java Typescript: Strong typing version of Javascript Vala: Aiming at replacing C/C++ in GUI programming in Linux (Elementary OS). Compile to C = fast speed. Visual Basic: Builtin support by many Microsoft software Why to avoid this languange in (about) 1 sentense C: No modern language features, unsafe and hard for object-oriented programming CoffeeScript: No compelling feature, Typescript might be a better choice C++: Templates are very hard for debugging, slow compilation. Many modern features are implemented based on templates and std libraries, which are not elegant C#: Confusing runtime standards, frequently changing API and sometimes break backward compatibility D: No sponsor = poor eco-system Dart: Again, typescript might be a better choice F#: I don\u0026rsquo;t know who is using it, C# is good enough Fortran: Old syntax and no modern language features Go: No generics, don\u0026rsquo;t allow unused variables and modules Groovy: There\u0026rsquo;re better alternatives outside of JVM Languages Haskell: Learning it is like learning to be a mathematician Java: Verbose, not as elegant and fast as C# Javascript: Single-threaded, too flexible (see the meme below) {% asset_img js-triangle.jpg Javascript等号三位一体%} Julia: The package manangement is very hard to use. The syntax is also hard to understand Kotlin: Slow to compile. No big problems other than that, but there\u0026rsquo;re better alternatives outside JVM Matlab: Proprietary languange owned by Mathworks and you have to install a big Matlab software to run the code. Python and Julia are good enough to replace Matlab (if you are not a Simulink user) Objective-C: Only used by Apple, hard to read Perl: Hard to read, too flexible and slow. Python is better PHP: Single threaded, only suitable for Web development. Javascript is better in terms of general abilities and community size Python: Bad performance, single threaded (caused by GIL) R: Even worse than Matlab Rust: The compiler is too strict sometimes, and it\u0026rsquo;s hard to manipulate strings in Rust Ruby: Bad performance, usually used only by backend engineers Scala: Harder to learn than Kotlin, and worse interoperability with Java Swift: Only a good choice for iOS and OSX development. Typescript: Only a good choice for Web development Vala: Only used by Gnome and ElementaryOS, very small community Visual Basic: Don\u0026rsquo;t use it if you can! ","date":"2021-08-05T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2021-08/OneLinePerProgrammingLanguage/","title":"Select Modern Programming Languages by One-line comments"},{"content":" In this note, $\\{x_i\\}^b_a$ denotes set $\\{x_a, x_{a+1}, \\ldots, x_b\\}$ TODO: add Jordan Form Algebraic Structures Operation Definition: an (binary, closed) operation $\\ast$ on a set $S$ is a mapping of $S\\times S\\to S$ Commutative: $x\\ast y=y\\ast x,\\;\\forall x,y\\in S$ Associative: $(x\\ast y)\\ast z=x\\ast (y\\ast z),\\;\\forall x,y,z\\in S$ Group Definition: a group is a pair $(\\mathcal{S},\\ast)$ with following axioms $\\ast$ is associative on $\\mathcal{S}$ (Identity element) $\\exists e\\in \\mathcal{S}\\text{ s.t. }x\\ast e=e\\ast x=x,\\;\\forall x\\in \\mathcal{S}$ (Inverse element) $\\forall x\\in \\mathcal{S}, \\exists x\u0026rsquo; \\in \\mathcal{S}\\text{ s.t. }x\\ast x\u0026rsquo;=x\u0026rsquo;\\ast x=e$ Abelian: a group is called abelian group if $\\ast$ is also commutative Ring Definition: a ring is a triplet $(\\mathcal{R},+,\\ast)$ consisting of a set of scalars $\\mathcal{R}$ and two operators + and $\\ast$ with following axioms $(\\mathcal{R},+)$ is an abelian group with identity denoted $0$ $\\forall a,b,c \\in \\mathcal{R}\\text{ s.t. }a\\ast(b\\ast c) = (a\\ast b)\\ast c$ $\\exists 1\\in\\mathcal{R}, \\forall a\\in\\mathcal{R}\\text{ s.t. }a\\cdot 1=a$ $\\ast$ is distributive over $+$ Field Definition: a field $(\\mathcal{F},+,\\ast)$ is a ring where $(\\mathcal{F}\\backslash\\{0\\},\\ast)$ is also an abelian group. Difference from ring to field is that $\\ast$ need to be commutative and have a multiplicative inverse\nVector Space Definition: a vector space (aka. linear space) is a triplet $(\\mathcal{U},\\oplus,\\cdot)$ defined over a field $(\\mathcal{F},+,\\ast)$ with following axioms, where set $\\mathcal{U}$ is called vectors, operator $\\oplus$ is called vector addition and mapping $\\cdot$ is called scalar multiplication: (Null vector) $(\\mathcal{U},+)$ is an abelian group with identity element $\\emptyset$ Scalar multiplication is a mapping of $\\mathcal{F}\\times\\mathcal{U}\\to\\mathcal{U}$ $\\alpha\\cdot(x\\oplus y) = \\alpha\\cdot x \\oplus \\alpha\\cdot y,\\;\\forall x,y\\in\\mathcal{U};\\alpha\\in\\mathcal{F}$ $(\\alpha+\\beta)\\cdot x = \\alpha\\cdot x\\oplus\\beta\\cdot x,\\;\\forall x\\in\\mathcal{U};\\alpha,\\beta\\in\\mathcal{F}$ $(\\alpha\\ast\\beta)\\cdot x=\\alpha\\cdot(\\beta\\cdot x),\\;\\forall x\\in\\mathcal{U};\\alpha,\\beta\\in\\mathcal{F}$ $1_\\mathcal{F}\\cdot x=x$ Usually we don\u0026rsquo;t distinguish vector addition $\\oplus$ and addition of scalar $+$. Juxtaposition is also commonly used for both scalar multiplication $\\cdot$ and multiplication of scalars $\\ast$\nSubspace: a subspace $\\mathcal{V}$ of a linear space $\\mathcal{U}$ over field $\\mathcal{F}$ is a subset of $\\mathcal{U}$ which is itself a linear space over $\\mathcal{F}$ under same vector addition and scalar multiplication. Basis \u0026amp; Coordinate Linear Independence: Let $\\mathcal{V}$ be a vector space over $\\mathcal{F}$ and let $X=\\{x_i\\}^n_1\\subset \\mathcal{V}$ X is linearly dependent if $\\exists \\alpha_1,\\ldots,\\alpha_n\\in\\mathcal{F}$ not all 0 s.t. $\\sum^n_{i=1} \\alpha_i x_i=0$. X is linearly independent if $\\sum^n_{i=1} \\alpha_i x_i=0 \\Rightarrow \\alpha_1=\\alpha_2=\\ldots=\\alpha_n=0$ Span: Given a set of vectors $V$, the set of linear combinations of vectors in $V$ is called the span of it, denoted $\\mathrm{span}\\{V\\}$ Basis: A set of linearly independent vectors in a linear space $\\mathcal{V}$ is a basis if every vector in $\\mathcal{V}$ can be expressed as a unique linear combination of these vectors. (see below \u0026ldquo;Coordinate\u0026rdquo;) Basis Expansion: Let $(X,\\mathcal{F})$ be a vector space of dimension n. If $\\{v_i\\}^k_1,\\;1\\leqslant k\u0026lt; n$ is linearly independent, then $\\exists \\{v_i\\}^n_{k+1}$ such that $\\{v_i\\}_1^n$ is a basis. Reciprocal Basis: Given basis $\\{v_i\\}^n_1$, a set ${r_i}^1_n$ that satifies $\\langle r_i,v_j \\rangle=\\delta_i(j)$ is a reciprocal basis. It can be generated by Gram-Schmidt Process and $\\forall x\\in\\mathcal{X}, x=\\sum^n_{i=1}\\langle r_i,x\\rangle v_i$. Dimension: Cardinality of the basis is called the dimension of that vector space, which is equal to the maximum number of linearly independent vectors in the space. Denoted as $dim(\\mathcal{V})$. In an $n$-dimensional vector space, any set of $n$ linearly independent vectors is a basis. Coordinate: For a vector $x$ in vector space $\\mathcal{V}$, given a basis $\\{e_1, \\ldots, e_n\\}$ we can write $x$ as $x=\\sum^n_{i=1}\\beta_i e_i=E\\beta$ where $E=\\begin{bmatrix}e_1\u0026amp;e_2\u0026amp;\\ldots\u0026amp;e_n\\end{bmatrix}$ and $\\beta=\\begin{bmatrix}\\beta_1\u0026amp;\\beta_2\u0026amp;\\ldots\u0026amp;\\beta_n\\end{bmatrix}^\\top$. Here $\\beta$ is called the representation (or coordinate) of $x$ given the basis $E$. Norm \u0026amp; Inner product Inner Product: an operator on two vectors that produces a scalar result (i.e. $\\langle\\cdot,\\cdot\\rangle:\\mathcal{V}\\to\\mathbb{R}\\;or\\;\\mathbb{C}$) with following axioms: (Symmetry) $\\langle x,y \\rangle=\\overline{\\langle y,x\\rangle},\\;\\forall x,y\\in\\mathcal{V}$ (Bilinearity) $\\langle \\alpha x+\\beta y,z\\rangle=\\alpha\\langle x,z\\rangle+\\beta\\langle y,z\\rangle,\\;\\forall x,y,z\\in\\mathcal{V};\\alpha,\\beta\\in\\mathbb{C}$ (Pos. definiteness) $\\langle x,x\\rangle\\geqslant 0,\\;\\forall x\\in\\mathcal{V}$ and $\\langle x,x\\rangle=0\\Rightarrow x=0_\\mathcal{V}$ Inner Product Space: A linear space with a defined inner product Orthogonality: Perpedicularity of vectors ($x\\perp y$): $\\langle x,y\\rangle=0$ Perpedicularity of a vector to a set ($y\\perp\\mathcal{S},\\mathcal{S}\\subset\\mathcal{V}$): $y\\perp x,\\;\\forall x\\in\\mathcal{S}$ Orthogonal Set: set $\\mathcal{S}\\subset(\\mathcal{U},\\langle\\cdot,\\cdot\\rangle)$ is orthogonal $\\Leftrightarrow x\\perp y,\\;\\forall x,y\\in\\mathcal{S},x\\neq y$ Orthonormal Set: set $\\mathcal{S}$ is orthonormal iff $\\mathcal{S}$ is orthogonal and $\\Vert x\\Vert=1,\\;\\forall x\\in\\mathcal{S}$ Orthogonality of sets ($\\mathcal{X}\\perp\\mathcal{Y}$): $\\langle x,y\\rangle=0,\\;\\forall x\\in\\mathcal{X};y\\in\\mathcal{Y}$ Orthogonal Complement: Let $(\\mathcal{V},\\langle\\cdot,\\cdot\\rangle)$ be an inner product space and let $\\mathcal{U}\\subset\\mathcal{V}$ be a subspace of $\\mathcal{V}$, the orthogonal complement of $\\mathcal{U}$ is $\\mathcal{U}^\\perp=\\left\\{v\\in\\mathcal{V}\\middle|\\langle v,u\\rangle=0,\\;\\forall u\\in\\mathcal{U}\\right\\}$. $\\mathcal{U}^\\perp\\subset\\mathcal{V}$ is a subspace $\\mathcal{V}=\\mathcal{U}\\overset{\\perp}{\\oplus}\\mathcal{U}^\\perp$ ($\\oplus$: direct sum, $\\overset{\\perp}{\\oplus}$: orthogonal sum) Norm: A norm on a linear space $\\mathcal{V}$ is mapping $\\Vert\\cdot\\Vert:\\;\\mathcal{V}\\to\\mathbb{R}$ such that: (Positive definiteness) $\\Vert x\\Vert\\geqslant 0\\;\\forall x\\in \\mathcal{V}$ and $\\Vert x\\Vert =0\\Rightarrow x=0_\\mathcal{V}$ (Homogeneous) $\\Vert \\alpha x\\Vert=|\\alpha|\\cdot\\Vert x\\Vert,\\;\\forall x\\in\\mathcal{V},\\alpha\\in\\mathbb{R}$ (Triangle inequality) $\\Vert x+y\\Vert\\leqslant\\Vert x\\Vert+\\Vert y\\Vert$ Distance: Norm can be used to measure distance between two vectors. Meanwhile, distance from a vector to a (sub)space is defined as $d(x,\\mathcal{S})=\\inf_{y\\in\\mathcal{S}} d(x,y)=\\inf_{y\\in\\mathcal{S}} \\Vert x-y\\Vert$ Projection Point: $x^* =\\arg\\min_{y\\in\\mathcal{S}}\\Vert x-y\\Vert$ is the projection point of $x$ on linear space $\\mathcal{S}$. Projection Theorem: $\\exists !x^* \\in\\mathcal{S}$ s.t. $\\Vert x-x^* \\Vert=d(x,\\mathcal{S})$ and we have $(x-x^*) \\perp\\mathcal{S}$ Orthogonal Projection: $P(x)=x^*:\\mathcal{X}\\to\\mathcal{M}$ is called the orthogonal projection of $\\mathcal{X}$ onto $\\mathcal{M}$ Normed Space: A linear space with a defined norm $\\Vert\\cdot\\Vert$, denoted $(\\mathcal{V},\\mathcal{F},\\Vert\\cdot\\Vert)$ A inner product space is always a normed space because we can define $\\Vert x\\Vert=\\sqrt{\\langle x,x\\rangle}$\nCommon $\\mathbb{R}^n$ Norms: Euclidean norm (2-norm): $\\Vert x\\Vert_2=\\left(\\sum^n_{i=1}|x_i|^2\\right)^{1/2}=\\left\\langle x,x\\right\\rangle^{1/2}=\\left(x^\\top x\\right)^{1/2}$ $l_p$ norm (p-norm): $\\Vert x\\Vert_p=\\left(\\sum^n_{i=1}|x_i|^p\\right)^{1/p}$ $l_1$ norm: $\\Vert x\\Vert_1=\\sum^n_{i=1}|x_i|$ $l_\\infty$ norm: $\\Vert x\\Vert_\\infty=\\max_{i}\\{x_i\\}$ Common matrix norms: Matrix norms are also called operator norms, can measure how much a linear operator \u0026ldquo;magnifies\u0026rdquo; what it operates on.\nA general form induced from $\\mathbb{R}^n$ norm: $$\\Vert A\\Vert=\\sup_{x\\neq 0}\\frac{\\Vert Ax\\Vert}{\\Vert x\\Vert}=\\sup_{\\Vert x\\Vert=1}\\Vert Ax\\Vert$$ $\\Vert A\\Vert_1=\\max_j\\left(\\sum^n_{i=1}|a_{ij}|\\right)$ $\\Vert A\\Vert_2=\\left[ \\max_{\\Vert x\\Vert=1}\\left\\{(Ax)^* (Ax)\\right\\}\\right]^{1/2}=\\left[ \\lambda_{max}(A^ *A)\\right]^{1/2}$ ($\\lambda_{max}$: largest eigenvalue) $\\Vert A\\Vert_\\infty=\\max_i\\left(\\sum^n_{j=1}|a_{ij}|\\right)$ (Frobenius Norm) $\\Vert A\\Vert_F=\\left[ \\sum^m_{i=1}\\sum^n_{j=1}\\left|a_{ij}\\right|^2\\right]^{1/2}=\\left[ tr(A^*A)\\right]^{1/2}$ Useful inequations: Cauchy-Schwarz: $|\\langle x,y\\rangle|\\leqslant\\left\\langle x,x\\right\\rangle^{1/2}\\cdot\\left\\langle y,y\\right\\rangle^{1/2}$ Triangle (aka. $\\Delta$): $\\Vert x+y\\Vert\\leqslant\\Vert x\\Vert+\\Vert y\\Vert$ Lemma: $\\Vert x-y\\Vert \\geqslant \\left| \\Vert x\\Vert-\\Vert y\\Vert \\right|$\nPythagorean: $x\\perp y \\Leftrightarrow \\Vert x+y\\Vert=\\Vert x\\Vert+\\Vert y\\Vert$ Gramian Gram-Schmidt Process: A method to find orthogonal basis $\\{v_i\\}^n_1$ given an ordinary basis $\\{y_i\\}^n_1$. It\u0026rsquo;s done by perform $v_k=y_k-\\sum^{k-1}_{j=1}\\frac{\\langle y_k,v_j\\rangle}{\\langle v_j,v_j \\rangle}\\cdot v_j$ iteratively from 1 to $n$. To get an orthonormal basis, just normalize these vectors. Gram Matrix: The Gram matrix generated from vectors $\\{y_i\\}_ 1^k$ is denoted $G(y_ 1,y_ 2,\\ldots,y_ k)$. Its element $G_{ij}=\\langle y_i,y_j\\rangle$ Gram Determinant: $g(y_1,y_2,\\ldots,y_n)=\\det G$ Normal Equations: Given subspace $\\mathcal{M}$ and its basis $\\{y_i\\}^n_1$, the projection point of $\\forall x\\in\\mathcal{M}$ can be represented by $$x^*=\\alpha y=\\begin{bmatrix}\\alpha_1\u0026amp;\\alpha_2\u0026amp;\\ldots\u0026amp;\\alpha_n\\end{bmatrix}\\begin{bmatrix}y_1\\\\y_2\\\\ \\vdots \\\\y_n\\end{bmatrix},\\;\\beta=\\begin{bmatrix}\\langle x,y_1\\rangle\\\\ \\langle x,y_2\\rangle\\\\ \\vdots\\\\ \\langle x,y_n\\rangle\\end{bmatrix} where\\;G^\\top\\alpha=\\beta$$ For least-squares problem $Ax=b$, consider $\\mathcal{M}$ to be the column space of $A$, then $G=A^\\top A,\\;\\beta=A^\\top b,\\;G^\\top\\alpha=\\beta\\Rightarrow\\alpha=(A^\\top A)^{-1}A^\\top b$. Similarly for weighted least-squares problem ($\\Vert x\\Vert=x^\\top Mx$), let $G=A^\\top MA, \\beta=A^\\top Mb$, we can get $\\alpha=(A^\\top MA)^{-1}A^\\top Mb$\nLinear Algebra Linear Operator Definition: a linear operator $\\mathcal{A}$ (aka. linear transformation, linear mapping) is a function $f: V\\to U$ that operate on a linear space $(\\mathcal{V},\\mathcal{F})$ to produce elements in another linear space $(\\mathcal{U},\\mathcal{F})$ and obey $$\\mathcal{A}(\\alpha_1 x_1+\\alpha_2 x_2) = \\alpha_1\\mathcal{A}(x_1) + \\alpha_2\\mathcal{A}(x_2),\\;\\forall x_1,x_2\\in V;\\alpha_1, \\alpha_2\\in\\mathcal{F}$$\nRange (Space): $\\mathcal{R}(\\mathcal{A})=\\left\\{u\\in U\\middle|\\mathcal{A}(v)=u,\\;\\forall v\\in V\\right\\}$\nNull Space (aka. kernel): $\\mathcal{N}(\\mathcal{A})=\\left\\{v\\in V\\middle|\\mathcal{A}(v)=\\emptyset_U\\right\\}$\n$\\mathcal{A}$-invariant subspace: Given vector space $(\\mathcal{V},\\mathcal{F})$ and linear operator $\\mathcal{A}:\\mathcal{V}\\rightarrow \\mathcal{V}$, $\\mathcal{W}\\subseteq\\mathcal{V}$ is $A$-invariant if $\\forall x\\in\\mathcal{W}$, $\\mathcal{A}x\\in\\mathcal{W}$.\nBoth $\\mathcal{R}(\\mathcal{A})$ and $\\mathcal{N}(\\mathcal{A})$ are $\\mathcal{A}$-invariant Matrix Representation: Given bases for both $V$ and $U$ (respectively $\\{v_i\\}^n_1$ and $\\{u_j\\}^m_1$), matrix representation $A$ satisfies $\\mathcal{A}(v_i)=\\sum^m_{j=0}A_{ji}u_j$ so that $\\beta=A\\alpha$ where $\\alpha$ and $\\beta$ is the representation of a vector under $\\{v_i\\}$ and $\\{u_j\\}$ respectively. {% asset_img linear_map_relations.png Relation between a linear map and its matrix representations %}\n$P$ and $Q$ are change of basis matrices, $A=Q^{-1}\\tilde{A}P,\\;\\tilde{A}=QAP^{-1}$ The i-th column of $A$ is the coordinates of $\\mathcal{A}(v_i)$ represented by the basis $\\{u_j\\}$, similarly i-th column of $\\tilde{A}$ is $\\mathcal{A}(\\tilde{v}_i)$ represented in $\\{\\tilde{u}_j\\}$ The i-th column of $P$ is the coordinates of $v_i$ represented by the basis $\\{\\tilde{v}\\}$, similarly i-th column of $Q$ is $u_j$ represented in $\\{\\tilde{u}\\}$ Matrix Similarity ($A\\sim B$): Two (square) matrix representations ($A,B$) of the same linear operator are called similar (or conjugate) and they satisfies $\\exists P$ s.t. $B=PAP^{-1}$.\nFrom now on we don\u0026rsquo;t distinguish between linear operator $\\mathcal{A}$ and its matrix representation where choice of basis doesn\u0026rsquo;t matter.\nRank: $rank(A)=\\rho(A)\\equiv dim(\\mathcal{R}(A))$\nSylvester\u0026rsquo;s Inequality: $\\rho(A)+\\rho(B)-n\\leqslant \\rho(AB)\\leqslant \\min\\{\\rho(A), \\rho(B)\\}$ Singularity: $\\rho(A)\u0026lt; n$ Nullity: $null(A)=\\nu(A)\\equiv dim(\\mathcal{N}(A))$\n$\\rho(A)+\\nu(A)=n$ ($n$ is the dimensionality of domain space) Adjoint: The adjoint of the linear map $\\mathcal{A}: \\mathcal{V}\\to\\mathcal{W}$ is the linear map $\\mathcal{A}^*: \\mathcal{W}\\to\\mathcal{V}$ such that $\\langle y,\\mathcal{A}(x)\\rangle_\\mathcal{W}=\\langle \\mathcal{A}^ *(y),x\\rangle_\\mathcal{V}$\nFor its matrix representation, adjoint of $A$ is $A^ *$, which is $A^\\top$ for real numbers.\nProperties of $\\mathcal{A}^ *$ is similar to matrix $A^ *$\n$\\mathcal{U}=\\mathcal{R}(A)\\overset{\\perp}{\\oplus}\\mathcal{N}(A^ *),\\;\\mathcal{V}=\\mathcal{R}(A^ *)\\overset{\\perp}{\\oplus}\\mathcal{N}(A)$ $\\mathcal{N}(A^* )=\\mathcal{N}(AA^* )\\subseteq\\mathcal{U},\\;\\mathcal{R}(A)=\\mathcal{R}(AA^*)\\subseteq\\mathcal{U}$ Self-adjoint: $\\mathcal{A}$ is self-adjoint iff $\\mathcal{A}^*=\\mathcal{A}$.\nFor self-adjoint $\\mathcal{A}$, if $\\mathcal{V}=\\mathbb{C}^{n\\times n}$ then $A$ is hermitian; if $\\mathcal{V}=\\mathbb{R}^{n\\times n}$ then $A$ is symmetric. Self-adjoint matrices have real eigenvalues and orthogonal eigenvectors Skew symmetric: $A^*=-A$ For quadratic form $x^\\top Ax=x^\\top(\\frac{A+A^\\top}{2}+\\frac{A-A^\\top}{2})x$, since $A-A^\\top$ is skew symmetric, scalar $x^\\top (A-A^\\top) x=-x^\\top (A-A^\\top)x$, so the skew-symmetric part is zero. Therefore for quadratic form $x^\\top Ax$ we can always assume $A$ is symmetric.\nDefiniteness: (for symmetric matrix $P$)\nPositive definite ($P\\succ 0$): $\\forall x\\in\\mathbb{R}^n\\neq 0,\\; x^\\top Px\u0026gt;0 \\Leftrightarrow$ all eigenvalues of $P$ are positive. Semi-positive definite ($P\\succcurlyeq 0$): $x^\\top Px\\geqslant 0 \\Leftrightarrow$ all eigenvalues of $P$ are non-negative. Negative definite ($P\\prec 0$): $x^\\top Px \u0026lt; 0 \\Leftrightarrow$ all eigenvalues of $P$ are negative. Orthogonal Matrix: $Q$ is orthogonal iff $Q^\\top Q=I$, iff columns of $Q$ are orthonormal.\nIf $A\\in\\mathbb{R}^{n\\times b}$ is symmetric, then $\\exists$ orthogonal $Q$ s.t. $Q^\\top AQ=\\Lambda=\\mathrm{diag}\\{\\lambda_1,\\ldots,\\lambda_n\\}$ (see Eigen-decomposition section below) Orthogonal Projection: Given linear space $\\mathcal{X}$ and subspace $\\mathcal{M}$, $P(x)=x^*:\\mathcal{X}\\to\\mathcal{M}$ ($x^ *$ is the projection point) is called orthogonal projection. If $\\{v_i\\}$ is a orthonormal basis of $\\mathcal{M}$, then $P(x)=\\sum_i \\langle x,v_i\\rangle v_i$\nEigenvalue and Canonical Forms Eigenvalue and Eigenvector: Given mapping $\\mathcal{A}:\\mathcal{V}\\rightarrow\\mathcal{V}$, if $\\exists \\lambda\\in\\mathcal{F}, v\\neq \\emptyset_{\\mathcal{V}}\\in\\mathcal{V}$ s.t. $\\mathcal{A}(v) = \\lambda v$, then $\\lambda$ is the eigenvalue, $v$ is the eigenvector (aka. spectrum). If eigenvalues are all distinct, then the associated eigenvectors form a basis. Eigenspace: $\\mathcal{N}_\\lambda = \\mathcal{N}(\\mathcal{A}-\\lambda \\mathcal{I})$. $q=dim(\\mathcal{N}_\\lambda)$ is called the geometric multiplicity (几何重度) $\\mathcal{N}_\\lambda$ is an $\\mathcal{A}$-invariant subspace. Characteristic Polynomial: $\\phi(s)\\equiv\\mathcal{det}(A-s I)$ is a polynomial of degree $n$ in $s$ Its solutions are the eigenvalues of $A$. The multiplicity $m_i$ of root term $(s-\\lambda_i)$ here is called algebraic multiplicity (代数重度) of $\\lambda_i$. Cayley-Hamilton Theorem: $\\phi(A)=\\mathbf{0}$ Proof needs the eigendecomposition or Jordan decomposition descibed below\nMinimal Polynomial: $\\psi(s)$ is the minimal polynomial of $A$ iff $\\psi(s)$ is the polynomial of least degree for which $\\psi(A)=0$ and $\\psi$ is monic (coefficient of highest order term is 1) The multiplicity $\\eta_i$ of root term $(s-\\lambda_i)$ here is called the index of $\\lambda_i$ Eigendecomposition (aka. Spectral Decomposition) is directly derived from the definition of eigenvalues: $$A=Q\\Lambda Q^{-1}, \\Lambda=\\mathrm{diag}\\left\\{\\lambda_1,\\lambda_2,\\ldots,\\lambda_n\\right\\}$$ where $Q$ is a square matrix whose $i$-th column is the eigenvector $q_i$ corresponding to eigenvalue $\\lambda_i$. Feasibility: $A$ can be diagonalized (using eigendecomposition) iff. $q_i=m_i$ for all $\\lambda_i$. If $A$ has $n$ distinct eigenvalues, then $A$ can be diagonalized. Generalized eigenvector: A vector $v$ is a generalized eigenvector of rank $k$ associated with eigenvalue $\\lambda$ iff $v\\in\\mathcal{N}\\left((A-\\lambda I)^k\\right)$ but $v\\notin\\mathcal{N}\\left((A-\\lambda I)^{k-1}\\right)$ If $v$ is a generalized eigenvector of rank $k$, $(A-\\lambda I)v$ is a generalized eigenvector of rank $k-1$. This creates a chain of generalized eigenvectors (called Jordan Chain) from rank $k$ to $1$, and they are linearly independent. $\\eta$ (index, 幂零指数) of $\\lambda$ is the smallest integer s.t. $dim\\left(\\mathcal{N}\\left((A-\\lambda I)^\\eta\\right)\\right)$ The space spanned by the chain of generalized eigenvectors from rank $\\eta$ is called the generalized eigenspace (with dimension $\\eta$). Different generalized eigenspaces associated with the same and with different eigenvalues are orthogonal. Jordan Decomposition: Similar to eigendecomposition, but works for all square matrices. $A=PJP^{-1}$ where $J=\\mathrm{diag}\\{J_1,J_2,\\ldots,J_p\\}$ is the Jordan Form of A consisting of Jordan Blocks. Jordan Block: $J_i=\\begin{bmatrix} \\lambda \u0026amp; 1 \u0026amp;\u0026amp;\u0026amp; \\\\\u0026amp;\\lambda\u0026amp;1\u0026amp;\u0026amp;\\\\\u0026amp;\u0026amp;\\lambda\u0026amp;\\ddots\u0026amp;\\\\\u0026amp;\u0026amp;\u0026amp;\\ddots\u0026amp;1\\\\\u0026amp;\u0026amp;\u0026amp;\u0026amp;\\lambda\\end{bmatrix}$ Each Jordan block corresponds to a generalized eigenspace $q_i$ = the count of Jordan blocks associated with $\\lambda_i$ $m_i$ = the count of $\\lambda_i$ on diagonal of $J$ $\\eta_i$ = the dimension of the largest Jordan block associated with $\\lambda_i$ $\\Lambda$ in eigendecomposition, $J$ in Jordan Form and $\\Sigma$ in SVD (see below) are three kinds of Canonical Forms of a matrix $A$\nFunction of matrics: Let $f(\\cdot)$ be an analytic function and $\\lambda_i$ be an eigenvalue of $A$. If $p(\\cdot)$ is a polynomial that satisfies $p(\\lambda_i)=f(\\lambda_i)$ and $\\frac{\\mathrm{d}^k}{\\mathrm{d}s^k} p(\\lambda_i)=\\frac{\\mathrm{d}^k}{\\mathrm{d}s^k} f(\\lambda_i)$ for $k=1,\\ldots,\\eta_i-1$, then $f(A)\\equiv p(A)$. This extends the functions applicable to matrics from polynomials (trivial) to any analytical functions By Cayley-Hamilton, we can always choose $p$ to be order $n-1$ Sylvester\u0026rsquo;s Formula: $f(A)=\\sum^k_{i=1}f(\\lambda_i)A_i$ ($f$ being analytic) SVD and Linear Equations SVD Decomposition is useful in various fields and teached by a lot of courses, its complete version is formulated as $$A=U\\Sigma V^*, \\Sigma=\\begin{bmatrix}\\mathbf{\\sigma}\u0026amp;\\mathbf{0}\\\\ \\mathbf{0}\u0026amp;\\mathbf{0}\\end{bmatrix}, \\mathbf{\\sigma}=\\mathrm{diag}\\left\\{\\sqrt{\\lambda_1},\\sqrt{\\lambda_2},\\ldots,\\sqrt{\\lambda_r}\\right\\},V=\\begin{bmatrix}V_1\u0026amp;V_2\\end{bmatrix},U=\\begin{bmatrix}U_1\u0026amp;U_2\\end{bmatrix}$$ where\n$r=\\rho(A)$ is the rank of matrix $A$ $\\sigma_i$ are called sigular values, $\\lambda_i$ are eigenvalues of $A^* A$ Columns of $V_1$ span $\\mathcal{R}(A^ *A)=\\mathcal{R}(A^ *)$, columns of $V_2$ span $\\mathcal{N}(A^ *A)=\\mathcal{N}(A)$ Columns of $U_1=AV_1\\sigma^{-1}$ span $\\mathcal{R}(A)$, columns of $U_2$ span $\\mathcal{N}(A^*)$ SVD can be derived by doing eigenvalue decomposition on $A^* A$\nWith SVD introduced, we can efficiently solve general linear equation $Ax=b$ as $x=x_r+x_n$ where $x_r\\in\\mathcal{R}(A^\\top)$ and $x_n\\in\\mathcal{N}(A)$.\n$Ax=b$ tall $A$ ($m\u0026gt;n$) fat $A$ ($m\u0026lt; n$) Overdetermined, Least Squares, use Normal Equations Underdetermined, Quadratic Programming, use Lagrange Multiplies I.$b\\in\\mathcal{R}(A)$ 1.$\\mathcal{N}(A)={0}$ $x$ exist \u0026amp; is unique $x=(A^\\top A)^{-1}A^\\top b=A^+b$ $x=A^\\top(AA^\\top)^{-1}b=A^+b$ 2.$\\mathcal{N}(A)\\neq{0}$ $x$ exist \u0026amp; not unique $x_r=(A^\\top A)^{-1}A^\\top b=A^+b$ $x_r=A^\\top(AA^\\top)^{-1}b=A^+b$ II.$b\\notin\\mathcal{R}(A)$ 1.$\\mathcal{N}(A)={0}$ $x$ not exists, $x_r$ exist \u0026amp; is unique $x_r=(A^\\top A)^{-1}A^\\top b=A^+b$ $x_r=A^\\top(AA^\\top)^{-1}b=A^+b$ 2.$\\mathcal{N}(A)\\neq{0}$ $x$ not exists, $x_r$ not exist $(A^\\top A)^{-1}$ invertible $(AA^\\top)^{-1}$ invertible $A^+=(A^\\top A)^{-1}A^\\top$ is left pseudo-inverse, $A^+=A^\\top (AA^\\top)^{-1}$ is right pseudo-inverse. $A^+$ can be unified by the name Moore-Penrose Inverse and calculated using SVD by $A^+=V\\Sigma^+ U^\\top$ where $\\Sigma^+$ take inverse of non-zeros. Miscellaneous Selected theorems and lemmas useful in Linear Algebra. For more matrix properties see my post about Matrix Algebra\nMatrix Square Root: $N^\\top N=P$, then $N$ is the square root of $P$ Square root is not unique. Cholesky decomposition is often used as square root.\nSchur Complement: Given matrices $A_{n\\times n}, B_{n\\times m}, C_{m\\times m}$, the matrix $M=\\begin{bmatrix}A\u0026amp;B\\\\ B^\\top\u0026amp;C\\end{bmatrix}$ is symmetric. Then the following are equivalent (TFAE) $M\\succ 0$ $A\\succ 0$ and $C-B^\\top A^{-1}B\\succ 0$ (LHS called Schur complement of $A$ in $M$) $C\\succ 0$ and $A-B C^{-1}B^\\top\\succ 0$ (LHS called Schur complement of $C$ in $M$) Matrix Inverse Lemma: $(A+BCD)^{-1}=A^{-1}-A^{-1}B\\left(C^{-1}+DA^{-1}B\\right)^{-1}DA$ Properties of $A^\\top A$ $A^\\top A \\succeq 0$ and $A^\\top A \\succ 0 \\Leftrightarrow A$ has full rank. $A^\\top A$ and $AA^\\top$ have same non-zero eigenvalues, but different eigenvectors. If $v$ is eigenvector of $A^\\top A$ about $\\lambda$, then $Av$ is eigenvector of $AA^\\top$ about $\\lambda$. If $v$ is eigenvector of $AA^\\top$ about $\\lambda$, then $A^\\top v$ is eigenvector of $A^\\top A$ about $\\lambda$. $tr(A^\\top A)=tr(AA^\\top)=\\sum_i\\sum_j\\left|A_{ij}\\right|^2$ $det(A)=\\prod_i\\lambda_i, tr(A)=\\sum_i\\lambda_i$ Real Analysis Set theory $\\text{~}S$ stands for complement of set $S$ in following contents. These concepts are discussed under normed space $(\\mathcal{X}, \\Vert\\cdot\\Vert)$\nOpen Ball: Let $x_0\\in\\mathcal{X}$ and let $a\\in\\mathbb{R}, a\u0026gt;0$, then the open ball of radius $a$ about $x_0$ is $B_a(x_0)=\\left\\{x\\in\\mathcal{X}\\middle| \\Vert x-x_0\\Vert \u0026lt; a\\right\\}$ Given subset $S\\subset \\mathcal{X}$, $d(x,S)=0\\Leftrightarrow \\forall\\epsilon \u0026gt;0, B_\\epsilon(x)\\cap S\\neq\\emptyset$ Given subset $S\\subset \\mathcal{X}$, $d(x,S)\u0026gt;0\\Leftrightarrow \\exists\\epsilon \u0026gt;0, B_\\epsilon(x)\\cap S=\\emptyset$ Interior Point: Given subset $S\\subset\\mathcal{X}$, $x\\in S$ is an interior point of $S$ iff $\\exists\\epsilon \u0026gt;0, B_\\epsilon(x)\\subset S$ Interior: $\\mathring{S}=\\{x\\in \\mathcal{X}|x\\text{ is an interior point of }S\\}=\\{x\\in\\mathcal{X}|d(x,\\text{~}S)\u0026gt;0\\}$ Open Set: $S$ is open if $\\mathring{S}=S$ Closure Point: Given subset $S\\subset\\mathcal{X}$, $x\\in S$ is a closure point of $S$ iff $\\forall\\epsilon \u0026gt;0, B_\\epsilon(x)\\cap S\\neq\\emptyset$. Closure: $\\bar{S}=\\{x\\in\\mathcal{X}|x\\text{ is a closure point of }S\\}=\\{x\\in\\mathcal{X}|d(x,S)=0\\}$ Note that $\\partial\\mathcal{X}=\\emptyset$\nClosed Set: $S$ is closed if $\\bar{S}=S$ $S$ is open $\\Leftrightarrow$ $\\text{~}S$ is closed, $S$ is closed $\\Leftrightarrow$ $\\text{~}S$ is open. Set being both open and closed is called clopen(e.g. the whole set $\\mathcal{X}$), empty set is clopen by convention.\nSet Boundary: $\\partial S=\\bar{S}\\cap\\overline{\\text{~}S}=\\bar{S}\\backslash\\mathring{S}$ Sequences Sequence($\\{x_n\\}$): a set of vectors indexed by the counting numbers Subsequence: Let $1\\leqslant n_1\u0026lt; n_2\u0026lt;\\ldots$ be an infinite set of increasing integers, then $\\{x_{n_i}\\}$ is a subsequence of $\\{x_n\\}$ Convergence($\\{x_n\\}\\to x\\in\\mathcal{X}$): $\\forall \\epsilon\u0026gt;0,\\exists N(\\epsilon)\u0026lt;\\infty\\text{ s.t. }\\forall n\\geqslant N, \\Vert x_n-x\\Vert \u0026lt;\\epsilon$ If $x_n \\to x$ and $x_n \\to y$, then $x=y$ If $x_n \\to x_0$ and $\\{x_{n_i}\\}$ is a subsequence of $\\{x_n\\}$, then $\\{x_{n_i}\\} \\to x_0$ Cauchy Convergence (necessary condition for convergence): $\\{x_n\\}$ is cauchy if $\\forall \\epsilon\u0026gt;0,\\exists N(\\epsilon)\u0026lt;\\infty$ s.t. $\\forall n,m\\geqslant N, \\Vert x_n-x_m\\Vert \u0026lt;\\epsilon$ If $\\mathcal{X}$ is finite dimensional, $\\{x_n\\}$ is cauchy $\\Rightarrow$ $\\{x_n\\}$ has a limit in $\\mathcal{X}$ Limit Point: Given subset $S\\subset\\mathcal{X}$, $x$ is a limit point of $S$ if $\\exists \\{x_n\\}$ s.t. $\\forall n\\geqslant 1, x_n\\in S$ and $x_n\\to x$ $x$ is a limit point of $S$ iff $x\\in\\bar{S}$ $S$ is closed iff $S$ contains its limit points Complete Space: a normed space is complete if every Cauchy sequence has a limit. A complete normed space $(\\mathcal{X}, \\Vert\\cdot\\Vert)$ is called a Banach space. $S\\subset \\mathcal{X}$ is complete if every Cauchy sequence with elements from $S$ has a limit in $S$ $S\\subset \\mathcal{X}$ is complete $\\Rightarrow S$ is closed $\\mathcal{X}$ is complete and $S\\subset\\mathcal{X} \\Rightarrow S$ is complete All finite dimensional subspaces of $X$ are complete Completion of Normed Space: $\\mathcal{Y}=\\bar{\\mathcal{X}}=\\mathcal{X}+\\{$all limit points of Cauchy sequences in $\\mathcal{X}\\}$ E.g. $C[a,b]$ contains continuous functions over $[a,b]$. $(C[a,b], \\Vert\\cdot\\Vert_1)$ is not complete, $(C[a,b], \\Vert\\cdot\\Vert_\\infty)$ is complete. Completion of $(C[a,b], \\Vert\\cdot\\Vert_1)$ requires Lebesque integration.\nContraction Mapping: Let $S\\subset\\mathcal{X}$ be a subset and $T:S\\to S$ is a contraction mapping if $\\exists 0\\leqslant c\\leqslant 1$ such that, $\\forall x,y \\in S, \\Vert T(x)-T(y)\\Vert\\leqslant c\\Vert x-y\\Vert$ Fixed Point: $x^* \\in\\mathcal{X}$ is a fixed point of $T$ if $T(x^ *)=x^ *$ Contraction Mapping Theorem (不动点定理): If $T:S\\to S$ is a contraction mapping in a complete subset $S$, then $\\exists! x^ *\\in\\mathcal{X}\\text{ s.t. }T(x^ *)=x^ *$. Moreover, $\\forall x_0\\in S$, the sequence $x_{k+1}=T(x_k),k\\geqslant 0$ is Cauchy and converges to $x^ *$. E.g. Newton Method: $x_{k+1}=x_k-\\epsilon\\left[\\frac{\\partial h}{\\partial x}(x_k)\\right]^{-1}\\left(h(x_k)-y\\right)$\nContinuity and Compactness Continuous: Let $(\\mathcal{X},\\Vert\\cdot\\Vert_\\mathcal{X})$ and $(\\mathcal{Y},\\Vert\\cdot\\Vert_\\mathcal{Y})$ be two normed spaces. A function $f:\\mathcal{X}\\to\\mathcal{Y}$ is continuous at $x_0\\in\\mathcal{X}$ if $\\forall\\epsilon \u0026gt;0,\\exists \\delta(\\epsilon,x_0)\u0026gt;0\\text{ s.t. }\\Vert x-x_0\\Vert_\\mathcal{X}\u0026lt;\\delta \\Rightarrow\\Vert f(x)-f(x_0)\\Vert_\\mathcal{Y} \u0026lt;\\epsilon$ $f$ is continuous on $S\\subset\\mathcal{X}$ if $f$ is continuous at $\\forall x_0\\in S$ If $f$ in continuous at $x_0$ and $\\{x_n\\}$ is a sequence s.t. $x_n\\to x_0$, then the sequence $\\{f(x_n)\\}$ in $\\mathcal{Y}$ converges to $f(x_0)$ If $f$ is discontinuous at $x_0$, then $\\exists \\{x_n\\}\\in\\mathcal{X}$ s.t. $x_n\\to x_0$ but $f(x_n)\\nrightarrow f(x_0)$ Compact: $S\\subset\\mathcal{X}$ is (sequentially) compact if every sequence in $S$ has a convergent subsequence with limit in $S$ Bounded: $S\\subset\\mathcal{S}$ is bounded if $\\exists r\u0026lt;\\infty$ such that $S\\subset B_r(0)$ $S$ is compact $\\Rightarrow$ $S$ is closed and bounded Bolzano-Weierstrass Theorem: In a finite-dimensional normed space, $C$ is closed and bounded $\\Leftrightarrow$ for $C$ is compact Weierstrass Theorem: If $C\\subset\\mathcal{X}$ is a compact subset and $f:C\\to\\mathbb{R}$ is continuous at each point of $C$, then $f$ achieves its extreme values, i.e. $\\exists \\bar{x}\\in C\\text{ s.t. }f(\\bar{x})=\\sup_{x\\in C} f(x)$ and $\\exists \\underline{x}\\in C\\text{ s.t. }f(\\underline{x})=\\inf_{x\\in C} f(x)$ $f:C\\to\\mathbb{R}$ continuous and $C$ compact $\\Rightarrow$ $\\sup_{x\\in C}f(x)\u0026lt;\\infty$ ","date":"2020-06-27T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2020-06/AlgebraBasicsNotes/","title":"Notes for Algebra Basics"},{"content":" In this note, $f\\in\\mathbb{F}^\\mathbb{G}$ stands for a function with domain in $\\mathbb{G}$ and co-domain in $\\mathbb{F}$, i.e. $f:\\mathbb{F}\\to\\mathbb{G}$, $H(x)$ generally stands for Heaviside function (step function) Please read the Algebra Basics notes first if you are not familiar with related concepts. Transforms Laplace Transform Definition: $F(s)=\\mathcal{L}\\{f(t)\\}(s)=\\int^\\infty_0 f(t)e^{-st}\\mathrm{d}t$ Note that the transform is not well defined for all functions in $\\mathbb{C}^\\mathbb{R}$. And the transform is only valid for $s$ in a region of convergence, which is usually separated by 0.\nLaplace Transform is a linear map from $(\\mathbb{C}^\\mathbb{R}, \\mathbb{C})$ to $(\\mathbb{C}^\\mathbb{C}, \\mathbb{C})$ and it\u0026rsquo;s one-to-one. Properties: (see Wikipedia or this page for full list) Derivative: $f\u0026rsquo;(t) \\xleftrightarrow{\\mathcal{L}} sF(s)-f(0^-)$ Integration: $\\int^t_0 f(\\tau)d\\tau \\xleftrightarrow{\\mathcal{L}} \\frac{1}{s}F(s)$ Delay: $f(t-a)H(t-a) \\xleftrightarrow{\\mathcal{L}} e^{-as}F(s)$ Convolution: $\\int^t_0 f(\\tau)g(t-\\tau)\\mathrm{d}\\tau \\xleftrightarrow{\\mathcal{L}} F(s)G(s)$ Stationary Value: $\\lim\\limits_{t\\to 0} f(t) = \\lim\\limits_{s\\to \\infty} sF(s), \\lim\\limits_{t\\to \\infty} f(t) = \\lim\\limits_{s\\to 0} sF(s)$ Inverse Laplace Transform Laplace transform is one-to-one, so we can apply inverse transform on functions in s-space\nThere are several ways to calculate Laplace transform, the first one is directly evaluating integration while the latter two are converting the function into certain formats that are convenient for table lookup:\n(Mellin\u0026rsquo;s) Inverse formula: $f(t)=\\mathcal{L}^{-1}\\{F(s)\\}(t)=\\frac{1}{2\\pi j}\\lim\\limits_{T\\to\\infty} \\int ^{\\gamma+iT}_{\\gamma-iT} e^{st}F(s)\\mathrm{d}s$ where the integration is done along the vertical line $Re(s)=\\gamma$ in the convex s-plane such that $\\gamma$ is greater than the real part of all poles of $F(s)$. Power Series: $F(s) = \\sum^\\infty_{n=0} \\frac{n!a_n}{s^{n+1}}\\xleftrightarrow{\\mathcal{L}} f(t) = \\sum ^\\infty_{n=0} a_n t^n $ Partial Fractions: $F(s)=\\frac{k_1}{s+a}+\\frac{k_2}{s+b}+\\ldots \\xleftrightarrow{\\mathcal{L}} f(t)=k_1 e^{-at} + k_2 e^{-bt} + \\ldots$ To calculate partial fractions, one can use Polynomial Division or following lemma: Suppose $F(s)=\\frac{N(s)}{D(s)}=\\frac{N(s)}{\\prod^n_{i=1} (s-p_i)^{r_i}}$ where $\\mathrm{deg}(N(s)) \u0026lt; \\mathrm{deg(D(s))}$ and each $p_i$ is a distinct root of $D(s)$ (i.e. pole) with multiplicity $r_i$, then $F(s)=\\sum^n_{i=1}\\sum^{r_i}_ {j=1} \\frac{k_{ij}}{(s-p_i)j}$ where $k_{ij}=\\frac{1}{(r_i-j)!}\\left.\\frac{\\mathrm{d}^{r_i-j}}{\\mathrm{d}s^{r_i-j}}(s-p_i)^{r_i}F(s)\\right\\vert_{s=p_i}$ Z-Transfrom Definition: $F(z)=\\mathcal{Z}\\{f(k)_ {k\\in\\mathbb{N}}\\}(z)=\\sum^\\infty_{k=0} f(k)z^{-k}$ Notice that $f$ is defined on natural numbers. In time domain, it\u0026rsquo;s usually corresponding to $f(kT)$. Z-transform is also only valid for $z$ in certain region (usually separated by 1)\nLaplace Transform is a linear map from $(\\mathbb{C}^\\mathbb{N}, \\mathbb{C})$ to $(\\mathbb{C}^\\mathbb{C}, \\mathbb{C})$ and it\u0026rsquo;s one-to-one. Properties: (see Wikipedia or this page for full list) Accumulation: $\\sum^n_{k=-\\infty} f(k) \\xleftrightarrow{\\mathcal{Z}} \\frac{1}{1-z^{-1}}F(z)$ Delay: $f(k-m) \\xleftrightarrow{\\mathcal{Z}} z^{-m}F(z)$ Convolution: $\\sum^k_{n=0}f_1(n)f_2(k-n) \\xleftrightarrow{\\mathcal{Z}} F_1(z)F_2(z)$ Stationary Value: $\\lim\\limits_{t\\to 0} f(t) = \\lim\\limits_{z\\to \\infty} F(z), \\lim\\limits_{t\\to \\infty} f(t) = \\lim\\limits_{z\\to 1} (z-1)F(z)$ Example: Z-Transform of PID controller Assume the close-loop error input of the controller is $e(t)$, and $e(kT)$ after sampling. PID controller action in analog is $$m(t)=K\\left(e(t)+\\frac{1}{T_i}\\int^t_0e(t)\\mathrm{d}t+T_d\\frac{\\mathrm{d}e(t)}{\\mathrm{d}t}\\right)$$ We can approximate by trapezoidal rule with two point difference: $$m(kT)=K\\left(e(kT)+\\frac{T}{T_i}\\sum^k_{h=1}\\frac{e((h-1)T)+e(hT)}{2}+T_d\\left(\\frac{e(kT)-e((k-1)T)}{T}\\right)\\right)$$ Lets define $f(hT) = \\frac{1}{2}\\left(e((h-1)T)+e(hT)\\right),\\;f(0)=0$ Then $$\\begin{split}\\mathcal{Z}\\left(\\left\\{\\sum^k_{h=1}\\frac{e((h-1)T)+e(hT)}{2}\\right\\}_k\\right)(z)=\\mathcal{Z}\\left(\\left\\{\\sum^k_{h=1}f(hT)\\right\\}_k\\right)(z) \\\\ =\\frac{1}{1-z^{-1}}(F(z)-F(0))=\\frac{1}{1-z^{-1}}F(z)\\end{split}$$ Notice that $$F(z)=\\mathcal{Z}\\left({f(hT)}_h\\right)(z)=\\frac{1+z^{-1}}{2}E(z)$$ so we can calculate the Z-transform of $m(kT)$ $$\\begin{split} M(z)\u0026=K\\left(1+\\frac{T}{2T_i}\\left(\\frac{1+z^{-1}}{1-z^{-1}}\\right)+\\frac{T_d}{T}(1-z^{-1})\\right)E(z)\\\\\u0026=K\\left(1-\\frac{T}{2T_i}+\\frac{T}{T_i}\\frac{1}{1-z^{-1}}+\\frac{T_d}{T}(1-z^{-1})\\right)E(z)\\\\\u0026=\\left(K_p+K_i\\left(\\frac{1}{1-z^-1}\\right)+K_d(1-z^{-1})\\right)E(z) \\end{split}$$ Here we have\nProportional Gain $K_p=K-\\frac{KT}{2T_i}$ Integral Gain $K_I=\\frac{KT}{T_i}$ Derivative Gain $K_d=\\frac{KT_d}{T}$ Inverse Z-Transform Inverse formula: $f(k)=\\mathcal{Z}^{-1}\\{F(z)\\}(k)=\\frac{1}{2\\pi j}\\oint _\\Gamma z^{k-1}F(z)\\mathrm{d}z$ where the integration is done along any closed path $\\Gamma$ that encloses all finite poles of $z^{k-1}X(z)$ in the z-plane. According to residual theorem, we can write it as $f(k)=\\sum_{p_i}Res(z^{k-1}f(z), pi)$ where $p_i$ are poles of $z^{k-1}f(k)$ and residual $Res(g(z),p)=\\frac{1}{(m-1)!}\\left.\\frac{\\mathrm{d}^{m-1}}{\\mathrm{d}z^{m-1}}\\left((z-p)^mg(z)\\right)\\right\\vert_{z=p}$ with $m$ being the multiplicity of the pole $p$ in $g$. Power Series: same as inverse laplace. Partial Fractions: same as inverse laplace. Modified Z-Transfrom Definition: $F(z,m)=\\mathcal{Z}_m(f,m)=\\mathcal{Z}(\\left\\{f(kT-(1-m)T)\\right\\} _{k\\in\\mathbb{N}^+})(z)$ We denote corresponding continuous form $\\mathcal{L}(f(t-(1-m)T)\\delta_ T(t))$ as $F^*(s,m)$ Residual Theorem: $\\mathcal{Z}_m(f,m)=z^{-1}\\sum _{p_i} Res(\\frac{F(s)e^{mTs}}{1-z^{-1}e^{Ts}}, p_i)$ ModZ Transform is usually used when there\u0026rsquo;s delay in the system, use this transform to shift the signal with proper $m$ value. Starred Transform Definition: $F^* (s)=\\sum^\\infty_{n=0}f(n*T)e^{-nTs}$ Starred Transform is defined in continuous s-domain, but it only aggregates on discrete s values defined periodically by sampling time T, like Z-Transform. Starred Transform is usually exchangeable with Z-Transform with $z=e^{Ts}$.\nSometimes we also see * as an operator to sample a continuous signal. It converts a continuous signal to discrete delta functions. (See the \u0026ldquo;Sampler\u0026rdquo; section below) Calculation from Laplace Transform $F^*(s)=\\sum_{p_i\\in\\{poles\\;of\\;F(\\lambda)\\}} Res\\left(F(\\lambda)\\frac{1}{1-e^{-T(s-\\lambda)}}, p_i\\right)$ $F^*(s)=\\frac{1}{T}\\sum^\\infty_{n=-\\infty}F(s+jn\\omega_s)+\\frac{e(0)}{2}$ where $\\omega_s=\\frac{2\\pi}{T}$ Properties: $F^*(s)$ is periodic in s plane with period $j\\omega_s=\\frac{2\\pi j}{T}$ If $F(s)$ has a pole at $s=s_0$, then $F^*(s)$ must have poles at $s=s_0+jn\\omega_s$ for $m\\in\\mathbb{Z}$ $A(s)=B(s)F^* (s) \\Rightarrow A^* (s)=B^* (s)F^* (s)$, while usually $A(s)=B(s)F(s) \\nRightarrow A^* (s)=B^* (s)F^* (s)$ Fourier Transform Fourier transform is basically to substitute $s=j\\omega$ into Laplace transform. Additional properties are not discussed here.\nOne important theorem (Shannon-Nyquist Sampling Theorem): Suppose $e:\\mathbb{R}_+\\to\\mathbb{R}$ has a Fourier Transform with no frequency components greater than $f_0$, then $e$ is uniquely determined by the signal $e_s$ generated by ideally sampling $e$ with period $\\frac{1}{2}f_0$. State Space Representation Continuous State Space Representation Definition A continuous-time linear state-space system can be described by following two equations: \\begin{align}\u0026amp;\\text{State equation}:\\;\u0026amp;\\dot{x}(t)\u0026amp;=A(t)x(t)+B(t)u(t),\u0026amp;\\;x(t)\\in\\mathbb{R}^n,\\;u(t)\u0026amp;\\in\\mathbb{R}^m \\\\\u0026amp;\\text{Output equation}:\\;\u0026amp;y(t)\u0026amp;=C(t)x(t)+D(t)u(t),\u0026amp;\\;y(t)\u0026amp;\\in\\mathbb{R}^p\\end{align}\nThe input $u:[0,\\infty)\\to\\mathbb{R}^m$, state $x:[0,\\infty)\\to\\mathbb{R}^n$, and output $y:[0,\\infty)\\to\\mathbb{R}^p$ are all signals, i.e. functions of continuous time $t\\in[0,\\infty)$. The coefficients $A\\in\\mathbb{R}^{n\\times n}$,$B\\in\\mathbb{R}^{n\\times m}$,$C\\in\\mathbb{R}^{p\\times n}$,$D\\in\\mathbb{R}^{p\\times m}$\nThis linear time-varying (LTV) system can be written compactly as \\begin{align*} \\dot{x}\u0026amp;=A(t)x+B(t)u \\\\ y\u0026amp;=C(t)x+D(t)u\\end{align*} Similarly, linear time-invariant (LTI) system can be written as \\begin{align} \\dot{x}\u0026amp;=Ax+Bu \\\\ y\u0026amp;=Cx+Du\\end{align}\nFor non-linear system, the equation will be written as\ntime-varying (NLTV) time-invariant (NTLI) time-invariant autonomous \\begin{align*}\\dot{x}\u0026amp;=f(x,u,t)\\\\y\u0026amp;=g(x,u,t)\\end{align*}\n\\begin{align*}\\dot{x}\u0026amp;=f(x,u)\\\\y\u0026amp;=g(x,u)\\end{align*}\n\\begin{align*}\\dot{x}\u0026amp;=f(x)\\\\y\u0026amp;=g(x)\\end{align*}\nSolution Math prerequisites here:\nFor definition of function on matrix, see my notes for algebra basics $e^A$ is matrix exponential, expm in MATLAB $\\frac{\\mathrm{d}}{\\mathrm{d}t}e^{At}=Ae^{At}=e^{At}A$ $e^{(A+B)t}\\Leftrightarrow AB=BA$ (be careful when commute matrices) $\\mathcal{L}\\{e^{At}\\}=(sI-A)^{-1}$ (can be derived from property 1 and laplace derivative) To calculate $e^A$ Eigenvalue decomposition Jordan form decomposition Directly evaluate infinite power series (converges quickly) Inverse Laplace transform For more properties of the matrix function, seeMatrix Algebra For homogeneous LTI system: $$\\begin{align}x(t)=e^{A(t-t_0)}x_0\\end{align}$$\n\u0026ldquo;homogeneous\u0026rdquo; = zero-input, Eq.5 is also called zero input response (ZIR). \u0026ldquo;homogeneous equation\u0026rdquo; = 齐次方程 For LTI system: $$\\begin{align}x(t)=e^{A(t-t_0)}x(t_0)+\\int^t_{t_0}e^{A(t-\\tau)}Bu(\\tau)d\\tau\\end{align}$$ This result requires $A$ to be time-invariant, $B,C,D$ can be time varying.\nThe solution consists of two parts: ZIR and ZSR (zero state response, $x(t_0)=0$), which are homogenenous solution (通解) and particular solution (特解) of the ODE. ZIR and ZSR are both linear mapping For homogeneous LTV system: $$\\begin{align}x(t)=\\Phi(t,t_0)x_0\\end{align}$$\nMatrix $\\Phi$ is called the state transition matrix, defined as $$\\begin{equation}\\begin{split}\\Phi(t,t_0)\\equiv I+\\int^t_{t_0}A(s_1)\\mathrm{d}s_1+\\int^t_ {t_0}A(s_1)\\int^{s_1}_ {t_0}A(s_2)\\mathrm{d}s_2\\mathrm{d}s_1+\\\\ \\int^t_ {t_0}A(s_1)\\int^{s_1}_ {t_0}A(s_2)\\int^{s_2}_ {t_0}A(s_3)\\mathrm{d}s_3\\mathrm{d}s_2\\mathrm{d}s_1+\\cdots\\end{split}\\end{equation}$$ Properties of $\\Phi$: $\\Phi(t,t)=I$ $\\frac{\\mathrm{d}}{\\mathrm{d}t}\\Phi(t,t_0)=A(t)\\Phi(t,t_0)$ (semigroup property) $\\Phi(t,s)\\Phi(s,\\tau)=\\Phi(t,\\tau)$ $\\forall t,\\tau\\geqslant 0,\\;[\\Phi(t,\\tau)]^{-1}=\\Phi(\\tau,t)$ Eq.6 can be directly derived by evaluating Eq.8 For LTV system: $$\\begin{align}x(t)=\\Phi(t,t_0)x_0+\\int^t_{t_0}\\Phi(t,\\tau)B(\\tau)u(\\tau)d\\tau\\end{align}$$\nSome conclusions:\nThe solution given by Eq.9 is unique The set of all solutions to ZIR system forms a vector space of dimension $n$ If $A(t)A(s)=A(s)A(t)$, then $\\Phi(t,t_0)=e^{\\int^t_{t_0}A(\\tau)\\mathrm{d}\\tau}$ Phase Portraits: A phase portrait is a graph of several zero-input responses on the phase plane ($\\dot{x}(t)$ and $x(t)$ are phase variables)\nUsually in phase portraits, there are two straight lines corresponding to the eigenvector of A, other lines are growing in or opposite to the direction of the lines.\nTransfer function For LTI case, $\\frac{Y(s)}{U(s)} = C(sI-A)^{-1}B+D$ This can be derived by take laplace transform of both sides of state equations\nDiscrete State Space Representation Definition A discrete-time linear state-space system can be described by following two equations: $$\\begin{align}\u0026amp;\\text{State eq.}:\\;\u0026amp;x(k+1)\u0026amp;=A(k)x(k)+B(k)u(k),\u0026amp;\\;x\\in\\mathbb{R}^n,\\;u\u0026amp;\\in\\mathbb{R}^m \\\\ \u0026amp;\\text{Output eq.}:\\;\u0026amp;y(k)\u0026amp;=C(k)x(k)+D(k)u(k),\u0026amp;\\;y\u0026amp;\\in\\mathbb{R}^p\\end{align}$$\nThe input $u:\\mathbb{N}\\to\\mathbb{R}^m$, state $x:\\mathbb{N}\\to\\mathbb{R}^n$, and output $y:\\mathbb{N}\\to\\mathbb{R}^p$ are all signals, i.e. functions of continuous time $t\\in\\mathbb{N}$.\nDiscrete LTI system is sometimes written compactly as $$\\begin{align} x_{k+1}\u0026amp;=Ax_k+Bu_k \\\\ y_k\u0026amp;=Cx_k+Du_k \\end{align}$$\nTransfer function For LTI case, $H(z)=C(zI-A)^{-1}B+D$ (pulse tranfer function) Controllability \u0026amp; Reachability Note: hereafter $\\mathfrak{R}$ denotes range space, $\\mathfrak{N}$ denotes null space.\nControllability: $\\exists u$ that drives any initial state $x(t_0)=x_0$ to $x(t_1)=0$ Reachability: $\\exists u$ that drives initial state $x(t_0)=0$ to any $x(t_1)=x_1$ Consider the continuous LTV system $\\dot{x}=A(t)x+B(t)u,\\;x\\in\\mathbb{R}^n,u\\in\\mathbb{R}^m$.\nReachable Subspace: Given $t_0$ \u0026amp; $t_1$, the reachable subspace $\\mathcal{R}[t_0, t_1]$ consists of all states $x_1$ for which there exists and input $u:[t_0, t_1]\\to\\mathbb{R}^m$ that transfers the state from $x(t_0)=0$ to $x(t_1)=x_1$.\n$\\mathcal{R}[t_0, t_1]\\equiv\\left\\{x_1\\in\\mathbb{R}^n\\middle|\\exists u(\\cdot),\\;x_1=\\int^{t_1}_{t_0}\\Phi(t_1,\\tau)B(\\tau)u(\\tau)\\mathrm{d}\\tau\\right\\}$ Controllable Subspace: Given $t_0$ \u0026amp; $t_1$, the controllable subspace $\\mathcal{C}[t_0, t_1]$ consists of all states $x_0$ for which there exists an input $u:[t_0, t_1]\\to\\mathbb{R}^m$ that transfers the state from $x(t_0)=x_0$ to $x(t_1)=0$\n$\\mathcal{C}[t_0, t_1]\\equiv\\left\\{x_0\\in\\mathbb{R}^m\\middle|\\exists u(\\cdot),\\;0=\\Phi(t_1,t_0)x_0+\\int^{t_1}_{t_0}\\Phi(t_1,\\tau)B(\\tau)u(\\tau)\\mathrm{d}\\tau\\right\\}$ or $\\mathcal{C}[t_0, t_1]\\equiv\\left\\{x_0\\in\\mathbb{R}^m\\middle|\\exists u(\\cdot),\\;x_0=\\int^{t_1}_{t_0}\\Phi(t_0,\\tau)B(\\tau)\\left[-u(\\tau)\\right]\\mathrm{d}\\tau\\right\\}$ Reachability Grammian: $W_\\mathcal{R}(t_0, t_1)\\equiv\\int^{t_1}_{t_0}\\Phi(t_1,\\tau)B(\\tau)B(\\tau)^\\top\\Phi^\\top(t_1,\\tau)\\mathrm{d}\\tau$ given times $t_1\u0026gt;t_0\\geqslant0$\nThe system is reachable at time $t_0$ iff $\\exists t_1$ s.t. $W_\\mathcal{R}(t_0,t_1)$ is non-singular. non-singular for some $t_1$ $\\Rightarrow$ non-singular for any $t_1$\n$\\mathcal{R}[t_0,t_1]=\\mathfrak{R}(W_\\mathcal{R}(t_0,t_1))$ if $x_1=W_\\mathcal{R}(t_0,t_1)\\eta_1\\in\\mathfrak{R}(W_\\mathcal{R}(t_0,t_1))$, the control $u(t)=B^\\top(t)\\Phi^T(t_1,t)\\eta_1$,$t\\in[t_0,t_1]$ can be used to transfer the system from $x(t_0)=0$ to $x(t_1)=x_1$ (w/ minimum energy) minimum energy = minimum $\\int^T_0\\Vert u(\\tau)\\Vert^2\\mathrm{d}\\tau$\nFor LTI system $W_\\mathcal{R}(t_0,t_1)=\\int^{t_1}_ {t_ 0}e^{A(t_1-\\tau)}BB^\\top e^{A^{\\top} (t_1-\\tau)}\\mathrm{d}\\tau=\\int^{t_1-t_ 0}_ {0}e^{At}BB^\\top e^{A^{\\top}t}$ Controllability Grammian: $W_\\mathcal{C}(t_0, t_1)\\equiv\\int^{t_1}_{t_0}\\Phi(t_0,\\tau)B(\\tau)B(\\tau)^\\top\\Phi^\\top(t_0,\\tau)\\mathrm{d}\\tau$ given times $t_1\u0026gt;t_0\\geqslant0$\nThe system is reachable at time $t_0$ iff $\\exists t_1$ s.t. $W_\\mathcal{C}(t_0,t_1)$ is non-singular.\n$\\mathcal{C}[t_0,t_1]=\\mathfrak{R}(W_\\mathcal{C}(t_0,t_1))$\nif $x_0=W_\\mathcal{C}(t_0,t_1)\\eta_0\\in\\mathfrak{R}(W_\\mathcal{C}(t_0,t_1))$, control $u(t)=-B^\\top(t)\\Phi^\\top(t_0,t)\\eta_0$,$t\\in[t_0,t_1]$ can be used to transfer the state from $x(t_0)=x_0$ to $x(t_1)=0$ (w/ minimum energy)\nFor LTI system $W_\\mathcal{C}(t_0,t_1)=\\int^{t_1}_ {t_ 0}e^{A(t_0-\\tau)}BB^\\top e^{A^{\\top} (t_0-\\tau)}\\mathrm{d}\\tau=\\int^{t_1-t_ 0}_ {0}e^{-At}BB^\\top e^{-A^{\\top}t}$\nControllability Matrix: For LTI system, controllability matrix $\\mathcal{C}=[B\\;|\\;AB\\;|\\;A^2B\\;\\cdots\\;A^{n-1}B]$\nThe controllability matrix works for both continuous and discrete system, and it\u0026rsquo;s easier to be derived from discrete LTI equations: In discrete LTI, $\\mathcal{C}\\mathbf{u}=-A^k x_0$ where $\\mathbf{u}=\\begin{bmatrix}u_{k-1} \u0026amp; u_{k-2} \u0026amp; \\ldots \u0026amp; u_0\\end{bmatrix}^\\top$\nFor LTI, $\\mathcal{R}[t_0,t_1]=\\mathfrak{R}(W_\\mathcal{R}[t_0,t_1])=\\mathfrak{R}(\\mathcal{C})=\\mathfrak{R}(W_\\mathcal{C}[t_0,t_1])=\\mathcal{C}[t_0,t_1]$ This implies Controllability $\\Leftrightarrow$ Reachability for LTI systems.\nThe controllable subspace $\\mathfrak{\\mathcal{C}}$ is the smallest A-invariant subspace that contains $\\mathfrak{\\mathcal{B}}$ If the controllability matrix has full rank, the LTI system (or the pair $(A,B)$) is completely controllable PBH-Eigenvector Test: An LTI system is not controllable iff there exists a nonzero left eigenvector $v$ of $A$ such that $vB=0$\nPBH-Rank Test: An LTI system will be controllable iff $[\\lambda I-A \\;| \\;B]$ has full row rank for all eigenvalue $\\lambda$\nFor LTI system, there exists an input $u(\\cdot)$ that transfer the state from $x_0$ ito $x_1$ in finite time $T$ iff $x_1-e^{AT}x_0\\in\\mathfrak{R}(\\mathcal{C})$\nThe input that transfers any state $x_0$ to any other state $x_1$ in some finite time $T$ is $u(t)=B^\\top e^{A^{\\top}(T-t)}W_\\mathcal{R}^{-1}(0,T)[x_1 -e^{AT}x_0]$, for $t\\in[0,T]$ (w/ minimum energy) Observability Observability: Given any input $u(t)$ and output $y(t)$ over $t\\in[t_0,t_1]$, it\u0026rsquo;s sufficient to determine a unique initial state $\\exists !x(t_0)$.\nObservability Grammian: $W_\\mathcal{O}(t_0,t_1)\\equiv\\int^{t_1}_{t_0}\\Phi^\\top(t_1,\\tau)C^\\top(\\tau)C(\\tau)\\Phi(t_1,\\tau)\\mathrm{d}\\tau$\nThe system is observable at time $t_0$ iff $\\exists t_1$ s.t. $W_{\\mathcal{O}}(0,t)$ is nonsingular.\nFor LTI system $W_{\\mathcal{O}}(t_0,t_1)=\\int^{t_1}_{t_0} e^{A^{\\top}(t_1-\\tau)}C^\\top Ce^{A(t_1-\\tau)}\\mathrm{d}\\tau=\\int^{t_1-t_0}_0 e^{A^{\\top}\\tau}C^\\top Ce^{A\\tau}\\mathrm{d}\\tau$\nObservability Matrix: For LTI system, observability $\\mathcal{O}=\\begin{bmatrix}C\\\\CA\\\\CA^2\\\\ \\vdots\\\\CA^{k-1}\\end{bmatrix}$\nThe controllability matrix works for both continuous and discrete system, and it\u0026rsquo;s easier to be derived from discrete LTI equations: In discrete LTI, $\\Psi_{k-1}=\\mathcal{O}x_0$ where $$\\Psi_k\\equiv\\begin{bmatrix}y_0\\\\y_1\\\\y_2\\\\ \\vdots\\\\ y_{k-1}\\end{bmatrix}-\\begin{bmatrix} D \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ CB \u0026amp; D \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \\\\ CAB \u0026amp; CB \u0026amp; D \u0026amp; \\cdots \u0026amp; 0 \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ CA^{k-2}B \u0026amp; CA^{k-3}B \u0026amp; CA^{k-4}B \u0026amp; \\cdots \u0026amp; 0 \\end{bmatrix}\\begin{bmatrix}u_0\\\\u_1\\\\u_2\\\\ \\vdots \\\\ u_{k-1}\\end{bmatrix}$$\nIf the controllability matrix has full rank, the LTI system (or the pair $(A,C)$) is completely observable. PBH-Rank Test: An LTI system will be observable iff $\\begin{bmatrix}A-\\lambda I \\\\C\\end{bmatrix}$ has full column rank for all eigenvalue $\\lambda$\nDuality Duality Theorem: The pair $(A,B)$ is controllable iff the pair $(A^\\top, B^\\top)$ is observable. Controllability only depends on matrix $A$ and $B$ while the Observability only depends on matrix $A$ and $C$ Duality theorem is useful for proof of observability conclusions from controllability Adjoint System: Original System Adjoint System Equations $$\\begin{align*} \\dot{x}\u0026=A(t)x+B(t)u \\\\ y\u0026=C(t)x \\end{align*}$$$$\\begin{align*} \\dot{p}\u0026=-A^*(t)p-C^*(t)v \\\\ z\u0026=B^*(t)p\\end{align*}$$ Initial Condition$x(t_0)=x_0$$p(t_1)=p_1$ State Trasition Matrix $\\Phi(t,t_0)$ $\\Phi^*(t_1,t)=\\left(\\Phi^*(t,t_1)\\right)^{-1}$ Zero-State Response $$\\begin{split}L_u:\\;\u0026u(\\cdot)\\to x(t_1)\\\\=\u0026\\int^{t_1}_{t_0}\\Phi(t_1,\\tau)B(\\tau)u(\\tau)\\mathrm{d}\\tau\\end{split}$$$$\\begin{split}P_u:\\;\u0026v(\\cdot)\\to p(t_0)\\\\=\u0026\\int^{t_1}_{t_0}\\Phi^*(\\tau,t_0)C^*(\\tau)v(\\tau)\\mathrm{d}\\tau\\end{split}$$ Zero-Input Response $$\\begin{split}L_0:\\;\u0026x_0\\to y(\\cdot)\\\\=\u0026C(\\cdot)\\Phi(\\cdot,t_0)x_0\\end{split}$$ $$\\begin{split}P_0:\\;\u0026p_1\\to z(\\cdot)\\\\=\u0026B^*(\\cdot)\\Phi^*(t_1,\\cdot)p_1\\end{split}$$ Duality Theorem Controllable ($\\rho(L_u)=n$) Observable ($\\rho(P_0^*)=n$) Observable ($\\rho(L_0^*)=n$) Controllable ($\\rho(P_u)=n$) A state is reachable ($x\\in\\mathfrak{R}(L_u)$) A state is unobservable ($x\\in\\mathfrak{N}(L_0)$) Note that ZIR and ZSR are both linear mappings and $L_u^*=P_0,\\;L_0^*=P_u$ Decomposition and Realizations Similarity Transform of a (LTI) system: Based on Eq.3 and Eq.4, define $x=P\\bar{x}$, then we have $$\\begin{align}\\dot{\\bar{x}}\u0026amp;=P^{-1}AP\\bar{x}+P^{-1}Bu\u0026amp;=\\bar{A}\\bar{x}+\\bar{B}u \\\\ y\u0026amp;=CP\\bar{x}+Du\u0026amp;=\\bar{C}\\bar{x}+Du\\end{align}$$\nSimilarity transform doesn\u0026rsquo;t affect transfer function. Controllability Decomposition: For an uncontrollable LTI system, define matrix $V=[V_1\\;V_2]$ where $V_1$ is a basis for $\\mathfrak{R}(\\mathcal{C})$ and $V_2$ complete a basis for $\\mathbb{R}^n$, then after similarity transform with $\\bar{x}=V^{-1}x$, we can partition the system like following: $$\\begin{align*}\\dot{\\bar{x}}\u0026amp;=\\bar{A}\\bar{x}+\\bar{B}u\u0026amp;=\u0026amp;\\begin{bmatrix}\\bar{A}_ {11}\u0026amp;\\bar{A}_ {12} \\\\ \\mathbf{0} \u0026amp; \\bar{A} _{22}\\end{bmatrix}\\begin{bmatrix}\\bar{x} _1 \\\\ \\bar{x} _2\\end{bmatrix}+\\begin{bmatrix}\\bar{B} _1 \\\\ \\mathbf{0}\\end{bmatrix}u \\\\ y\u0026amp;=\\bar{C}\\bar{x}+Du\u0026amp;=\u0026amp; \\begin{bmatrix}\\bar{C} _1 \u0026amp; \\bar{C} _2\\end{bmatrix}\\begin{bmatrix}\\bar{x} _1 \\\\ \\bar{x} _2\\end{bmatrix} + Du\\end{align*}$$ Here $\\bar{x}_2$ is uncontrollable, and ZSR of the system with or without $\\bar{x}_2$ is the same.\nObservability Decomposition: For an unobservable LTI system, define matrix $U=\\begin{bmatrix}U_1\\\\U_2\\end{bmatrix}$ where $U_1$ is a basis for $\\mathfrak{R}(\\mathcal{O}^\\top)$ and $U_2$ complete a basis for $\\mathbb{R}^n$, then after similarity transform with $\\hat{x}=Ux$, we can partition the system like following: $$\\begin{align*}\\dot{\\hat{x}}\u0026amp;=\\hat{A}\\hat{x}+\\hat{B}u\u0026amp;=\u0026amp;\\begin{bmatrix}\\hat{A}_ {11}\u0026amp;\\mathbf{0} \\\\ \\hat{A}_ {21} \u0026amp; \\hat{A} _{22}\\end{bmatrix}\\begin{bmatrix}\\hat{x} _1 \\\\ \\hat{x} _2\\end{bmatrix}+\\begin{bmatrix}\\hat{B} _1 \\\\ \\hat{B} _2\\end{bmatrix}u \\\\ y\u0026amp;=\\hat{C}\\hat{x}+Du\u0026amp;=\u0026amp; \\begin{bmatrix}\\hat{C} _1 \u0026amp; \\mathbf{0}\\end{bmatrix}\\begin{bmatrix}\\hat{x} _1 \\\\ \\hat{x} _2\\end{bmatrix} + Du\\end{align*}$$\nRealization: $\\Sigma$ (system with Eq.3 and Eq.4) is a realization of $H(s)$ iff $H(s)=C(sI-A)^{-1}B+D$.\nEquivalent: Two realizations are said to be equivalent if they have the same transfer function Algebraically Equivalent: Two realizations have same transfer function and $n$ (dimension of states). (this implies a similarity transform between them) Minimal Realization: $\\Sigma$ is a minimal realization of $H(s)$ iff there doesn\u0026rsquo;t exists an equivalent realization $\\bar{\\Sigma}$ with $\\bar{n}\u0026lt; n$ $\\Sigma$ is a minial realization iff $\\Sigma$ is completely controllable and observable.\nKalman Cannonical Structure Theorem (aka. Kalman Decomposition): suppose $\\rho(\\mathcal{C})\u0026lt; n$ and $\\rho(\\mathcal{O})\u0026lt; n$, $\\mathfrak{R}(\\mathcal{C})$ are the controllable states, $\\mathfrak{N}(\\mathcal{O})$ are the unobservable states, define subspaces:\nSubspaces Controllable Observable $V_2\\equiv\\mathfrak{R}(\\mathcal{C})\\cup\\mathfrak{N}(\\mathcal{O})$ Yes No $V_1$ s.t. $V_1\\oplus V_2=\\mathfrak{R}(\\mathcal{C})$ Yes Yes $V_4$ s.t. $V_4\\oplus V_2=\\mathfrak{N}(\\mathcal{O})$ No No $V_3$ s.t. $V_1\\oplus V_2\\oplus V_3\\oplus V_4=\\mathbb{C}^n$ No Yes Then let $$\\begin{align*}\\tilde{x}=\\begin{bmatrix}\\tilde{x}_ 1\\\\ \\tilde{x}_ 2\\\\ \\tilde{x}_ 3\\\\ \\tilde{x}_ 4\\end{bmatrix},\\;\\tilde{A}=\u0026amp;\\begin{bmatrix}A_ {\\mathrm{co}} \u0026amp;\u0026amp;A_{13}\u0026amp;\\\\A_{21}\u0026amp;A_{\\mathrm{c\\bar{o}}}\u0026amp;A_{23}\u0026amp;A_{24}\\\\\u0026amp;\u0026amp;A_{\\mathrm{\\bar{c}o}}\u0026amp;\\\\\u0026amp;\u0026amp;A_{43}\u0026amp;A_{\\mathrm{\\bar{c}\\bar{o}}} \\end{bmatrix},\\;\\tilde{B}=\\begin{bmatrix}B_{\\mathrm{co}}\\\\ B_{\\mathrm{c\\bar{o}}} \\\\ \\mathbf{0} \\\\ \\mathbf{0} \\end{bmatrix} \\\\ \\tilde{C}=\u0026amp;\\begin{bmatrix}C_{\\mathrm{co}}\u0026amp;\\mathbf{0}\\quad\u0026amp;C_{\\mathrm{\\bar{c}o}}\u0026amp;\\mathbf{0}\\quad\\end{bmatrix}\\end{align*}$$ $$\\tilde{\\Sigma}:\\begin{cases} \\dot{\\tilde{x}}=A_{\\mathrm{co}}\\tilde{x}_ 1+B_{\\mathrm{co}}u_1\\\\ y=C_{\\mathrm{co}}\\tilde{x}_1\\end{cases}$$ $\\tilde{\\Sigma}$ is completely controllable and completely observable.\nConsider SISO systems $$H(s)=\\frac{b(s)}{a(s)}=\\frac{b_{n-1}s^{n-1}+\\ldots+b_1s+b_0}{s^n+a_{n-1}s^{n-1}+\\ldots+a_1s+a_0}=\\frac{\\sum^{n-1}_{j=0} b_js^j}{s^n+\\sum^{n-1}_{i=0} a_is^i}=\\frac{Y(s)}{U(s)}$$ Controllable Cannonical Form: $$\\begin{align}\\dot{x}\u0026amp;=\\begin{bmatrix} 0\u0026amp;1\u0026amp;\u0026amp;\\\\ \\vdots \u0026amp; \u0026amp; \\ddots \u0026amp; \\\\ 0\u0026amp;\u0026amp;\u0026amp;1 \\\\-a_0\u0026amp;-a_1\u0026amp;\\cdots\u0026amp;-a_{n-1}\\end{bmatrix}x+\\begin{bmatrix}0\\\\ \\vdots \\\\ 0 \\\\ 1\\end{bmatrix}u\u0026amp;=\u0026amp;A_cx+B_cu\\\\ y\u0026amp;=\\begin{bmatrix}\\quad b_0 \u0026amp;\\quad b_1 \u0026amp;\\cdots \u0026amp; \\quad b_{n-1}\\end{bmatrix}x\u0026amp;=\u0026amp;C_cx \\end{align}$$ $(A_c, B_c)$ is controllable $(A_c, C_c)$ is observable if $a(s)$ and $b(s)$ have no common factors Observable Cannonical Form: $$\\begin{align}\\dot{x}\u0026amp;=\\begin{bmatrix} 0\u0026amp;\u0026amp;\u0026amp;\u0026amp;-a_0\\\\ 1 \u0026amp; \\ddots \u0026amp;\u0026amp;\u0026amp;-a_1 \u0026amp; \\\\ \u0026amp;\\ddots\u0026amp;\\ddots\u0026amp;\u0026amp;\\vdots \\\\\u0026amp;\u0026amp;\\ddots\u0026amp;0\u0026amp;-a_{n-2} \\\\ \u0026amp;\u0026amp;\u0026amp;1\u0026amp;-a_{n-1}\\end{bmatrix}x+\\begin{bmatrix}b_0\\\\ b_1 \\\\ \\vdots \\\\ b_{n-2} \\\\ b_{n-1}\\end{bmatrix}u\u0026amp;=\u0026amp;A_ox+B_ou\\\\ y\u0026amp;=\\begin{bmatrix}0 \u0026amp; \\;\\cdots \u0026amp;\\;\\cdots \u0026amp; 0 \u0026amp; \\quad 1\\qquad \\end{bmatrix}x\u0026amp;=\u0026amp;C_ox \\end{align}$$ $(A_o, C_o)$ is observable $(A_o, B_o)$ is controllable if $a(s)$ and $b(s)$ have no common factors Model Cannonical Forms: Do Spectral Decomposition (eigen-decomposition) or Jordan Decomposition, and then use the modal matrix (matrix of eigenvectors) to do similarity transform. The Gilbert Realization: Let $G(s)$ be a $p\\times m$ rational transfer function with simple poles (nonrepeated) at $\\lambda_i,\\;i=1,2,\\ldots,k$. Calculate partial fraction expansion $$G(s)=\\sum^k_{i=1}\\frac{R_i}{s-\\lambda_i},\\qquad \\text{Residue}\\;R_i=\\lim_{s\\to\\lambda_i}(s-\\lambda_i)G(s)$$ Let $r_i=\\rho(R_i)$, now write $R_i=C_iB_i$ where $C_ i\\in\\mathbb{R}^ {p\\times r_ i},\\;B_ i\\in\\mathbb{R}^ {r_ i\\times p}$, then write $$A=\\mathrm{blkdiag}\\{\\lambda_i I_{r_i}\\},\\;B^\\top=[B_1^\\top \\;\\cdots\\; B^\\top_k],\\;C=[C_1\\; \\cdots\\;C_k]$$, then $(A,B,C)$ is a realization of $G(s)$ with order $n=\\sum^k_1 r_i$ For MIMO system the cannonical forms with be quite complex:\nControllable Cannonical Form (for MIMO): Here we provide a way to convert from controllable LTI system to controllable. The collection of independent columns of $\\mathcal{C}$ may be expressed as $$M=[b_1\\;Ab_1\\; \\cdots\\;A^{\\mu_1-1}b_1\\;|\\;b_2\\;Ab_2\\;\\cdots\\;A^{\\mu_2-1}b_2\\;|\\;\\cdots\\;|\\;b_p\\;Ab_p\\;\\cdots\\;A^{\\mu_p-1}b_p]$$ Construct $M^{-1}$ and then $T$:$$M^{-1}=\\left[m_{11}^\\top\\;m_{12}^\\top\\;\\cdots\\;m_{1\\mu_1}^\\top\\;\\middle|\\;\\cdots\\;\\middle|\\;m_{p1}^\\top\\;m_{p2}^\\top\\;\\cdots\\;m_{p\\mu_p}^\\top \\right]^\\top$$ $$T=\\left[m_{1\\mu_1}^\\top\\;(m_{1\\mu_1}A)^\\top\\;\\cdots\\;\\left(m_{1\\mu_1}A^{\\mu_1-1}\\right)^\\top\\;\\middle|\\;\\cdots\\;\\middle|\\; m_{p\\mu_p}^\\top\\;(m_{p\\mu_p}A)^\\top\\;\\cdots\\;\\left(m_{p\\mu_p}A^{\\mu_p-1}\\right)^\\top\\right]^\\top$$ Perform similarity transform with $\\bar{x}=Tx$ and the canonical form will be obtained like following: $$\\bar{A}=\\begin{bmatrix}\\bar{A}_ {\\mu_1\\times\\mu_1}\u0026amp;\\mathbf{0}_ {\\cdot\\cdot}\u0026amp;\\cdots\u0026amp;\\mathbf{0}_ {\\cdot\\cdot} \\\\ \\mathbf{0}_ {\\cdot\\cdot}\u0026amp;\\bar{A}_ {\\mu_2\\times\\mu_2}\u0026amp;\\cdots\u0026amp;\\mathbf{0}_ {\\cdot\\cdot}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots \\\\ \\mathbf{0}_ {\\cdot\\cdot}\u0026amp;\\mathbf{0}_ {\\cdot\\cdot}\u0026amp;\\cdots\u0026amp;\\bar{A}_ {\\mu_ p\\times\\mu_ p} \\end{bmatrix},\\quad\\bar{B}=\\begin{bmatrix}\\mathbf{0}_ {\\cdot n}\\\\ \\mathbf{0}_ {\\cdot (n-1)}\\\\ \\vdots\\\\ \\mathbf{0}_ {\\cdot 1}\\end{bmatrix}$$ Here $\\bar{A}_ {\\mu_ i\\times\\mu_ i}$ is the same structure as in SISO, $\\mathbf{0}_ {\\cdot\\cdot}$ is a zero matrix except the last row, $\\mathbf{0}_ {\\cdot i}$ is a zero matrix except for the last row, and in the last row there are $i$ non-zeros on the right with the first element being 1. System Performance System Characteristic Equation: The polynomical with the roots equal to the poles of the output that are independent of the input.\nSystem Type: A plant $G$ can always be written as $G(s)=\\frac{K\\prod^m_{i=1}(s-s_i)}{s^N\\prod^p_{j=1}(s-s_j)},\\;z_i,z_j\\neq 0$ or $G(z)=\\frac{K\\prod^m_{i=1}(z-z_i)}{(z-1)^N\\prod^p_{j=1}(z-z_j)},\\;z_i,z_j\\neq 1$. Here $N$ is called the system type of $G(z)$.\nProperties that matters for a controller:\nStability Steady state accuracy Transient response Sensitivity Exogenous disturbance rejection Bounded control effort Stability Stability means when the time goes to infinity, the system response is bounded. A system is stable if all its poles lies in the left half of $s$-plane or all inside the unit circle of $z$-plane. A system is marginally stable if one of the pole is on the imaginary axis of $s$-plane or on the unit circle of $z$-plane. Stability of linear systems is independent of input The stability of a linear system can be evaluated by its characteristic equation $1-G_{op}(z)=0$, where $G_{op}$ is the open-loop transfer function (transfer function when input is eliminated, or feedback route is cut off). Methods to evaluate stability Routh-Hurwitz Criterion: $s$-plane (omited here, see Wikipedia) For discrete system, a strategy is use bilinear transformation: $z=e^{\\omega T}\\approx \\frac{1+\\omega T/2}{1-\\omega T/2}$ Jury Criterion: $z$-plane (see Wikipedia) Root Locus Method: both $s$- and $z$-plane (see Wikipedia, rlocus in MATLAB) Nyquist Criterion: both $s$- and $z$-plane (see Wikipedia, nyquist in MATLAB) It works for both continuous and discrete systems, the difference is that in $s$-plane the detour point is at $s=0$ while in $z$-plane the detour point is at $z=1$. Bode Diagrams: draw frequency response for (pulse) transfer function, works for both $s$- and $z$-plane (see Wikipedia, bode in MATLAB) A review of the stability judgement method here at 知乎\nLyaponov Stability Lyaponove Stability is only concerned with the effect of initial conditions on the response of the system (ZIR)\nEquilibrium Point $x_e$: Consider NLTV $\\dot{x}(t)=f(x(t),u(t),t)$, equilibrium point satisfies $x(t_0)=x_e,\\;u(t)\\equiv 0\\Rightarrow x(t)=x_e,\\;\\text{i.e. }f(x_e,0,t)=0,\\;\\forall t\u0026gt;t_0$ For discrete system, it\u0026rsquo;s $x(k+1)=x(k)=x_e$ For LTI system, $x_e$ can be calculated from $Ax_e=0$, so the origin $x=0$ is always an equilibrium point. Set of equilibrium points in LTI systems are connected. Lyapunov stability: An equilibrium point $x_e$ of the system $\\dot{x}=A(t)x$ is stable (in the sense of Lyapunov) iff $\\forall \\epsilon\u0026gt;0,\\;\\exists \\delta(t_0,\\epsilon)\u0026gt;0$ s.t. $\\Vert x(t_0)-x_e\\Vert\u0026lt;\\delta\\Rightarrow\\Vert x(t)-x_e\\Vert \u0026lt;\\epsilon,\\;\\forall t\u0026gt;t_0$ $x_e$ is uniformly stable if $\\delta=\\delta(\\epsilon)$ (regardless of $t_0$) $x_e$ in LTI is stable $\\Rightarrow x_e$ is uniformly stable $x_e$ is asymptotically stable if $\\Vert x(t)-x_e\\Vert\\to 0$ as $t\\to 0$ $x_e$ is exponentially stable if $\\Vert x(t)-x_e\\Vert \\leqslant \\gamma e^{-\\lambda(t-t_0)}\\Vert x(t_0)-x(e)\\Vert$ $x_e$ in LTI is asymptotically stable $\\Rightarrow x_e$ is exponentially stable $x_e$ is globally stable if $\\delta$ can be chosen arbitrarily large For LTV system, the system is stable (the zero solution is stable) iff $\\Phi(t,t_0)$ is bounded by $K(t_0)$. If bounded by constant $K$, then the system is uniformly stable. If bounded by constant $K$ and $\\Vert\\Phi(t,0)\\Vert\\to 0$ as $t\\to 0$, then the system is asymptotically stable. For LTI system $\\dot{x}=Ax$, it is Lyapunov stable iff $\\mathrm{Re}(\\lambda_i)\\leqslant 0$ or $\\mathrm{Re}(\\lambda_i)=0,\\;\\eta_i=1$. ($\\eta_i$ is the multiplicity of $\\lambda_i$) If $\\mathrm{Re}(\\lambda_i)\u0026lt;0$, then the system is asymptotically stable Internal stability: concerns the state variables External stability: concerns the output variables Notes for contents below:\nPositive definite (pd.) function: function $V$ is pd. wrt. $p$ if $V(x)\u0026gt;0,\\;x\\neq p$ and $V(x)=0,\\;x=p$ $C^n$ denotes the set of continuous and at least n-th differentiable functions Lyapunov\u0026rsquo;s Direct Method: Let $\\mathcal{U}$ be an open neighborhood of $p$ and let $V:\\mathcal{U}-\u0026gt;\\mathbb{R}$ be a countinuous positive definite $C^1$ function wrt. $p$, we have following two conclusions:\nIf $\\dot{V}\\leqslant 0$ on $\\mathcal{U}\\backslash\\{p\\}$ then $p$ is a stable fixed point of $\\dot{x}=f(x)$ If $\\dot{V}\u0026lt; 0$ on $\\mathcal{U}\\backslash\\{p\\}$ then $p$ is an asymptotically stable fixed point of $\\dot{x}=f(x)$ Lyapunov Function:\nA function satisfying conclusion 1 is called a Lyapunov function A function satisfying conclusion 2 is called a strict Lyapunov function A function that is $C^1$ and pd. is called a Lyapunov function candidate The energy function usually can be used as Lyapunov function. If it\u0026rsquo;s only semi-positive definite, one can use LaSalle\u0026rsquo;s Theorem\nFor LTI system, the zero solution of $\\dot{x}=Ax$ is asymptotically stable iff $\\forall$ pd. hermitian matrices $Q$, equation $A^*P+PA=-Q$ has a unique hermitian solution $P$ that is positive definite.\n$A^*P+PA=-Q$ is called Lyapunov\u0026rsquo;s Matrix Equation here $V(x)=x^* Px=\\int^\\infty_0 x^*(t)Qx(t)dt$, which can be also called cost-to-go, or generalized energy\nLyapunov\u0026rsquo;s Indirect Method (Lyapunov\u0026rsquo;s First Method / Lyapunov\u0026rsquo;s Linearization Theorem): The nonlinear system $\\dot{x}=f(x)$ is (locally) asymptotically stable near the equilibrium point $x_e$ if the linearized system $\\dot{x}_L=\\frac{\\partial f}{\\partial x}(x_e)x_L$ is asymptotically stable.\nBounded-Input Bounded-Output Stability BIBO stability is only concerned with the response of the system to the input (ZSR).\nBounded-Input Bounded-Output (BIBO) stability: The LTV system is said to be (uniformly) BIBO stable if there exists a finite constant $g$ s.t. $\\forall u(\\cdot)$, its forced response $y_f(\\cdot)$ satisfies $$ \\sup_{t\\in[0,\\infty)}\\Vert y_f(t)\\Vert \\leqslant g \\sup_{t\\in[0,\\infty)} \\Vert u(t)\\Vert $$ The impulse response can be analyzed to assess BIBO stability The LTV system is uniformly BIBO stable iff every entry of $D(t)$ is bounded and $\\sup_{t\\geqslant 0}\\int^t_0|g_{ij}(t,\\tau)|d\\tau \u0026lt;\\infty$ for every entry $g_{ij}$ of the matrix $C(t)\\Phi(t,\\tau)B(\\tau)$.\nBIBO stability is related with the stability descibed in classical control theory. Exponential Lyapunov Stability $\\Rightarrow$ BIBO stability Steady State Accuracy Steady state accurary can be derived from the property of Laplace/Z-transform as mentioned above (assuming stability) $$\\lim\\limits_{t\\to \\infty} f(t) = \\lim\\limits_{z\\to 1} (z-1)F(z) = \\lim\\limits_{s\\to 0}sF(s)$$\nTransient Response Some measurements of transient response (with step input):\nRise time $t_r$: time from 10% to 90% of steady state value Peak overshoot: $M_p$ for overshoot magnitude and $t_p$ for time Settling time $t_s$: time after which the magnitude fall in $1-d$ to $1-d$ final value. $d$ is usually %2~5. Sensitivity Given a transfer function $H(z)$ with parameter $\\Theta\\in\\mathbb{R}$, then sensitivity is defined as $S_H=\\frac{\\partial H}{\\partial \\Theta}\\cdot\\frac{\\Theta}{H} = \\frac{\\partial H/H}{\\partial \\Theta/\\Theta}$\nDiscretization and Linearization Discretization Example The following image shows a minial example of sampling and hold. Sampling (A/D) Ideal sampler (a.k.a impulse modulator) converts a continuous signal $e: \\mathbb{R}_+ \\to \\mathbb{R}$ to a discrete one $\\hat{e}: \\mathbb{N}\\to \\mathbb{R}$, such that $$ \\hat{e}=e(t)\\delta(t-kT)=e(t)\\delta_T(t); \\forall k\\in \\mathbb{N} $$ Ideal sampler is actually applying starred transform. How to sample? A rule of thumb used to select sampling rates is chosing a rate of at least 5 samples per time constant. The $\\tau$ appearing in the transient response term $ke^{-t/\\tau}$ of a first order analog system is called the time constant. If the sampling time is too large, it can make the system unstable. Reconstruction/Hold (D/A) Zero order hold (ZOH): $ZOH(\\{e(k)\\}_{k\\in\\mathbb{N}})(t) = e(k)\\;for\\;kT\\leq t\\leq (k+1)T$ Alternative form: $ZOH(\\{e(k)\\})=\\sum^\\infty_{k=0}e(k)(H(t-kT)-H(t-(k+1)T))$ Its Laplace Transform: $G_{ZOH}(s)=\\frac{1-e^{-Ts}}{s}$ First order hold (FOH): (delayed version) $$FOH(\\{e(k)\\}_ {k\\in\\mathbb{N}})(t)=\\sum_ {k\\in\\mathbb{N}}\\left[e(kT)+\\frac{t-kT}{T}(e(kT)-e((k-1)T)) \\right]\\left[H(t-kT)-H(t-(k+1)T) \\right]$$ State Space Representation Suppose we are given the LTI continuous system $$\\begin{align*} \\dot{x}(t) \u0026amp;= Ax(t)+Bu(t) \\\\ y(t)\u0026amp;=Cx(t)+Du(t) \\end{align*}$$ If the input is sampled and ZOH and the output is sampled, then $$\\begin{align*} x(k+1)\u0026amp;=\\bar{A}x(k)+\\bar{B}u(k) \\\\ y(k)\u0026amp;=\\bar{C}x(k)+\\bar{D}u(k)\\end{align*}$$ where $\\bar{A}=\\Phi((k+1)T,kT)=e^{AkT}$ $\\bar{B}=\\int^{(k+1)T}_{kT}\\Phi((k+1)T,\\tau)B\\mathrm{d}\\tau=A^{-1}(e^{AT}-I)$ $\\bar{C}=C$ and $\\bar{D}=D$\nSteps to apply conversion:\nDervice SS model for analog system Calculate discrete representation (c2d in MATLAB) Calculate pulse transfer function (ss2tf in MATLAB) If there is a complex system with multiple sampling and holding, a general rule is Each ZOH output is assumed to be an input Each sampler input is assumed to be an output and then create continuous state space from analog part of the system, then discretize them to generate discrete equations $s$-plane and $z$-plane When converting $s$ to $z$, the complex variables are related by $z=e^{Ts}$. Suppose $s=\\sigma+j\\omega$, then $z=e^{T\\sigma}\\angle \\omega T$\nNote: if frequencies differ in integer multiples of the sampling frequency $\\frac{2\\pi}{T}=\\omega_s$, then they are sampled into the same location in the $z$-plane.\nFor transient response relationship, suppose $s$-plane poles occur at $s=\\sigma\\pm j\\omega$, then the transient response if $Ae^{\\sigma t}\\cos(\\omega t+\\varphi)$. When sampling occurs at $z$-plane poles, then the transient response if $Ae^{\\sigma kT}\\cos(\\omega kT+\\varphi)$.\nExample: 2nd order transfer function $$G(s)=\\frac{\\omega_n^2}{s^2+2\\xi\\omega_ns+\\omega_n^2}$$ The $z$-plane poles occur at $z=r\\angle\\pm\\theta$ where $r=e^{-\\xi\\omega_n T}$ and $\\theta=\\omega_n T\\sqrt{1-\\xi^2}$. Then we can get the inverse relationship\n$\\xi=-\\ln( r)/\\sqrt{\\ln^2( r)+\\theta^2}$ $\\omega_n=(1/T)\\sqrt{\\ln^2( r)+\\theta^2}$ (time constant) $\\tau=-T/\\ln( r)$ Linearization Jacobian Linearization: linearize $\\dot{x}=f(x,u)$ at an equilibrium $(x_e, u_e)$ is $$\\frac{\\mathrm{d}z}{\\mathrm{d}t}=Az+Bv,\\quad\\text{where}\\;A=\\left.\\frac{\\mathrm{d}f}{\\mathrm{d}x}\\right|_ {\\begin{split}x=x_e\\\\u=u_e\\end{split}},\\;B=\\left.\\frac{\\mathrm{d}f}{\\mathrm{d}u}\\right|_ {\\begin{split}x=x_e\\\\u=u_e\\end{split}},\\;z=(x-x_e),\\;v=(u-u_e)$$ change $(x_e, u_e)$ to a trajectory $(x_e(t), u_e(t))$ we can linearize the system about a trajectory. Controllers Full State Feedback This method can be used for both continuous and discrete systems, just make sure to use corresponding method for choosing correct closed-loop transfer function.\nFor state space systems, with access to all of the state variables, we can change the $A$ matrix and thereby change the system dynamics by feedback.\nConsider SISO LTI system ($u\\in\\mathbb{R},y\\in\\mathbb{R}$), we define the input as $u\\equiv Kx+Ev$ where $K\\in\\mathbb{R}^{1\\times n},\\;E\\in\\mathbb{R}$ is an input matrix and $v(t)\\in\\mathbb{R}^\\mathbb{R}$ is the exogeneous (externally applied) input. The new system will be $$\\begin{align}\\dot{x}\u0026amp;=(A+BK)x+BEv\\\\y\u0026amp;=(C+DK)x+DEv\\end{align}$$ The mission is to find a state update matrix $A_{\\mathrm{CL}}\\equiv A+BK$ with desired set of eigenvalues, therefore we can construct $A_{\\mathrm{CL}}$ with specific eigenvalues and then calculate $K$. This process will be quite easy if the system is already in controllable cannonical form. (which can be constructed directly from transfer function or using similarity transform)\nAnother way (SISO only) to calculate $K$ without controllable cannonical form is using the following formulae given the desired characteristic polynomial $\\phi^{\\star}(s)=s^n+\\sum^{n-1}_ {i=0} a^\\star_i s^i$ and original characteristic polynomial $\\phi(s)=s^n+\\sum^{n-1}_ {i=0} a_i s^i$\nAckermann\u0026rsquo;s Formula: $K=-e^\\top_n\\mathcal{C}^{-1}\\phi^\\star(A)$ (here $e_i$ is unit vector with 1 at i-th position) Bass-Gura\u0026rsquo;s Formula: $$K=-[(a^\\star_{n-1}-a_{n-1}) \\;\\cdots\\;(a^\\star_0-a_0)]\\begin{bmatrix}1\u0026amp;a_{n-1}\u0026amp;a_{n-2}\u0026amp;\\cdots\u0026amp;a_1\\\\\u0026amp;1\u0026amp;a_{n-1}\u0026amp;\\cdots\u0026amp;a_2\\\\ \u0026amp;\u0026amp;\\ddots\u0026amp;\\ddots\u0026amp;\\vdots \\\\ \u0026amp;\u0026amp;\u0026amp;1\u0026amp;a_{n-1}\\\\ \u0026amp;\u0026amp;\u0026amp;\u0026amp;1\\end{bmatrix}^{-1}\\mathcal{C}^{-1}$$ Note that the zeros of transfer function will not be affected by state feedback.\nState Estimation (Observer Design) Some times we don\u0026rsquo;t have the direct access to the state, we need construct an observer For stochastic version, please check my notes for stochastic system\nAssume a plant $\\Sigma$ and an (Luenberger) observer $\\hat{\\Sigma}$: $$\\Sigma:\\begin{cases}\\dot{x}=Ax+Bu\\\\ y=Cx\\end{cases},\\quad \\hat{\\Sigma}:\\begin{cases} \\dot{\\hat{x}}=A\\hat{x}+Bu+L(y-\\hat{y})\\\\ y=C\\hat{x}\\end{cases}$$\nSubtract observer dynamics from plant dynamics and define $e\\equiv x-\\hat{x}$, the dynamics for $e$ is $\\dot{e}=(A-LC)e$ and $y-\\hat{y}=Ce$. This error dynamic $A_e=A-LC$ can be easily changed with observable cannonical form. (which similarly can be constructed directly from transfer function or using similarity transform)\nReduced-order Observer: If the state length of the system $n$ is large while $n-p$ is small, split the system and let $x_1$ holds the states that can be measured directly while $x_2$ holds states that are to be estimated, (i.e. $y=x_1+Du$). Define $z=\\hat{x}_2-Lx_1$ then the system runs like $$\\begin{align*}\\begin{bmatrix}x_1 \\\\ \\hat{x}_2\\end{bmatrix}\u0026amp;=\\begin{bmatrix} y-Du\\\\ z+Lx_1 \\end{bmatrix}\\qquad\\begin{split}\u0026amp;\\text{measurement} \\\\ \u0026amp;\\text{observer}\\end{split} \\\\ u\u0026amp;=K\\begin{bmatrix}x_1 \\\\ \\hat{x}_2 \\end{bmatrix} + v \\qquad\\text{control law}\\end{align*}$$ And then the error we care about is only $e=x_2-\\hat{x}_2$. Ackermann\u0026rsquo;s Formula: $L=\\phi^\\star(A)\\mathcal{O}^{-1}e_n$ ($\\phi^\\star$ is the desired characteristic function for $A_e$) Separation Principle: If a stable observer and stable state feedback are designed for an LTI system, then the combined observer and feedback will be stable. Errors from state estimation\nInaccurate knowledge of $A$ and $B$ Initial condition uncertainty Disturbance or sensor error It\u0026rsquo;s advised to choose observer poles to be 2-4x faster than closed loop poles LQR Motivation: handle control constraints and time varying dynamics with performance metric (ideas of optimal control) Note: $x^\\top Ax$ is called a quadratic form, $x^\\top Ay$ is called a bilinear form\nA quadratic function $f(x)=x^\\top Dx+C^\\top x+c_0$ has one minimizer iff $D\\succ 0$, or multiple minimizers iff $D\\succeq 0$. (discrete finite time) Linear Quadratic Regulator (LQR): the control problem is defined as $$\\begin{align*}\\min_{u\\in\\left(\\mathbb{R}^m\\right)^{\\{0,\\ldots,N\\}}} J_{N}(u,x_0)\u0026amp;=\\frac{1}{2}\\sum^{N}_{k=0}(x^\\top(k)Q(k)x(k)+u^\\top(k)R(k)u(k)) \\\\ \\mathrm{s.t.}\\qquad x(k+1) \u0026amp;= A(k)x(k) + B(k)u(k)\\quad \\forall k\\in\\{0,\\ldots,N-1\\}\\\\ y(k)\u0026amp;=C(k)x(k)\\\\ x(0)\u0026amp;=x_0\\end{align*}$$ where $Q(k)\\succ 0$ and $R(k)\\succ 0$ Bellman\u0026rsquo;s Principle of Optimality: If a closed loop control $u^\\star$ is optimal over the interval $0\\leqslant k\\leqslant N$, it\u0026rsquo;s also optimal over any subinterval $m\\leqslant k\\leqslant N$ where $m\\in\\{0,\\ldots,N\\}$ The Minimum Principle: The optimal input to the LQR problem satisfies the following backward equations: $$\\begin{align*}u^\\star(k)\u0026amp;=-K(x)x(k) \\\\ K(k)\u0026amp;=\\left[B^\\top(k) P(k+1)B(k)+\\frac{1}{2}R(k)\\right]^{-1}B^\\top(k)P(k+1)A(k) \\\\ P(k)\u0026amp;=A^\\top(k)P(k+1)[A(k)- B(k)K(k)]+\\frac{1}{2}Q(k)\\end{align*}$$ and $P(N)=Q(N),\\;K(N)=0$. The optimal cost is $J^\\star_N=x^\\top(0)P(0)x(0)$ For infinite horizon, $K(k)$ start becoming constants. The optimal input for LQR problem (assuming the system became LTI when $N\\to\\infty$) is $u^*(k)=-Kx(k)$ where $$K=(B^\\top PB+R/2)^{-1}B^\\top PA$$ and $P\\succ 0$ is the unique solution to the discrete-time algebraic Riccati Equation: $$P=A^\\top PA-A^\\top PB\\left(B^\\top PB+R/2\\right)^{-1}B^\\top PA+Q/2$$ ","date":"2020-06-10T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2020-06/ControlSystemNotes/","title":"Notes for Control System"},{"content":"I encountered a lot of calculation of derivates and integration on matrices when I was learning linear systems and SLAM, but I haven\u0026rsquo;t learned much knowledge about them. Recently I know about the book Matrix Cookbook, which thoroughly discussed the arithmetics of matrices. Therefore, I post it here for future references.\nContents 基础内容 求导 逆 复矩阵 求解与分解 统计与概率 多元概率分布 高斯 特殊矩阵 函数与运算符 Source The book can be downloaded from a website from Technical University of Denmark. If the link failed, you can downloaded from here directly.\n","date":"2019-06-06T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2019-06/MatrixAlgebra/","title":"Matrix Algebra"},{"content":" Prerequisites: Knowledge of Elementary Calculus, Linear Algebra and Probability\nDiscrete-Time Stochastic System Stochastic Sequences Definition: Given $k\\in\\mathbb{K}\\subseteq\\mathbb{Z}$ a sequence of integers, $\\mathcal{X}(k,\\omega): (\\Omega,\\mathcal{F},\\mathbb{P})\\to(\\mathbb{R}^n,\\mathcal{F}_ \\mathcal{X},\\mathbb{P}_ \\mathcal{X})$ is a random/stochastic sequence. Uncertainties: Consider a casual system $F$ relates some scalar inputs $u(k)$ to output $x(k)$ Epistemic/Model uncertainty: $\\mathcal{X}(k,\\omega)=F(k,u(k),u(k-1),\\ldots,\\omega)$. (system is stochastic and input is deterministic). Aleatoric/Input uncertainty: $\\mathcal{X}(k,\\omega)=f(k,U(k,\\omega),u(k-1,\\omega),\\ldots)$ (system is deterministic and input is stochastic). Realization: An outcome $\\mathcal{X}(k,\\omega)=x(k)$ given $\\omega$ is called a realization of stochastic sequence $\\mathcal{X}$ Terminology and Convention $\\mathcal{X}(k,\\omega)$ is often written as $\\mathcal{X}(k)$ when there\u0026rsquo;s no ambiguity. $\\mathbb{K}=\\mathbb{Z}$ if not specified. Sequence over a set $\\mathcal{K}_1\\subseteq\\mathbb{K}$ are denoted $\\mathcal{X}(\\mathcal{K}_1)$. $\\mathcal{X}$ denotes $\\mathcal{X}(\\mathbb{K})$ if not specified. Consecutive subsequence: $$\\mathcal{X}(k:l)=\\{\\mathcal{X}(k),\\mathcal{X}(k+1),\\ldots,\\mathcal{X}(l)\\},\\;x(k:l)=\\{x(k),x(k+1),\\ldots,x(l)\\}$$ Abbreviations: SS - stochastic sequence IID - independent indentically distributed Probabilistic characterization Distribution and density: $$F_ \\mathcal{X}\\left(k:l;x(k:l)\\right)\\equiv\\mathbb{P}((\\mathcal{X}_ i(k)\\leqslant x_i(k))\\cap\\cdots\\cap(\\mathcal{X}_ i(l)\\leqslant x_ i(l)),\\;i=1\\ldots n)$$ $$f_ \\mathcal{X}\\left(k:l;x(k:l)\\right)\\equiv \\frac{\\partial^{n(l-k+1)}}{\\partial x_ 1(k)\\cdots\\partial x_ n(l)}F_ \\mathcal{X}(k:l;x(k:l))$$ Here $k:l$ actually denotes a set of consecutive integers, it can be also changed to ordinary sets $\\{k,l\\}$ or single scalar $k$. Ensemble Average: $\\mathbb{E}[\\psi(\\mathcal{X}(k))]$, doing summation over different realization at same time $k$ Mean: $\\mu_ \\mathcal{X}(k)\\equiv\\mathbb{E}[\\mathcal{X}(k)]=\\int^\\infty_{-\\infty}x(k)f_ \\mathcal{X}(k;x(k))\\mathrm{d}x(k)$ Conditional Mean: $\\mu_ \\mathcal{X}(l|k)\\equiv\\mathbb{E}[\\mathcal{X}(l)|\\mathcal{X}(k)=x(k)]$ Time Average: $\\frac{1}{2N+1}\\sum^N_{k=-N}\\psi(\\mathcal{X}(k))$, doing summation over different time k of same realization Autocorrelation: Scalar case: $r_ \\mathcal{X}(k,l)\\equiv\\mathbb{E}[\\mathcal{X}(k)\\mathcal{X}(l)]=\\int^\\infty_{-\\infty}\\int^\\infty_{-\\infty}x(k)x(l)f_ \\mathcal{X}(k,l;x(k,l))\\mathrm{d}x(k)\\mathrm{d}x(l)$ Vector case: $R_ \\mathcal{X}(k,l)\\equiv\\mathbb{E}[\\mathcal{X}(k)\\mathcal{X}^\\top(l)]$ Conditional autocorrelation: $R_ \\mathcal{X}(k,l|q)\\equiv\\mathbb{E}[\\mathcal{X}(k)\\mathcal{X}^\\top(l)|\\mathcal{X}(q)=x(q)]$ Often we denote $C_ \\mathcal{X}(k)=R_ \\mathcal{X}(k,k)$ Autocovariance: Scalar case: $\\kappa_ \\mathcal{X}(k,l)\\equiv\\mathbb{E}[(\\mathcal{X}(k)-\\mu_ \\mathcal{X}(k))(\\mathcal{X}(l)-\\mu_ \\mathcal{X}(l))]$ Vector case: $\\mathrm{K}_ \\mathcal{X}(k,l)\\equiv\\mathbb{E}[(\\mathcal{X}(k)-\\mu_ \\mathcal{X}(k))(\\mathcal{X}(l)-\\mu_ \\mathcal{X}(l))^\\top]$ Conditional autocovariance: $\\mathrm{K}_ \\mathcal{X}(k,l|q)\\equiv\\mathbb{E}[(\\mathcal{X}(k)-\\mu_ \\mathcal{X}(k|q))(\\mathcal{X}(l)-\\mu_ \\mathcal{X}(l|q))^\\top]$ Often we denote $S_ \\mathcal{X}(k|q)=\\mathrm{K}_ \\mathcal{X}(k,k|q)$ Useful conclusion: $\\mathrm{K}(a,b)=\\mathrm{K}(b,a)^T$ Normalized (autocorrelation coefficient): $\\rho_ \\mathcal{X}(k,l)\\equiv\\mathrm{K}_ \\mathcal{X}(k,l)/\\sigma^2_{\\mathcal{X}(k)}\\sigma^2_{\\mathcal{X}(l)}$ Strong Stationarity(aka. strict sense): (necessarily identically distributed over time) $$\\forall x(k:l)\\in\\mathbb{R}^{n(l-k+1)},\\;\\forall s\\in\\mathbb{Z},\\;f_ \\mathcal{X}(k:l;x(k:l))=f_ \\mathcal{X}(k+s:l+s;x(k:l))$$ Weak Stationarity(aka. wide sense): $\\forall k,l$ if $$\\mu_ \\mathcal{X}(k)=\\mu_ \\mathcal{X}(l)\\;\\text{and}\\;\\mathrm{K}_ \\mathcal{X}(k,l)=\\mathrm{K}_ \\mathcal{X}(k+s,l+s)\\equiv\\bar{\\mathrm{K}}_ \\mathcal{X}(s)$$ Weak stationarity is necessary condition for stationarity. (Equal when Gaussian distributed) Ergodicity: $\\mathcal{X}$ is called ergodic in $\\psi$ if $\\mathbb{E}[\\psi(\\mathcal{X})]$ is stationary Ensemble average is equal to Time average, that is $$ \\frac{1}{2N+1}\\sum^N_{k=-N}\\psi(\\mathcal{X}(k))\\to\\mathbb{E}[\\psi(\\mathcal{X})];\\text{as};l\\to \\infty$$ Markov Sequence Markov Sequence: A ss. $\\mathcal{X}(k)$ is called a (discrete-time) Markov sequence if $$\\begin{split}f_ \\mathcal{X}\\left(k;x(k)\\middle|\\mathcal{X}(k-1)=x(k-1),\\mathcal{X}(k-2)=x(k-2),\\ldots\\right) \\\\=f_ \\mathcal{X}(k;x(k)|\\mathcal{X}(k-1)=x(k-1))\\end{split}$$ We often make some assumption on the initial condition $\\mathcal{X}(0)$, such as known, deteministic or uniformly distributed within certain domain. Markov Chains: Markov sequence with discrete set of values(states) ${x_1\\ldots x_m}$ Hidden Markov model: Sequence $\\mathcal{Y}$ is called a Hidden Markov Model if it\u0026rsquo;s modeled by a system of the form $$\\begin{align}\\mathcal{X}(k+1)\u0026amp;=g(k,\\mathcal{X}(k),\\mathcal{W}(k)) \\\\ \\mathcal{Y}(k)\u0026amp;=h(k,\\mathcal{X}(k),\\mathcal{W}(k))\\end{align}$$ We also say that $\\mathcal{Y}$ has a (discrete-time) stochastic state space. Guassian-Markov Sequence (GMS): $\\mathcal{X}(k+1)=g(k,\\mathcal{X}(k),\\mathcal{W}(k))$ where $\\mathcal{W}(k)$ is iid. Guassian Linear Stochastic Sequence $$\\begin{align}\\mathcal{X}(k+1)\u0026amp;=A(k)\\mathcal{X}(k)+B(k)\\mathcal{W}(k) \\\\ \\mathcal{Y}(k)\u0026amp;=C(k)\\mathcal{X}(k)+D(k)\\mathcal{W}(k)\\end{align}$$\nFor linear Markov sequences, the deterministic mean sequence and centered uncertain sequence completely decouple. So we often assume that $\\mathcal{X}(k)$ and $\\mathcal{Y}(k)$ are centered in this case, with regard to deterministic inputs. The equation with deterministic inputs is often written as $$\\mathcal{X}(k+1)=A(k)\\mathcal{X}(k)+B_u(k)u(k)+B_\\mathcal{W}(k)\\mathcal{W}(k)$$\nRecursive-form expectations:\nMean: $\\mu_ \\mathcal{X}(k+1|q)=A(k)\\mu_ \\mathcal{X}(k|q)+B(k)\\mu_\\mathcal{W}(k)$ Covariance (Discrete-time algebraic Lyapunov/Stein difference equation): $$S_ \\mathcal{X}(k+1|q)=A(k)S_ \\mathcal{X}(k|q)A^\\top(k)+B(k)S_\\mathcal{W}(k)B^\\top(k)$$ Can be solved with dlyap in MATLAB\nConvergence when $k\\to\\infty$:\nMean convergence: $\\mu_ \\mathcal{X}(k|q)$ converges requires $\\max_i|\\lambda_i(A)|\u0026lt;1$ ($\\lambda$ denotes eigenvalue) Covariance convergence: $S_ \\mathcal{X}(k|q)$ converges requires $\\max_i|\\lambda_i(A)|\u0026lt;1$ (Discrete-time) Lyapunov equation (Stein equation): $\\bar{S}_ \\mathcal{X}=A\\bar{S}_ \\mathcal{X}A^\\top+B\\bar{S}_\\mathcal{W}(k)B^\\top$. Solution for this equation exists iff. $A$ is asymptotically stable (characterizing sequence is stationary). Explicit state transition: By recursive substitution, $$\\mathcal{X}(k)=\\Psi(k,q)\\mathcal{X}(q)+\\sum^{k-1}_ {i=q}\\Gamma(k,i)\\mathcal{W}(i)$$ where state transition matrix $\\Psi(k,q)=\\begin{cases}I, \u0026amp;k=q \\\\ \\prod^{k-1}_ {i=q}A(i),\u0026amp; k\u0026gt;q\\end{cases}$ and $\\Gamma(k,i)=\\Psi(k,i+1)B(i)$.\nConditioned Mean sequence: $\\mu_ \\mathcal{X}(k|q)=\\Psi(k,q)\\mu_ \\mathcal{X}(q)+\\sum^{k-1}_ {i=q}\\Gamma(k,i)\\mu_\\mathcal{W}(i)$ Conditioned Autocovariance Matrix: $$\\mathrm{K}_ \\mathcal{X}(k,l|q)=\\Psi(k,q)S_ \\mathcal{X}(q)\\Psi^\\top(l,q)+\\sum^{min\\{k,l\\}-1}_ {i=q}\\Gamma(k,i)S_\\mathcal{W}(i)\\Gamma^\\top(l,i)$$ A special case: $S_ \\mathcal{X}(k|q)=\\mathrm{K}_ \\mathcal{X}(k,k|q)=\\sum^{k-1}_ {i=q}\\Gamma(k,i)S_\\mathcal{W}(i)\\Gamma^\\top(k,i)$, $S_ \\mathcal{X}(k|k)=0$ Useful equation (stationary centered case): $$\\mathrm{K}_ \\mathcal{X}(k,l)=\\begin{cases} S_ \\mathcal{X}(k)\\cdot(A^\\top)^{(l-k)}\u0026amp;,l\u0026gt;k\\\\ S_ \\mathcal{X}(k)\u0026amp;,l=k\\\\ A^{(k-l)}S_ \\mathcal{X}(k)\u0026amp;,l\u0026lt; k\\end{cases}$$ Conditional Autocorrelation Matrix: $R_ \\mathcal{X}(k,l|q)=\\mathrm{K}_ \\mathcal{X}(k,l|q)+\\mu_ \\mathcal{X}(k|q)\\mu_ \\mathcal{X}^\\top(l|q)$\nObservation $\\mathcal{Y}$ property:\nMean: $\\mu_ \\mathcal{Y}(k|q)=C(k)\\mu_ \\mathcal{X}(k|q)+D(k)\\mu_\\mathcal{W}(k)$ Covariance: $$\\mathrm{K}_ \\mathcal{Y}(k,l|q)=\\begin{cases}C(k)\\mathrm{K}_ \\mathcal{X}(k,l|q)C^\\top(l)+C(k)\\Gamma(k,l)S_W(l)D^\\top(l)\u0026amp;:k\u0026gt;l \\\\C(k)S_ \\mathcal{X}C^\\top(k)+D(k)S_\\mathcal{W}(k)D^\\top(k)\u0026amp;:k=l\\\\ C(k)\\mathrm{K}_ \\mathcal{X}(k,l|q)C^\\top(l)+D(k)S_\\mathcal{W}(k)\\Gamma^\\top(l,k)C^\\top(l)\u0026amp;:k\u0026lt; l\\end{cases}$$ Stationary time-invariant covariance: $$\\mathrm{K}_ \\mathcal{Y}(s)=\\begin{cases}CA^{|s|}\\bar{S}_ \\mathcal{X}C^\\top+CA^{|s|-1}B\\bar{S}_ WD^\\top\u0026amp;:s\\neq 0 \\\\C\\bar{S}_ \\mathcal{X}C^\\top+D\\bar{S}_ WD^\\top\u0026amp;:s=0\\end{cases}$$ Gaussian Stochastic Sequence Jointly Gaussian $\\Rightarrow, \\nLeftarrow$ Marginally Gaussian $c^\\top X$ is Gaussian $\\Leftrightarrow X$ is Gaussian Conditional Gaussian: if $X$ and $Y$ are Gaussian, then $X|Y \\sim \\mathcal{N}(\\mu_{X|Y},S_{X|Y})$ where $\\mu_{X|Y}=\\mu_X+S_{XY}S_Y^{-1}(Y-\\mu_Y)$, $S_{X|Y}=S_X-S_{XY}S_Y^{-1}S_{YX}$ A linear controllable GMS $\\mathcal{X}(k)$ is stationary iff. $A(k)=A, B(k)=B$ (time-invariant) and $A$ is asymptotically stable. All LTI stationary GMS are also ergodic in all finite momoents Solve $\\mathcal{X}(k+1)=A\\mathcal{X}(k)+B\\mathcal{W}(k)$ when $\\mathcal{X}$ is stationary ($\\max_i|\\lambda_i(A)|\u0026lt;1$) solve $\\bar{\\mu}_ \\mathcal{X}=A\\bar{\\mu}_ \\mathcal{X}+B\\bar{\\mu}_\\mathcal{W}$ for $\\bar{\\mu}$ solve $\\bar{S}_ \\mathcal{X}=A\\bar{S}_ \\mathcal{X}A^\\top+B\\bar{S}_ \\mathcal{W}B^\\top$ for $\\bar{S}_ \\mathcal{X}$ calculate $\\Sigma_ \\mathcal{X}(k:l|q)=\\begin{bmatrix}\\mathrm{K}_ \\mathcal{X}(k,k|q)\u0026amp;\\cdots\u0026amp;\\mathrm{K}_ \\mathcal{X}(k,l|q)\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ \\mathrm{K}_ \\mathcal{X}(l,k|q)\u0026amp;\\cdots\u0026amp;\\mathrm{K}_ \\mathcal{X}(l,l|q)\\end{bmatrix}$ using $\\bar{S}_ \\mathcal{X}$ Then $f_ \\mathcal{X}(k:l;x(k:l))$ is determined with $\\mu_ \\mathcal{X}(k:l)=\\{\\bar{\\mu}_ \\mathcal{X},\\bar{\\mu}_ \\mathcal{X}\\ldots\\bar{\\mu}_ \\mathcal{X}\\}$ and $\\Sigma_ \\mathcal{X}(k:l)$ above. Observation \u0026amp; Filtering For deterministic version, please check my notes for control system\n(LTI) Luenberger observer: $$\\begin{align}\\hat{\\mathcal{X}}(k+1)\u0026amp;=A\\hat{\\mathcal{X}}(k)+L(\\hat{\\mathcal{Y}}(k)-\\mathcal{Y}(k))+B\\bar{\\mu}_ \\mathcal{W} \\\\ \\hat{\\mathcal{Y}}(k)\u0026amp;=C\\hat{\\mathcal{X}}(k)+D\\bar{\\mu}_\\mathcal{W}\\end{align}$$ where $L$ is the observer gain. Note: We often assume that the process \u0026amp; measurement noise are decoupled and independent Combined form: $\\hat{\\mathcal{X}}(k+1)=[A+LC]\\hat{\\mathcal{X}}(k)-L\\mathcal{Y}(k)+B\\mu_\\mathcal{W}(k)$ State estimation residual $r(k)=\\mathcal{X}(k)-\\hat{\\mathcal{X}}(k)$ Combined form: $r(k+1)=[A+LC]r(k)+[B+LD]\\tilde{\\mathcal{W}}(k)$ Stationary covariance can be solved by a Lyapunov equation $$\\bar{S}_ r=[A+LC]\\bar{S}_ r[A+LC]^T+[LD+B]\\bar{S}_ \\mathcal{W}[LD+B]^T$$ A common objective: minimize $\\bar{S}_r=\\mathbb{E}(rr^\\top)$ Solutions: $L=-A\\bar{S}_ rC^\\top[C\\bar{S}_ rC^\\top+D\\bar{S}_ \\mathcal{W}D^\\top]^{-1}$ (Kalman observer gain) Or solve (Discrete-time) Algebraic Riccati equation $$\\bar{S}_ r=A\\bar{S}_ rA^\\top+B\\bar{S}_ \\mathcal{W}B^\\top-A\\bar{S}_ rC^\\top[C\\bar{S}_ rC^\\top+D\\bar{S}_ \\mathcal{W}D^\\top]^{-1}C\\bar{S}_ rA^\\top$$ Innovation sequence $e(k)=\\hat{\\mathcal{Y}}(k)-\\mathcal{Y}(k)$ with $L$ is optimal We can find that $\\mu_e=0$ and $\\mathrm{K}_e(k+s,k)=\\begin{cases}C\\bar{S}_rC^\\top+D\\bar{S}_WD^T\u0026amp;:s=0 \\\\0\u0026amp;:s\\neq0\\end{cases}$. So the innovation sequence is iid. (only in Kalman observer) (Output) Probabilistically-equivalent model: $$\\begin{align}\\mathcal{X}(k+1)\u0026amp;=A\\mathcal{X}(k)+Le(k) \\\\ \\mathcal{Y}(k)\u0026amp;=C\\mathcal{X}(k)-e(k)\\end{align}$$ Markov Chains Content in this section comes from EECS 501 In this specific field, we often use stand-alone analysis methods.\nBasic definitions State distribution: We denote row vector $\\pi_t$ as $\\pi_t(x)=\\mathbb{P}(\\mathcal{X}_t=x),\\; x\\in S$ ($S$ is the set of states). Directly we have $\\sum_x\\pi(x)=1$ Time homogeneous: $\\mathbb{P}(\\mathcal{X}_ {t+1}=y|\\mathcal{X}_ t=x)=\\mathbb{P}(\\mathcal{X}_{s+1}=y|\\mathcal{X}_s=x)\\;\\forall s,t$ One-step transition probability matrix: $P_t=[P_{xy,t}]$ where $P_{xy,t}=\\mathbb{P}(\\mathcal{X}_ {t+1}=y|\\mathcal{X}_ t=x)$. Time-homo case: $P=[P_{xy}]$ where $P_{xy}=p(y|x)$ Rows of the matrix sum up to 1. This matrix is also called stochastic matrix. Extend this matrix to continuous states, then we use transition kernel $T(x,y)$ to describe the transition probability, m-step transition probability matrix: $P_{xy,t}^{(m)}=\\mathbb{P}(\\mathcal{X}_ {t+m}=y|\\mathcal{X}_ t=x)$ Chapman-Kolmogorov Equation: $P^{(n+m)}_t=P^{(n)}_t P^{(m)}_t$ State Variables Hitting time: $T_1(y)=\\min\\{n\\geq 0:\\mathcal{X}_ n=y\\},\\;T_k(y)=\\min\\{n\u0026gt;T_{k-1}(y):\\mathcal{X}_ n=y\\}$ where $n\\in\\mathbb{N}$ Period: For state $i\\in x$, its period is the greatest common divisor of $\\{n\u0026gt;1|T_n(i)\u0026gt;0\\}$. A Markov Chain is aperiodic If all states have period 1. Return probability: $f_{xy}=\\mathbb{P}(T_1(y)\u0026lt;\\infty|\\mathcal{X}_0=x)$ Occupation time: $V(y)=\\sum^\\infty_{n=1}\\unicode{x1D7D9}_{\\mathcal{X_n}}(y)$ Some properties $f_{xy}=\\mathbb{P}(V(y)\\geqslant 1|\\mathcal{X}_0=x)$ $\\mathbb{P}(V(y)=m|\\mathcal{X}_ 0=x)=\\begin{cases} 1-f_{xy}\u0026amp;:m=0\\\\f_{xy}f_{yy}^{m-1}(1-f_{yy})\u0026amp;:m\\geqslant 1\\end{cases}$ $\\mathbb{E}[ V(y)|\\mathcal{X}_ 0=x]=\\begin{cases} 0\u0026amp;:f_{xy}=0\\\\\\infty\u0026amp;:f_{xy}\u0026gt;0,\\ f_{yy}=1\\\\f_{xy}/(1-f_{yy})\u0026amp;:f_{xy}\u0026gt;0,\\ f_{yy}\u0026lt;1\\end{cases}$ $\\mathbb{E}[ V(y)|\\mathcal{X}_ 0=x]=\\sum^\\infty_{n=1}P^{(n)}_{xy}$ State Classification Here we usually consider only time-homogeneous Markov Chains\nAccessible ($x\\to y$): $\\exists n\\;\\text{s.t.}\\ P_{xy}^{(n)}\u0026gt;0$ $x\\to y \\Leftrightarrow f_{xy}\u0026gt;0$ Communicate ($x\\leftrightarrow y$): $x\\to y\\;\\text{and}\\;y\\to x$. This is a equivalence relation. Equivalent class: set of states that communicate with each other Irreducible: a Markov chain with only one communicating class Absorbing/Closed state: $P_{xx}=1$ Absorbing class: set $C$ is absorbing iff $\\forall x \\in C, \\sum_{y\\in C}P_{xy}=1$ Transient state: $f_{xx}\u0026lt;1 \\Leftrightarrow \\mathbb{E}[V_i|\\mathcal{X}_0=i]\u0026lt;\\infty$ Recurrent state: $f_{xx}=1 \\Leftrightarrow \\mathbb{E}[V_i|\\mathcal{X}_0=i]=\\infty$ Positive recurrent: $\\mathbb{E}[T_1(x)|\\mathcal{X}_0=x]\u0026lt;0$ Null recurrent: $\\mathbb{E}[T_1(x)|\\mathcal{X}_0=x]=0$ These two kind of recurrent states also make up communicating classes Some properties If $x$ is (positive) recurrent and $x\\to y$, then $y$ is also (positive) recurrent and $f_{xy}=f_{yx}=1$ Every closed and finite subset of $X$ contains at least one (positive) recurrent state. All states of a communicating class are either positive recurrent, null recurrent or transient. Method to determine whether class $C$ is recurrent/transient If $C$ is non-closed, it\u0026rsquo;s transient If $C$ is closed and finite, then $C$ is positive recurrent If $C$ is closed and infinite, then $C$ can be either positive/null recurrent or transient A typical example is the birth-death chain\nStationary distribution: $\\bar{\\pi}\\;\\text{s.t.}\\;\\bar{\\pi}=\\bar{\\pi} P$ Stationary in limit form: $\\bar{\\pi}=\\lim_{n\\to \\infty} \\frac{1}{n}\\sum^{n-1}_{t=0} \\pi_t$ This is a Cesaro limit, we use this to deal with the problem that $\\lim_{n\\to \\infty} \\pi_t$ might not exist if the chain is periodic. Reversibility criterion for stationary: $\\forall i,j \\in S, \\pi_i P_{ij} = \\pi_j P_{ji}$ (a.k.a detailed balance condition), then the process is reversible and therefore stationary. Existence for stationary distribution satisfying $\\bar{\\pi}=\\bar{\\pi} P$ If the chain has single positive recurrent class, then exists unique solution: $\\bar{\\pi}(x)=0$ for all transient or null recurrent $x$ If the chain has multiple positive recurrent class, then there are multiple solutions, for each positive recurrent $x$ we have a $\\bar{\\pi}^i$. If the chain has only transient and null recurrent states, there is no solution$ Convergence of stationary distribution If the chain has positive recurrent class, then $\\frac{1}{n}\\sum^n_{t=1}\\mathbb{P}(\\mathcal{X}_t=j)\\xrightarrow[n\\to \\infty]{}\\bar{\\pi}_j,\\;\\forall \\mu_0$ (Ergodic) If the chain is positive recurrent, then $\\frac{1}{n}\\sum^n_{t=1}\\unicode{x1D7D9}_{\\mathcal{X}_t}(j)\\xrightarrow[n\\to \\infty]{\\text{a.s.}}\\bar{\\pi}_j$ If the chain is positive recurrent and aperiodic, then $\\mathbb{P}(\\mathcal{X}_n=j)\\xrightarrow[n\\to \\infty]{}\\bar{\\pi}_j$ Continuous-Time Stochastic System Stochastic Sequences Definition: Given $t\\in\\mathbb{T}\\subset\\mathbb{R}$ a sequence of time, $\\mathcal{X}(t,\\omega): (\\Omega,\\mathcal{F},\\mathbb{P})\\to(\\mathbb{R}^n,\\mathcal{F}_ \\mathcal{X},\\mathbb{P}_ \\mathcal{X})$ is a continuous stochastic sequence. Most definitions are similar to discrete sequence (including stationarity), while the sequence is often defined as $\\mathcal{X}(\\mathcal{G}),\\;\\mathcal{G}={t_1,t_2,\\ldots,t_N}\\subset\\mathbb{T}, t_i\u0026lt; t_{i+1}$ Stochastic Differential Equation (SDE): $$\\mathrm{d}\\mathcal{X}(t)=F(\\mathcal{X}(t),t)\\mathrm{d}t+\\sum^r_{i=1}G_i(\\mathcal{X}(t),t)\\mathrm{d}\\mathcal{W}_i(t)$$ Here $\\mathcal{W}$ is often a certain kind of noise random process. Markov Sequence Markov Sequence: A ss. $\\mathcal{X}(k)$ is called a (continuous-time) Markov sequence if for the set of times $\\mathcal{G}={t_1,t_2,\\ldots,t_N}$ with $t_i \u0026lt; t_{i+1}$, we have $$\\begin{split}f_ \\mathcal{X}\\left(t_N;x(t_N)\\middle|\\mathcal{X}(t_{N-1})=x(t_{N-1}),\\mathcal{X}(t_{N-2})=x(t_{N-2}),\\ldots\\right)\\qquad \\\\ =f_ \\mathcal{X}(t_N;x(t_N)|\\mathcal{X}(t_{N-1})=x(t_{N-1}))\\end{split}$$ Hidden Markov Model: Definition similar to discrete case. A continuous-time stochastic state space is of the form $$\\begin{align}\\dot{\\mathcal{X}}(t)\u0026amp;=F(\\mathcal{X},t)+G(\\mathcal{X},t)\\mathrm{d}\\mathcal{W}(t)/\\mathrm{d}t \\\\ \\mathcal{Y}(t)\u0026amp;=H(\\mathcal{X},t)+J(\\mathcal{X},t)\\mathrm{d}\\mathcal{W}(t)/\\mathrm{d}t\\end{align}$$ where $\\mathcal{W}$ is usually Wiener process and white noise $\\mathrm{d}\\mathcal{W}(t)/\\mathrm{d}t$ is often written as $\\mathcal{U}(t)$. The state space is affine if $F(\\mathcal{X}(t),t)=A(t)\\mathcal{X}(t)+u(t),\\;N(\\mathcal{X},t)=C(t)\\mathcal{X}(t)+v(t)$ The state space is bilinear if $G(\\mathcal{X},t)\\mathrm{d}\\mathcal{W}(t)=\\sum^r_{i=1}B_i(t)\\mathcal{X}\\mathrm{d}\\mathcal{W}_i(t)$ Poisson Counters Definition: It\u0026rsquo;s a stochastic Markow process $\\mathcal{N}(t)\\in\\{0,1,2,\\ldots\\}$ with the characteristic that it jumps up by only one integer at a time. Characteristics: transition times are random, transition step is always 1. Transition rule: $\\frac{\\partial}{\\partial t}p_\\mathcal{N}=\\begin{cases}-\\lambda p_\\mathcal{N}(t;n)\u0026amp;:n=0\\\\-\\lambda p_\\mathcal{N}(t;n)+\\lambda p_\\mathcal{N}(t;n-1)\u0026amp;:n\u0026gt;0\\end{cases}$ From the rule we can conclude that $p_\\mathcal{N}(t;n)=\\frac{1}{n!}(\\lambda t)^n e^{-\\lambda t}$ Bidirectional counter: $\\mathcal{N}(t)$ is defined as one-directional. $\\mathcal{N}_1(t)-\\mathcal{N}_2(t)$ is called bidirectional poisson counter. Expectation: $\\mathbb{E}[\\mathcal{N}(t)]=\\lambda t,\\;\\mathbb{E}[\\mathrm{d}\\mathcal{N}(t)]=\\lambda\\mathrm{d}t$ Ito calculus for Poisson counter: Ito sense: $n(t)$ is a realization of poisson counter $\\mathcal{N}$. $x(t)$ is a solution in Ito sense to $\\mathrm{d}x(t)=F(x(t),t)\\mathrm{d}t+G(x(t),t)\\mathrm{d}n(t)$ if On all intervals where $n(t)$ is constant, $\\dot{x}(t)=F(x(t),t)$ If $n(t)$ jumps at time $t_1$, $\\lim_{t\\to t_1^+}x(t)=\\lim_{t\\to t_1^-}x(t)+G\\left(\\lim_{t\\to t_1^+}x(t),t_1\\right)$ Ito rule: Given a fuction $\\psi(\\mathcal{X}(t),t)$, taking Taylor expansion we have $$\\mathrm{d}\\psi=\\left\\{\\frac{\\partial\\psi}{\\partial t}+(\\nabla_\\mathcal{X}\\psi)F(\\mathcal{X},t)\\right\\}\\mathrm{d}t+\\sum^r_{i=1}\\left\\{\\psi\\left(\\mathcal{X}+G_i(\\mathcal{X},t),t\\right)-\\psi(\\mathcal{X},t)\\right\\}\\mathrm{d}\\mathcal{N}_i(t)$$ Wiener-Process Definition (Brownian Motion): It\u0026rsquo;s a bidirectional poisson counter with infinite rate, i.e. $\\mathcal{W}=\\lim_{\\lambda\\to\\infty}\\frac{1}{\\sqrt(\\lambda)}(\\mathcal{N}_1-\\mathcal{N}_2)$ where $\\mathcal{N}_1,\\;\\mathcal{N}_2$ have rate $\\lambda/2$ Characteristic: It\u0026rsquo;s a Gaussian with zero mean and variance $t$ Note: Actual Wiener Process has stronger continuity property than Brownian motion. Expectation: $\\mathbb{E}[\\mathcal{W}]=\\mathbb{E}[d\\mathcal{W}]=0,\\;\\mathbb{E}[\\mathcal{W}(\\tau)\\mathcal{W}(t)]=\\mathbb{E}[\\mathcal{W}^2(\\min\\{t,\\tau\\})]=\\min\\{t,\\tau\\}$ Principle of independent increments: If the interval $[r,t), [\\sigma,s)$ don\u0026rsquo;t overlap, then $\\mathcal{W}(t)-\\mathcal{W}(\\tau)$ and $\\mathcal{W}(s)-\\mathcal{W}(\\sigma)$ are uncorrelated. Ito calculus for Wiener Process Ito rule: Given a fuction $\\psi(\\mathcal{X}(t),t)$, taking Taylor expansion we have $$\\begin{split}\\mathrm{d}\\psi=\\frac{\\partial\\psi}{\\partial t}\\mathrm{d}t+(\\nabla_\\mathcal{X}\\psi)F(\\mathcal{X},t)\\mathrm{d}t+\\sum^r_{i=1}\\left(\\nabla_\\mathcal{X}\\psi(\\mathcal{X},t)\\right)G_i(\\mathcal{X},t)\\mathrm{d}\\mathcal{W}_ i \\\\ -\\sum^r_{i=1}\\frac{1}{2}G_i^\\top(\\mathcal{X},t)\\left(\\mathrm{H}_\\mathcal{X}\\psi(\\mathcal{X},t)\\right)G_i(\\mathcal{X},t)\\mathrm{d}t\\end{split}$$ Note $\\nabla_{\\mathcal{X}}=\\begin{bmatrix}\\frac{\\partial\\psi}{\\partial x_1}\u0026amp;\\cdots\u0026amp;\\frac{\\partial\\psi}{\\partial x_n}\\end{bmatrix}$ and $\\mathrm{H}_{\\mathcal{X}}=\\begin{bmatrix}\\frac{\\partial^2\\psi}{\\partial x_1^2}\u0026amp;\\cdots\u0026amp;\\frac{\\partial^2\\psi}{\\partial x_1\\partial x_n}\\\\ \\vdots\u0026amp;\\ddots\u0026amp;\\vdots \\\\ \\frac{\\partial^2\\psi}{\\partial x_n\\partial x_1}\u0026amp;\\cdots\u0026amp;\\frac{\\partial^2\\psi}{\\partial x_n^2}\\end{bmatrix}$ are the gradient and Hessian operator respectively. By default, the operator target is $\\mathcal{X}$ is not noted.\nWhite noise: It is Guassian distributed stationary stochastic process with $\\mu_\\mathcal{U}(t)=0,\\;\\mathrm{K}_ \\mathcal{U}(t,\\tau)=\\Phi_ \\mathcal{U}\\delta(t-\\tau)$, where $\\Phi_\\mathcal{U}$ is spectral intensity. We often consider white noise as derivative of Wiener process: $\\mathcal{U}\\sim\\mathrm{d}\\mathcal{W}/\\mathrm{d}t$. Linear Stochastic Sequence $$\\begin{align}\\mathrm{d}\\mathcal{X}(t)\u0026amp;=\\{A(t)\\mathcal{X}(t)+u(t)\\}\\mathrm{d}t+B(k)\\mathrm{d}\\mathcal{W}(t) \\\\ \\mathcal{Y}(t)\u0026amp;=C(k)\\mathcal{X}(k)+D(k)\\mathcal{W}(k)\\end{align}$$\nDifferential equation of expectations Mean: $\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mu_\\mathcal{X}(t)=A(t)\\mu_\\mathcal{X}(t)$ Autocovariance: $\\frac{\\mathrm{d}}{\\mathrm{d}t}S_\\mathcal{X}(t)=A(t)S_\\mathcal{X}(t)+S_\\mathcal{X}A^\\top(t)+B(t)B^\\top(t)$ (called Lyapunov differential equation) Stationary LTI case Useful equation: $\\mathrm{R}_ \\mathcal{X}(t,\\tau)=\\begin{cases} S_ \\mathcal{X}\\exp\\{A^\\top(\\tau-t)\\}\u0026amp;,\\tau\u0026gt;t \\\\ \\exp\\{A(t-\\tau)\\}S_ \\mathcal{X}\u0026amp;,\\tau\u0026lt; t\\end{cases}$ (Continuous-time) algerbraic Lyapunov equation: $A\\bar{S}_ \\mathcal{X}+\\bar{S}_\\mathcal{X}A^\\top+BB^\\top=0$ Nonlinear Stochastic Sequence The Fokker-Planck Equation (FPE): Consider the Wiener-process excited general SDE, we have $$\\frac{\\partial f_ \\mathcal{X}(x;t)}{\\partial t}=-\\nabla\\left(F(\\mathcal{X})f_ \\mathcal{X}(x;t)\\right)+\\frac{1}{2}\\mathrm{tr}\\left[\\mathrm{H}\\left(\\Gamma(\\mathcal{X})f_ \\mathcal{X}(x;t)\\right)\\right]$$ here $\\Gamma(\\mathcal{X})=G(\\mathcal{X})G^\\top(\\mathcal{X})$\n$\\mathcal{X}$ is stationary means $\\frac{\\partial f_\\mathcal{X}(x;t)}{\\partial t}=0$ Gaussian closure: An approximate solution for FPE is supposing $f_\\mathcal{X}$ as multivariate Gaussian with some $S_\\mathcal{X}$ and ${\\mu_\\mathcal{X}}$. That is we focus on 1st-order and 2nd-order estimation. Denote the estimated distribution as $\\hat{f}_\\mathcal{X}(x;t)$\nEstimated expectation: $\\hat{\\mathbb{E}}\\phi(\\mathcal{X})=\\int\\cdots\\int\\phi(x)\\hat{f}_\\mathcal{X}(x;t)\\mathrm{d}x$\nSolution:$$\\begin{split}h(x,t)=-\\nabla F+\\tilde{x}^\\top S^{-1}F-(\\nabla\\Gamma)S^{-1}\\tilde{x}+\\frac{1}{2}\\mathrm{tr}\\left[\\mathrm{H}\\Gamma \\right] \\\\ +\\frac{1}{2}\\mathrm{tr}\\left[\\left(-S^{-1}+S^{-1}\\tilde{x}\\tilde{x}^\\top S^{-1}\\right)\\Gamma\\right]\\end{split}$$ and $$\\begin{align}\\dot{\\mu}_\\mathcal{X}(t)\u0026amp;=S(t)\\hat{\\mathbb{E}}[\\nabla^\\top h(x)] \\\\ \\dot{S} _\\mathcal{X}(t)\u0026amp;=S(t)\\hat{\\mathbb{E}}[\\mathrm{H} h(x)]S(t)\\end{align}$$\nUseful simplification: If $G$ is constant (independent of $\\mathcal{X}$), then the ODE of $\\dot{\\mu}$ and $\\dot{S}$ become $$\\begin{align}\\dot{\\mu}_ \\mathcal{X}(t)\u0026amp;=\\hat{\\mathbb{E}}[F(\\mathcal{X})] \\\\ \\dot{S} _\\mathcal{X}(t)\u0026amp;=\\hat{A}^\\top S+S\\hat{A}+\\Gamma\\end{align}$$ where $\\hat{A}=\\hat{\\mathbb{E}}\\left[\\frac{\\partial F}{\\partial\\mathcal{X}}\\right]$\nEquivalent linearization (Quasi-linearization): In the estimation, $\\mathcal{X}$ evolves equivalently to $\\mathrm{d}\\mathcal{X}(t)=\\hat{A}(t)\\mathcal{X}(t)\\mathrm{d}t+G\\mathrm{d}\\mathcal{W}(t)$ No guaranteed bounds generally exist for the estimation error $$e(\\mathcal{X},t)=\\left(\\frac{\\partial\\hat{f}_ \\mathcal{X}}{\\partial t}\\right)-\\left(-\\nabla\\left(F\\hat{f}_ \\mathcal{X}\\right)+\\frac{1}{2}\\mathrm{tr}\\left[\\mathrm{H}\\left(\\Gamma\\hat{f}_ \\mathcal{X}\\right)\\right]\\right)$$\nEstimation of $\\mu(t),\\;S(t)$ could also have error. And stationarity may not be the consistent between original system and estimated system\nSpectral Analysis Content in this section comes from MECHENG 549\nPower Spectral Density Definition: The power spectral density (PSD) of stochastic process $\\mathcal{Y}$ is $$\\Phi_\\mathcal{Y}(\\omega)\\equiv\\mathbb{E}\\left[ \\lim_{T\\to\\infty}\\frac{1}{2T}Y_T(\\omega)Y_T^\\top(\\omega)\\right]$$ where $Y_T(\\omega)$ is the Fourier transform of centered process $\\mathcal{Y}(t)$. White noise has the same PSD for whatever $\\omega$ Wiener-Khinchin Theorem: $\\Phi_\\mathcal{Y}(\\omega)=\\int^\\infty_{-\\infty}e^{-i\\omega\\theta}\\bar{\\mathrm{K}}_\\mathcal{Y}(\\theta)\\mathrm{d}\\theta$ Signal propagation: If the system $P$ has input $\\mathcal{Y}$ and output $\\mathcal{Z}$, then $\\Phi_\\mathcal{Z}=|P(i\\omega)\\Phi_\\mathcal{Y}(\\omega)P^\\top(i\\omega)|$ where $P(i\\omega)$ is the Fourier transform of the system. Cross spectrum: If the system $G$ has input $\\mathcal{Y}$ and output $\\mathcal{Z}$, then the cross-spectrum is $\\Phi_{\\mathcal{ZY}}(\\omega)=G(i\\omega)\\Phi_\\mathcal{Y}(\\omega)$ Periodograms Definition: We want to estimate $\\Phi_{\\mathcal{Y}}(\\omega)$ without the expectation, then we use $$Q_T(\\omega,y)=\\frac{1}{2T}\\left|\\int^T_{-T}e^{-i\\omega t}y(t)\\mathrm{d}t\\right|^2$$ where $y$ is a sample realization of $\\mathcal{Y}$. We also use window functions to calculate the spectrum over a finite time interval (using Bartlett\u0026rsquo;s procedure) Stochastic realizations We want to find a stochastic model which gives the same spectrum given. This is called stochastic realization problem. We focus on scalar LTI case.\nIf we know $P(s)=C[sI-A]^{-1}B+D$ (the Laplace transform of LTI system) and $P(s)=c\\frac{\\prod^m_{k=1}(s-z_k)}{\\prod^n_{k=1}(s-p_k)}$ for some $m\\leq n$ and real constant $c$. Then we have $$\\Phi_\\mathcal{Y}(\\omega)=P(i\\omega)P(-i\\omega)=c^2\\frac{\\prod^m_{k=1}(\\omega^2+z_k^2)}{\\prod^n_{k=1}(\\omega^2+p_k^2)}$$\nLemma: For any valid PSD, there exists a spectral factorization $\\Phi_\\mathcal{Y}(\\omega)=\\frac{\\sum^m_{k=0}a_k(\\omega^2)^k}{\\sum^n_{k=0}b_k(\\omega^2)^k}=P(i\\omega)P(-i\\omega)$ where $P(s)$ is an asymptotically stable n-th order transfer function, iff\n$\\Phi_\\mathcal{Y}(\\omega)$ is a ratio of polynomials of $\\omega^2$ All coefficients $a_k$ and $b_k$ are real The denominator has no positive real roots in $\\omega^2$ Any positive real roots in the numerator have even multiplicity Notes for math typing in Hexo Escape \\ by \\\\. Especially escape { by \\\\{ instead of \\{, and escape \\\\ by \\\\\\\\. Be careful about _, it\u0026rsquo;s used in markdown as italic indicator. Add space after _ is a useful solution. Some useful Mathjax tricks at StackExchange Several capital Greek characters should directly use its related Latin alphabet with \\mathrm command. Although I have migrated to Hugo, some tricks might still be relevant.\n","date":"2019-03-26T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2019-03/StochasticSystemNotes/","title":"Notes for Stochastic System"},{"content":"Probability Space Notation: $(\\Omega,\\mathcal{F},\\mathbb{P})$ $\\Omega$: Sample space $\\mathcal{F}$: Event space. Required to be σ-algebra. We often use Borel σ-algebra for continuous $\\Omega$). Axioms for σ-algebra $\\mathcal{F}$ is non-empty $A\\in\\mathcal{F} \\Rightarrow A^C\\in\\mathcal{F}$ (closed under complement) $A_i \\in\\mathcal{F} \\Rightarrow \\bigcup^\\infty_{k=1} A_k \\in \\mathcal{F}$ (closed under countable union) For continuous case considering interval $\\Omega=[a,b]$, $\\mathcal{F}_0$ is the set of all subintervals of $\\Omega$. Then its Borel σ-algebra is the smallest σ-algebra that contains $\\mathcal{F}_0$. Here the $\\mathcal{F}_0$ is a semialgebra. We can find a containing σ-algebra for every semialgebra. Axioms for semialgebra $\\emptyset, \\Omega \\in \\mathcal{F}$ $A_i \\in\\mathcal{F} \\Rightarrow \\bigcap^n_{k=1} A_k \\in \\mathcal{F}$ (closed under finite intersections) $\\forall B \\in\\mathcal{F}, B^C=\\bigcup^n_{k=1} A_k$ where $A_i \\in \\mathcal{F}$ $\\mathbb{P}$: Probability measure. Axioms for probability measure $\\mathbb{P}(\\Omega) = 1$ $\\forall A\\in\\mathcal{F}, \\mathbb{P}(A) \\geqslant 0$ $A_i, A_j \\in\\mathcal{F}$ are pairwise disjoint, then $\\mathbb{P}(\\bigcup^\\infty_{k=1}A_k)=\\sum^\\infty_{k=1}\\mathbb{P}(A_k)$ Product Space: Probability spaces can be combined using Cartesian product. Independence: $\\mathbb{P}(A_{k_1}\\cap A_{k_2}\\cap \u0026hellip;\\cap A_{k_l})=\\prod_{i=1}^l \\mathbb{P}(A_i),\\;\\forall \\{k_i\\}_1^l\\subset\\{ 1..n\\}$ Conditional probability: $\\mathbb{P}\\left(A_i \\middle| A_j\\right)=\\mathbb{P}(A_i\\cap A_j)/\\mathbb{P}(A_j)$ Total probability: $\\mathbb{P}(B)=\\sum_{i=1}^n \\mathbb{P}(B\\cap A_i)=\\sum_{i=1}^n \\mathbb{P}\\left(B\\middle| A_i\\right)\\mathbb{P}(A_i)$, where $\\{A_1,\\cdots,A_n\\}$ are disjoint and partition of $\\Omega$. Bayes\u0026rsquo; Rule: $$\\mathbb{P}(A_j|B)=\\frac{\\mathbb{P}(B|A_j)\\mathbb{P}(A_j)}{\\sum^n_{i=1} \\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}$$ Priori: $\\mathbb{P}(B|A_j)$ Posteriori: $\\mathbb{P}(A_j|B)$ Random Variables Note: The equations are written in continuous case by default, one can get the equation for discrete case by changing integration into summation and changing differential into difference.\nRandom Variable $\\mathcal{X}$ is a mapping $\\mathcal{X}: (\\Omega,\\mathcal{F},\\mathbb{P})\\to(\\Omega_ \\mathcal{X},\\mathcal{F}_ \\mathcal{X},\\mathbb{P}_ \\mathcal{X})$ Continuous \u0026amp; Discrete \u0026amp; Mixed Random Variable: Can be defined upon whether $\\Omega_\\mathcal{X}$ is continuous Can be defined upon whether we can find continuous density function $f_\\mathcal{X}$ $\\mathcal{F}_\\mathcal{X}$ for continuous $\\mathcal{X}$ is a Borel σ-field All three kinds of random variables can be expressed by CDF or \u0026ldquo;extended\u0026rdquo; PDF with Dirac function and Lebesgue integration. Scalar Random Variable: $\\mathcal{X}: \\Omega\\to\\mathbb{F}$ Formal definition: $\\mathcal{X}: (\\Omega,\\mathcal{F},\\mathbb{P})\\to(\\Omega_ \\mathcal{X}\\subset\\mathbb{F},\\mathcal{F}_ \\mathcal{X}\\subset\\left\\{\\omega\\middle| \\omega\\subset\\Omega_ \\mathcal{X}\\right\\},\\mathbb{P}_ \\mathcal{X}:\\mathcal{F}_ \\mathcal{X}\\to[0,1])$ Cumulative Distribution Function (CDF): $F_ \\mathcal{X}(x)=\\mathbb{P}_\\mathcal{X}(\\mathcal{X}(\\omega)\\leqslant x)$ Probability Mass Function (PMF): $p_ \\mathcal{X}(x)=\\mathbb{P}_\\mathcal{X}(\\mathcal{X}(\\omega)=x)$ Probability Density Function (PDF): $$f_ \\mathcal{X}(x)=\\mathbb{P}_ \\mathcal{X}(x\u0026lt; \\mathcal{X}(\\omega)\\leqslant x+ \\mathrm{d}x)=\\mathrm{d}F_ \\mathcal{X}(x)/ \\mathrm{d}x$$ Vector Random Variable (Multiple Random Variables): $\\mathcal{X}: \\Omega\\to\\mathbb{F}^n$ Formal definition $\\mathcal{X}: (\\Omega,\\mathcal{F},\\mathbb{P})\\to(\\Omega_ \\mathcal{X}\\subset\\mathbb{F}^n,\\mathcal{F}_ \\mathcal{X}\\subset\\left\\{\\omega\\middle| \\omega\\subset\\Omega_ \\mathcal{X}\\right\\},\\mathbb{P}_ \\mathcal{X}:\\mathcal{F}_ \\mathcal{X}\\to[0,1])$ Cumulative Distribution Function (CDF): $F_ \\mathcal{X}(x)=\\mathbb{P}_\\mathcal{X}(\\{\\mathcal{X}(\\omega)\\}_i\\leqslant x_i), i=1\\ldots n$ Probability Mass Function (PMF): $p_ \\mathcal{X}(x)=\\mathbb{P}_\\mathcal{X}(\\{\\mathcal{X}(\\omega)\\}_i=x)$ Probability Density Function (PDF): $$f_ \\mathcal{X}(x)=\\mathbb{P}_ \\mathcal{X}(x_i\u0026lt; \\{\\mathcal{X}(\\omega)\\}_ i\\leqslant x_i+ \\mathrm{d}x_i)=\\frac{\\partial^n}{\\partial x_1\\partial x_2\\ldots\\partial x_n}F_ \\mathcal{X}(x)$$ Afterwards, we don\u0026rsquo;t distinguish $\\mathbb{P}_\\mathcal{X}$ with $\\mathbb{P}$ if there\u0026rsquo;s no ambiguity.\nIndependence($\\perp$ or $\\perp$ with double vertical lines): $\\mathbb{P}(\\mathcal{X}\\in A\\cap \\mathcal{Y}\\in B)=\\mathbb{P}(\\mathcal{X}\\in A)\\mathbb{P}(\\mathcal{Y}\\in B)$ Independent CDF:$F_{\\mathcal{XY}}(x,y)=F_\\mathcal{X}(x)F_\\mathcal{Y}(y)$ iff $\\mathcal{X}\\perp\\mathcal{Y}$ Independent PMF:$p_{\\mathcal{XY}}(x,y)=p_\\mathcal{X}(x)p_\\mathcal{Y}(y)$ iff $\\mathcal{X}\\perp\\mathcal{Y}$ Independent PDF:$f_{\\mathcal{XY}}(x,y)=f_\\mathcal{X}(x)f_\\mathcal{Y}(y)$ iff $\\mathcal{X}\\perp\\mathcal{Y}$ Marginalization Marginal distribution function: $F_{1:m}(x_{1:m})\\equiv F\\left(\\begin{bmatrix}x_1\u0026amp;x_2\u0026amp;\\ldots\u0026amp;x_m\u0026amp;\\infty\u0026amp;\\ldots\u0026amp;\\infty\\end{bmatrix}^\\top\\right)$ Marginal density function: $f_{1:m}(x_{1:m})=\\int^\\infty_{-\\infty}\\cdots\\int^\\infty_{-\\infty} f(x) \\mathrm{d}x_{m+1}\\cdots \\mathrm{d}x_n$ Conditional (on event $\\mathcal{E}$) Conditional probability: $\\mathbb{P}(\\mathcal{X}\\in\\mathcal{D}|\\mathcal{E})=\\mathbb{P}(\\{\\omega|\\mathcal{X}(\\omega)\\in\\mathcal{D}\\}\\cap \\mathcal{E})/\\mathbb{P}(\\mathcal{E})$ on a event $\\mathcal{E}\\in\\mathcal{F}$ and a set $\\mathcal{D}\\subset\\mathcal{F}$. Conditional CDF: $F_ \\mathcal{X}(x|\\mathcal{E})=\\mathbb{P}(\\mathcal{X}_i\\leqslant x_i|\\mathcal{E})$ Conditional PMF: $p_ \\mathcal{X}(x|\\mathcal{E})=\\mathbb{P}(\\mathcal{X}_i=x_i|\\mathcal{E})$ Conditional PDF: $f_ \\mathcal{X}(x|\\mathcal{E})=\\frac{\\partial^n}{\\partial x_1\\partial x_2\\ldots\\partial x_n}F_ \\mathcal{X}(x|\\mathcal{E})$ Conditional (on variable $\\mathcal{Y}$) Conditional probability: $$\\mathbb{P}(\\mathcal{X}\\in\\mathcal{D}_1|\\mathcal{Y}\\in\\mathcal{D}_2)=\\mathbb{P}(\\{\\omega|\\mathcal{X}(\\omega)\\in\\mathcal{D}_1,\\mathcal{Y}(\\omega)\\in\\mathcal{D}_2\\})/\\mathbb{P}(\\mathcal{Y}(\\omega)\\in\\mathcal{D}_2)$$ Conditional PDF (similar for PMF): $$f_{\\mathcal{X}|\\mathcal{Y}\\in\\mathcal{D}}(x)=\\frac{\\int_{\\mathcal{Y}\\in\\mathcal{D}}f_{\\mathcal{XY}}(x,y)}{\\int_{\\mathcal{Y}\\in\\mathcal{D}}f_{\\mathcal{Y}}(y)},\\;f_{\\mathcal{X}|\\mathcal{Y}}(x|y)=f_{\\mathcal{X}|\\mathcal{Y}=y}(x)=\\frac{f_{\\mathcal{XY}}(x,y)}{f_{\\mathcal{Y}}(y)}$$ Using total probability we have $f_ \\mathcal{X}(x)=\\int f_{\\mathcal{X}|\\mathcal{Y}}(x|y)f_ \\mathcal{Y}(y)\\mathrm{d}y$. This can be further integrated into Bayes\u0026rsquo; rule. Conditional CDF: Can be defined similarly, of defined as $F_{\\mathcal{X}|\\mathcal{Y}\\in\\mathcal{D}}(x)\\equiv\\int f_{\\mathcal{X}|\\mathcal{Y}\\in\\mathcal{D}}(x)\\mathrm{d}x$ Similarly we have $F_ \\mathcal{X}(x)=\\int F_{\\mathcal{X}|\\mathcal{Y}}(x|y)f_ \\mathcal{Y}(y)\\mathrm{d}y$ Substitution law: $\\mathbb{P}((\\mathcal{X},\\mathcal{Y})\\in \\mathcal{D}|\\mathcal{X}=x)=\\mathbb{P}((x,\\mathcal{Y})\\in \\mathcal{D})$ Common usage: Suppose $\\mathcal{Z}=\\psi(\\mathcal{X},\\mathcal{Y})$, then $p_\\mathcal{Z}(z)=\\int_x \\mathbb{P}\\left(\\psi(x,\\mathcal{Y})=z\\right)p_\\mathcal{X}(x)$ Uncertainty Propagation Suppose $\\mathcal{Y}=\\psi(\\mathcal{X})$ or specifically $y=\\psi(x_1)=\\psi(x_2)=\\cdots=\\psi(x_K)$\nScalar case: $$f_ \\mathcal{Y}(y)=\\sum^K_{k=1} f_ \\mathcal{X}(\\psi^{-1}_ k(y))\\left| \\frac{\\partial\\psi}{\\partial x}\\biggr|_{x=\\psi^{-1}_k(y)} \\right|^{-1}$$ Vector case: $$f_ \\mathcal{Y}(y)=\\sum^K_{k=1} f_ \\mathcal{X}(\\psi^{-1}_ k(y))\\left|\\det(J)\\right|^{-1},\\text{where Jacobian }J=\\frac{\\partial\\psi}{\\partial x}\\biggr|_{x=\\psi^{-1}_k(y)}$$ Trivial Case — Summation: $\\mathcal{Y}=\\mathcal{X}_ 1+\\mathcal{X}_ 2$, then $f_ \\mathcal{Y}=\\int^\\infty_{-\\infty}f_ {\\mathcal{X}_ 1\\mathcal{X}_ 2}(x_1,x_2-x_1) \\mathrm{d}x_1$ Another way is to use the method of choice: $F_ \\mathcal{Y}(y)=\\int_ {\\psi(x)\\leq y}f_\\mathcal{X}(x)\\mathrm{d}x$ Expectation \u0026amp; Moments Expectation: $\\mathbb{E}_ \\mathcal{X}[\\psi(\\mathcal{X})]=\\int^\\infty_\\infty\\cdots\\int^\\infty_\\infty\\psi(x)f_ \\mathcal{X}(x) \\mathrm{d}x_1\\ldots \\mathrm{d}x_n$ A more rigorous way to define the expectation is $\\mathbb{E}_ \\mathcal{X}[\\psi(\\mathcal{X})]=\\int \\psi(\\mathcal{X})dF_ \\mathcal{X}(\\mathcal{X})$. This definition uses Lebesgue Integral and works on both discrete and continuous (or even mixed) variables. See this post and this discussion for more information. We write $\\mathbb{E}_ \\mathcal{X}$ as $\\mathbb{E}$ if there\u0026rsquo;s no ambiguity (when only one random variable is included). And $\\mathbb{E}[\\mathcal{X}]$ will be abbreviated as $\\mathbb{E}\\mathcal{X}$ afterwards.\nLinearity of expectation: $\\mathbb{E}[A\\mathcal{\\mathcal{X}}]=A\\mathbb{E}[\\mathcal{X}] (\\forall \\mathcal{X},\\mathcal{Y},\\forall A\\in\\mathbb{R}^{m\\times n})$ Independent expectation: $\\mathbb{E}[\\prod^n_i\\mathcal{X}_i]=\\prod^n_i\\left(\\mathbb{E}\\mathcal{X}_i\\right)(\\forall\\;\\text{indep.}\\;\\mathcal{X}_i)$ Conditional expectation: $\\mathbb{E}[\\mathcal{Y}|\\mathcal{X}=x]=\\int^\\infty_{-\\infty}yf_{\\mathcal{Y}|\\mathcal{X}}(y|x)\\mathrm{d}y$ Total expectation/Smoothing: $\\mathbb{E}_ \\mathcal{X}[\\mathbb{E}_ {\\mathcal{Y}|\\mathcal{X}}(\\mathcal{Y}|\\mathcal{X})]=\\mathbb{E}\\mathcal{Y}$ Substitution law: $\\mathbb{E}[g(\\mathcal{X},\\mathcal{Y})|\\mathcal{X}=x]=\\mathbb{E}[\\psi(x,\\mathcal{Y})|\\mathcal{X}=x]$ $\\mathbb{E}[\\psi(\\mathcal{X})|\\mathcal{X}]=\\psi(\\mathcal{X})$ $\\mathbb{E}[\\psi(\\mathcal{X})\\mathcal{Y}|\\mathcal{X}]=\\psi(\\mathcal{X})\\mathbb{E}(\\mathcal{Y}|\\mathcal{X})$ Towering: $\\mathbb{E}_ {\\mathcal{Y}|\\mathcal{Z}}[\\mathbb{E}_ \\mathcal{X}(\\mathcal{X}|\\mathcal{Y},\\mathcal{Z})|\\mathcal{Z}]=\\mathbb{E}_ {\\mathcal{X}|\\mathcal{Z}}[\\mathcal{X}|\\mathcal{Z}]$ Moment (p-th order): $\\mu_p(\\mathcal{X})=\\mathbb{E}[\\mathcal{X}^p]$ Mean: $\\mu_ \\mathcal{X}=\\mathbb{E}[\\mathcal{X}]$ Central moment (p-th order): $\\mathbb{E}[(\\mathcal{X}-\\mu_ \\mathcal{X})^p]$ Variance: $\\sigma_ \\mathcal{X}^2=\\mathbb{E}[(\\mathcal{X}-\\mu_ \\mathcal{X})^2]$, sometimes written as $\\sigma_ \\mathcal{X}^2=\\mathbb{V}(\\mathcal{X})$ Skewness: $\\tilde{\\mu}_ 3=\\mathbb{E}[(\\mathcal{X}-\\mu_ \\mathcal{X})^3]/\\sigma_\\mathcal{X}^3$ ($\\tilde{\\mu}_ 3\u0026gt;0$ right-skewed, $\\tilde{\\mu}_ 3\u0026lt;0$ left-skewed) Kurtosis: $\\tilde{\\mu}_ 4=\\mathbb{E}[(\\mathcal{X}-\\mu_ \\mathcal{X})^4]/\\sigma_\\mathcal{X}^4$ Excessive Kurtosis: $\\gamma = \\mu_ 4-3$ Correlation: $\\text{corr}(\\mathcal{X}_i,\\mathcal{X}_j)=\\mathbb{E}[\\mathcal{X}_i\\mathcal{X}_j]$ Correlation matrix: $C=\\mathbb{E}[\\mathcal{X}_i\\mathcal{X}_j^\\top]$ Correlation coefficient: $\\rho(\\mathcal{X}_ i,\\mathcal{X}_ j)=\\frac{\\text{corr}(\\mathcal{X}_ i,\\mathcal{X}_ j)}{\\sigma_{\\mathcal{X}_ i}^2\\sigma_{\\mathcal{X}_ j}^2}$ Covariance: $\\text{cov}(\\mathcal{X}_i,\\mathcal{X}_j)=\\mathbb{E}[(\\mathcal{X}_i-\\mu_i)(\\mathcal{X}_j-\\mu_j)]$ Covariance matrix: $S=\\mathbb{E}\\left[(\\mathcal{X}-\\mu_ \\mathcal{X})(\\mathcal{X}-\\mu_ \\mathcal{X})^\\top\\right]$ Properties: $\\text{cov}(\\mathcal{X}+c)=\\text{cov}(\\mathcal{X}), \\text{cov}(A\\mathcal{X},\\mathcal{X}B)=A\\text{cov}(\\mathcal{X})+\\text{cov}(\\mathcal{X})B^\\top$ Uncorrelated: $\\rho(\\mathcal{X}_ i,\\mathcal{X}_ j)=0 \\Leftrightarrow\\text{cov}(\\mathcal{X}_i,\\mathcal{X}_j)=0\\Leftrightarrow\\text{corr}(\\mathcal{X}_i,\\mathcal{X}_j)=\\mathbb{E}[\\mathcal{X}_i]\\mathbb{E}[\\mathcal{X}_j]$ (uncorrelated is necessary for independent) Cases where uncorrelated implies independence: (1) Jointly Gaussian (2) Bernoulli Centered variable: $\\tilde{\\mathcal{X}}=\\mathcal{X}-\\mu_ \\mathcal{X}$ Transform methods Probability generating function(PGF): similiar to Z-tranform $$G_ \\mathcal{X}(z)\\equiv\\mathbb{E}[z^\\mathcal{X}]=\\sum_{x_i}z^{x_i}p_ \\mathcal{X}(x_i)$$ For $\\mathcal{F}_ \\mathcal{X}=\\mathbb{N}$, we have $$\\frac{\\mathrm{d}^k}{\\mathrm{d}z^k}G_ \\mathcal{X}(z)\\Biggr|_{z=1}=\\mathbb{E}[\\mathcal{X}(\\mathcal{X}-1)\\cdots(\\mathcal{X}-(k-1))]$$ Moment generating function(MGF): similar to Laplace transform $$M_ \\mathcal{X}(z)\\equiv\\mathbb{E}[e^{s\\mathcal{X}}]=\\int^\\infty_{-\\infty}e^{sx}f_ \\mathcal{X}(x)\\mathrm{d}x$$ Generally we have $$\\frac{\\mathrm{d}^k}{\\mathrm{d}s^k}M_ \\mathcal{X}(s)\\Biggr|_{s=0}=\\mathbb{E}[\\mathcal{X}^k]$$ Characteristic function(CF): similar to Fourier transform $$\\phi_ \\mathcal{X}(\\omega)\\equiv\\mathbb{E}[e^{j\\omega \\mathcal{X}}]=\\int^\\infty_{-\\infty}e^{j\\omega x}f_ \\mathcal{X}(x)\\mathrm{d}x$$ Generally we have $$\\frac{\\mathrm{d}^k}{\\mathrm{d}\\omega^k}\\phi_ \\mathcal{X}(\\omega)\\Biggr|_{\\omega=0}=j^k\\mathbb{E}[\\mathcal{X}^k]$$ Independent: $\\mathcal{X}\\perp \\!\\!\\! \\perp\\mathcal{Y}$ iff. $\\phi_ \\mathcal{XY}(\\omega)=\\phi_ \\mathcal{X}(\\omega)\\phi_ \\mathcal{Y}(\\omega)$ Joint characteristic function: for vector case $\\mathcal{X}\\in\\mathbb{R}^n$, we define vector $u$ and $$\\phi_ \\mathcal{X}(u)\\equiv\\mathbb{E}[e^{ju^\\top \\mathcal{X}}]$$ Trivial usage: if $\\mathcal{Y}=\\mathcal{X}_ 1+\\mathcal{X}_ 2$, then $\\phi_ \\mathcal{Y}(u)=\\phi_{\\mathcal{X}_ 1}(u)\\phi_{\\mathcal{X}_ 2}(u)$ Common distributions1 Bernoulli: $\\Omega_\\mathcal{X}=\\{0,1\\}$ $$p_\\mathcal{X}(1)=p,\\;p_\\mathcal{X}(0)=q=1-p$$ $\\mu_\\mathcal{X}=p,\\;\\sigma^2_\\mathcal{X}=pq,\\;G_\\mathcal{X}(z)=q+pz$ Binomial - $\\mathcal{B}(n,p)$: $\\Omega_\\mathcal{X}=\\{0,1,\\ldots,n\\}$ $$p_\\mathcal{X}(k)=\\binom{n}{k}p^k(1-p)^{n-k}$$ $\\mu_\\mathcal{X}=np,\\;\\sigma^2_\\mathcal{X}=np(1-p),\\;G_\\mathcal{X}(z)=(1-p+pe^z)^n$ Multinomial: $\\Omega_\\mathcal{X}=\\{0,1,\\ldots,n\\}^k$ $$p_\\mathcal{X}(x)=\\binom{n}{x_1!\\cdots x_k!}p_1^{x_1}\\cdots p_k^{x_k}$$ Geometric: $\\Omega_\\mathcal{X}=\\mathbb{N}$ $$p_\\mathcal{X}(k)=(1-p)^{k-1}p$$ $\\mu_\\mathcal{X}=\\frac{1}{p},\\;\\sigma^2_\\mathcal{X}=\\frac{1-p}{p^2},\\;G_\\mathcal{X}(z)=\\frac{pz}{1-(1-p)z}$ Poisson: $\\Omega_\\mathcal{X}=\\mathbb{N}$ $$p_\\mathcal{X}(k)=\\frac{\\lambda^k}{k!}\\exp\\{-\\lambda\\}$$ $\\mu_\\mathcal{X}=\\lambda,\\;\\sigma^2_\\mathcal{X}=\\lambda,\\;G_\\mathcal{X}(z)=\\exp\\{\\lambda(z-1)\\}$ Uniform - $\\mathcal{U}(a,b)$: $\\Omega_\\mathcal{X}=[a,b]$ $$f(x)= \\begin{cases} 1/(b-a)\u0026amp;,\\;x \\in [a,b] \\\\ 0\u0026amp;,\\;\\text{otherwise} \\end{cases}$$ $\\mu_\\mathcal{X}=\\frac{1}{2}(a+b),\\;\\sigma^2_\\mathcal{X}=\\frac{1}{12}(b-a)^2,\\;M_\\mathcal{X}(s)=\\frac{e^{sb}-e^{sa}}{s(b-a)}\\;(s\\neq 0)$ Normal - $\\mathcal{N}(\\mu,\\sigma)$: $\\Omega_\\mathcal{X}=\\mathbb{R}$ $$f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp\\left\\{-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}$$ $M_\\mathcal{X}(s)=\\exp\\left\\{\\mu s+\\frac{1}{2}\\sigma^2s^2\\right\\}$ Joint Normal: $\\Omega_\\mathcal{X}=\\mathbb{R}^n$ $$f(x)=\\frac{1}{\\sqrt{(2\\pi)^n \\det(S)}}\\exp\\left\\{-\\frac{1}{2}(x-\\mu)^\\top S^{-1}(x-\\mu)\\right\\}$$ $\\phi_\\mathcal{X}(u)=\\exp\\left\\{ju^\\top \\mu-\\frac{1}{2}u^\\top Su\\right\\}$ Rayleigh: $\\Omega_\\mathcal{X}=[0,\\infty]$ $$f(x)=\\frac{x}{\\sigma^2}\\exp\\left\\{-\\frac{x^2}{2\\sigma^2}\\right\\}H(x)$$ where $H(x)$ is Heaviside step function Exponential - $\\mathcal{E}(\\lambda)$: $\\Omega_\\mathcal{X}=[0,\\infty]$ $$f(x)=\\frac{1}{\\mu}\\exp\\left\\{-\\frac{x}{\\mu}\\right\\}H(x)$$ $\\mu_\\mathcal{X}=1/\\lambda,\\;\\sigma^2_\\mathcal{X}=1/\\lambda^2,\\;M_\\mathcal{X}(s)=\\lambda/(\\lambda-s)$ Laplacian: $$f(x)=\\frac{1}{2b}\\exp\\left\\{-\\frac{|x-\\mu|}{b}\\right\\}$$ Derivation of the distributions Bernoulli → Binomial: $\\mathcal{X}_ i\\sim\\text{Bernoulli}( p) \\Rightarrow \\mathcal{Y}=\\sum_{i=1}^n \\mathcal{X}_ i\\sim\\mathcal{B}(n,p)$ Bernoulli → Geometric: $\\mathcal{X}_i\\sim\\text{Bernoulli}( p) \\Rightarrow \\mathcal{Y}\\sim\\text{Geometric}( p)$ denoting the first $\\mathcal{X}_i=1$ Binomial → Poisson: $\\mathcal{X}_i\\sim\\mathcal{B}(n,p,k=1) \\Rightarrow \\mathcal{Y}\\sim\\text{Poisson}(\\lambda)$ when $n\\to \\infty$ with $p=\\frac{\\lambda\\tau}{n}$ Binomial → Exponential: $\\mathcal{X}_i\\sim\\mathcal{B}(n,p,k\\neq0) \\Rightarrow \\mathcal{Y}\\sim\\mathcal{E}(\\lambda)$ when $n\\to \\infty$ with $p=\\frac{\\lambda\\tau}{n}$ Actually $\\mathcal{B}(n,p,k) \\Rightarrow e^{-\\lambda \\tau}\\frac{(\\lambda \\tau)^k}{k!}$\nExponential → Laplacian: $\\mathcal{X}_1, \\mathcal{X}_2 \\sim\\mathcal{E}(\\lambda) \\Rightarrow \\mathcal{X}_1-\\mathcal{X}_2\\sim\\text{Laplacian}(\\lambda^{-1})$ Concentration Inequalities Cauchy-Schwarz Inequality: $S=\\left(\\mathbb{E}[\\mathcal{X}\\mathcal{X}_j]\\right)^2\\leqslant\\left(\\mathbb{E}[\\mathcal{X}_i]\\right)^2\\left(\\mathbb{E}[\\mathcal{X}_j]\\right)^2$ Markov Inequality: $\\mathbb{P}(\\mathcal{X}\\geqslant a)\\leqslant \\mathbb{E}\\mathcal{X}/a,\\;a\u0026gt;0$ Chebychev Inequality: $\\mathbb{P}(|\\mathcal{X}-\\mu|\\geqslant\\delta)\\leqslant\\sigma^2/\\delta^2$ Jenson Inequality: $\\psi(\\mathbb{E} \\mathcal{X}) \\leqslant \\mathbb{E}\\psi(\\mathcal{X})$ for any convex function $\\psi$ Chernoff bound: $\\mathbb{P}(\\mathcal{X}\\geqslant a)\\leqslant \\underset{s\\geqslant 0}{\\min},e^{-as}M_ \\mathcal{X}(s)$ Law of Large Numbers: let $\\mathcal{X}_i$ be samples drawn from $(\\mathbb{R}^n,\\mathcal{F}^n,\\mathbb{P})$, and $\\mathbb{P}$ is such that $\\mathcal{X}_k$ has mean $\\mu$ and covariance $S$ Weak version: if $\\mathcal{Y}_ k=\\frac{1}{k}\\sum^k_{j=1}\\mathcal{X}_j$ then $$\\underset{k\\to\\infty}{\\lim} \\mathbb{P}\\left(\\left\\Vert \\mathcal{Y}_k-\\mu\\right\\Vert\u0026gt;\\epsilon\\right)=0$$ Strong version: if $\\mathcal{Y}_ k=\\frac{1}{k}\\sum^k_{j=1}\\mathcal{X}_j$ then $$\\underset{k\\to\\infty}{\\lim} \\mathcal{Y}_k=\\mu$$ Central Limit Theorem: if $\\mathcal{Y}_ k=\\frac{1}{\\sqrt{k}}\\sum^k_{j=1}S^{-1/2}\\left(\\mathcal{X}_ j-\\mu\\right)$ then $$\\underset{k\\to\\infty}{\\lim} f_{\\mathcal{Y}_k}(y_k)=\\mathcal{N}(0,I)$$ Estimation Theory Hilbert Space Projection Theorem: A Hilbert space is a complete inner product space. Let $\\mathcal{H}$ be a Hilbert space, $\\mathcal{M}$ be a closed subspace of $\\mathcal{H}$ and $z\\in\\mathcal{H}$. Then there is a unique $\\hat{z}\\in\\mathcal{M}$ which is closest to $z$: $$\\Vert z-\\hat{z}\\Vert \u0026lt; \\Vert z-y\\Vert, \\forall y\\in\\mathcal{M}, y\\neq\\hat{z}$$ Orthogonality Principle: $\\hat{z}$ is the closest point iff. $\\langle z-\\hat{z},y\\rangle=0, \\forall y\\in\\mathcal{M}$. In estimation we formulate inner product as $\\langle \\mathcal{X}, \\mathcal{Y}\\rangle=\\mathbb{E}[\\mathcal{X}\\mathcal{Y}^T]$, it\u0026rsquo;s $\\mathbb{E}[(\\mathcal{Y}-\\mathbb{E}[\\mathcal{Y}|\\mathcal{X}])h(\\mathcal{X})]=0, \\forall h(\\cdot)$. Estimation Problem: Given random vector \\mathcal{X} and random variable $\\mathcal{Y}$ with joint PDF $f_{\\mathcal{XY}}(\\cdot)$, we observe $\\mathcal{X}=x$ and we want to form an estimate of $\\mathcal{Y}$ as $\\hat{\\mathcal{Y}}=g(x)$ Minimum Mean Square Error(MMSE) Estimation: $\\hat{\\mathcal{Y}}=\\mathbb{E}(\\mathcal{Y}|\\mathcal{X})$ Target: minimize $\\mathbb{E}[(\\mathcal{Y}-\\hat{\\mathcal{Y}})(\\mathcal{Y}-\\hat{\\mathcal{Y}})^\\top]$ with $\\hat{\\mathcal{Y}}=g(\\mathcal{X})$ (arbitary $g(\\cdot)$) Linear Minimum MSE(LMMSE) Estimation: $\\hat{A}$ satisfies $\\mathbb{E}[\\mathcal{YX^\\top}]=A\\mathbb{E}[\\mathcal{XX^\\top}]$ Target: minimize $\\mathbb{E}[(\\mathcal{Y}-\\hat{\\mathcal{Y}})(\\mathcal{Y}-\\hat{\\mathcal{Y}})^\\top]$ with $\\hat{\\mathcal{Y}}=A\\mathcal{X}$ Affine Minimum MSE(AMMSE) Estimation: $\\hat{G}$ satisfies $\\mathbb{E}[\\mathcal{YX^\\top}]=G\\mathbb{E}[\\mathcal{XX^\\top}]$, $\\hat{c}=\\mu_{\\mathcal{Y}}-\\hat{G}\\mu_{\\mathcal{X}}$ Target: minimize $\\mathbb{E}[(\\mathcal{Y}-\\hat{\\mathcal{Y}})(\\mathcal{Y}-\\hat{\\mathcal{Y}})^\\top]$ with $\\hat{\\mathcal{Y}}=G\\mathcal{X}+c$ Convergence Categories: Generally we assume $n\\to\\infty$ and giving $\\mathcal{X}_n$ are random variables. Sure Convergence ($\\mathcal{X}_n\\xrightarrow{\\text{surely}}\\mathcal{X}$): $$\\forall \\omega\\in\\Omega, \\mathcal{X}_n(\\omega)\\xrightarrow{n\\to\\infty}\\mathcal{X}$$ Almost Sure Convergence ($\\mathcal{X}_ n\\xrightarrow{\\text{a.s./w.p.1}}\\mathcal{X}$, w.p.1: with probability 1): $$\\mathbb{P}(\\{\\omega\\in\\Omega:\\lim_ {n\\to\\infty}\\mathcal{X} _n(\\omega)=\\mathcal{X}\\})=1$$ Equivalent definition: $$\\mathbb{P}(\\bigcup_{\\epsilon\u0026gt;0}A(\\epsilon))=0\\;\\text{where}\\;A(\\epsilon)=\\bigcap_{N=1}\\bigcup_{n=N}\\{\\omega:|\\mathcal{X}_n(\\omega)-\\mathcal{X}(\\omega)|\\geqslant\\epsilon\\}$$ Convergence in Probability ($\\mathcal{X}_ n\\xrightarrow{\\text{in prob.}}\\mathcal{X}$): $$\\mathbb{P}(\\{\\omega\\in\\Omega:\\lim_ {nn\\to\\infty}|\\mathcal{X}_n(\\omega)-\\mathcal{X}(\\omega)|\\geqslant\\epsilon\\})=0,\\;\\forall\\epsilon\u0026gt;0$$ Convergence in Distribution ($\\mathcal{X}_ n\\xrightarrow{\\text{D}}\\mathcal{X}$): $$\\lim_ {n\\to\\infty} F_{\\mathcal{X}_ n}(x)=F_{\\mathcal{X}}(x)$$ Convergence in mean of order: ($\\mathcal{X}_ n\\xrightarrow{\\text{mean r}}\\mathcal{X}$, abbr. m.s. for $r=2$): $$\\mathbb{E}[|\\mathcal{X}_n-\\mathcal{X}|^r]\\to 0$$ $\\mathcal{X}_n\\xrightarrow{\\text{a.s./mean r}}\\mathcal{X}\\Rightarrow\\mathcal{X}_n\\xrightarrow{\\text{in prob.}}\\mathcal{X}\\Rightarrow\\mathcal{X}_n\\xrightarrow{\\text{D}}\\mathcal{X}$ Strong Law of Large Numbers (requires iid.): $$S_n=\\frac{1}{n}\\sum\\mathcal{X}_ i\\xrightarrow{\\text{a.s./m.s.}}\\mu_ \\mathcal{X}$$ Weak Law of Large Numbers (requires indentical uncorrelated distributed): $S_n\\xrightarrow{\\text{in prob.}}\\mu_\\mathcal{X}$ Central Limit Theorem (requires independent): $$\\mathcal{Y}_n=\\frac{1}{\\sqrt{n}}\\sum\\frac{\\mathcal{X}_i-m}{\\sigma}\\xrightarrow{\\text{D}}\\mathcal{N}(0,1)$$ Law of Large Numbers and Central Limit Theorem together characterized the limiting behavior of the average of samples. See Wikipedia and a proof to see their relationships.\nMiscellaneous Corollaries For random valuable that takes positive values, $\\mathbb{E}(X)=\\int^\\infty_0 \\mathbb(\\mathcal{X}\u0026gt;x)dx$ If $\\mathcal{X}_1,\u0026hellip;\\mathcal{X}_n$ are IID continuous random variables, then $\\mathbb{P}(\\mathcal{X}_1\u0026lt;\\mathcal{X}_2\u0026lt;\\ldots\u0026lt;\\mathcal{X}_n)=1/n!$ Define $\\mathcal{X}_ {(j)}$ to be the j-th smallest among $\\mathcal{X}_ 1,\u0026hellip;\\mathcal{X}_ n$. Suppose $\\mathcal{X}_ 1,\u0026hellip;\\mathcal{X}_ n$ are IID random variables with PDF $f$ and CDF $F$, then $$f_ {\\mathcal{X}_ {(j)}}(x)=\\frac{n!}{(n-j)!(j-1)!}[F(x)]^{j-1}[1-F(x)]^{n-j}f_ \\mathcal{X}(x)$$ There is a chart about Univariate Distribution Relationships\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-02-23T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/2019-02/ProbabilityNotes/","title":"Notes for Probability Theory (Basics)"},{"content":"{% note default %}\nPreface This article is a repost, originally written by David on the Prelert\u0026rsquo;s website. The original article is now only accessible on WebArchive.\nI found this article when I\u0026rsquo;m searching for the reason why Rust doesn\u0026rsquo;t have a corresponding type for long double in C/C++, which have caused some interoperability issues (see here and here). On the contrary, the languages Zig and the newly born Carbon both support f16 and f128 types (Zig also supports f80 and Carbon also supports bfloat16). But that\u0026rsquo;s not suprising because they all aim to provide max interoperability with C/C++. This article might explain some of the reason why Rust doesn\u0026rsquo;t support float types with higher precision. {% endnote %}\nContents C++ provides three floating point data types: float, double and long double. All the C++11 standard says about these types is:\nThe type double provides at least as much precision as float, and the type long double provides at least as much precision as double.\nThe set of values of the type float is a subset of the set of values of the type double; the set of values of the type double is a subset of the set of values of the type long double. The value representation of floating-point types is implementation-defined.\nHowever, almost all C++ compilers are part of a family that also includes a C compiler, and Annex F of the C99 standard is more prescriptive:\nThe float type matches the IEC 60559 single format. The double type matches the IEC 60559 double format. The long double type matches an IEC 60559 extended format, else a non-IEC 60559 extended format, else the IEC 60559 double format. Since only a complete masochist would write a C++ compiler that used different types for floating point than their closely related C compiler, in practice C++ adheres to the same rules. Certainly every C++ compiler I\u0026rsquo;ve ever worked with over the last 20 years has implemented the float and double types using the single and double precision representations defined in IEC 60559 (which is the same as IEEE 754). But there is some variation in implementations of the last of these types, long double, and this can cause problems.\nThroughout my career in software development I\u0026rsquo;ve run into several issues with the long double type, and these fall into the two basic categories of:\nLack of testing Portability Lack of testing At the end of last year I wrote about a problem that would fall into the first category. A bug in the x86_64 implementation of the powl() function in glibc went unfixed for over 5 years. I suspect if the bug had been in the more widely used pow() function then more of a fuss would have been made and somebody would have fixed it sooner. Because the long double version of the function is less widely used, the bug was left to fester.\nAnother example of the lack of testing long double gets is a problem I ran into with the IBM xlC/C++ compiler on AIX before joining Prelert. The name (hard link) through which the compiler is invoked defines how it will behave, and when invoked using the name xlC128_r it uses a 128 bit representation for long double. At one time, even the most trivial programs compiled like this would core dump. Although the bug report shows an example calling fork(), even a simple \u0026ldquo;Hello world\u0026rdquo; program would core dump on exit if compiled with the -brtl flag! Clearly all the testing had been done on the more commonly used invocations of the compiler (where long double is not 128 bits in size).\nPortability On the portability side, some gotchas to be aware of are:\nMicrosoft Visual C++ represents long double using IEEE 754 double precision – just like double (the third option permitted by C99). Therefore, making a distinction between double and long double in your code is pointless if you only ever compile with Microsoft Visual C++. But if you have to support platforms other than Windows too and use long double then you\u0026rsquo;ve built in a key difference in behaviour between the platforms that may bite you. Most other x86 compilers treat long double as being the 80 bit extended precision type as used by the x87 floating-point unit. On SPARC chips (OK I know they\u0026rsquo;re dying out) the long double type maps to a 128 bit representation, but, by default, compilers will generate code to do the operations in software rather than in hardware. This dates back to a time when most SPARC chips couldn\u0026rsquo;t do the operations in hardware and would request it be done in software using interrupts. Doing the 128 bit floating point operations in software unconditionally was faster than reacting to these interrupts. However, doing operations on long doubles in software is orders of magnitude slower than doing the same operations on doubles in hardware – some of our unit tests were 20 times slower when we encountered this problem, and the tests weren\u0026rsquo;t purely doing long double arithmetic. This is a case where code can be portable in terms of compiling and producing the correct results, but not in terms of having acceptable performance. It\u0026rsquo;s instructive to look at what other portable languages do. Java has float and double types corresponding to IEEE 754\u0026rsquo;s single and double precision representations (and unlike C++ the Java standard is very explicit about how floating point operations may be implemented). Java doesn\u0026rsquo;t make a long double type available to the programmer, presumably due to the portability issues I\u0026rsquo;ve outlined (although the standard allows the x87 extended precision format to be used in intermediate calculations done by the JVM). Python just has a float type, which is \u0026ldquo;usually implemented as a double type in C\u0026rdquo;. So, if your overall system contains components written in other languages then you\u0026rsquo;ll avoid a data interchange problem by avoiding long double. The same goes if you want to store floating point numbers in a database table – for example PostgreSQL offers real and double corresponding to IEEE 754\u0026rsquo;s single and double precision representations.\nA final advantage on x86 CPUs of sticking to float and double is that the compiler can then choose to do floating point calculations in the SSE unit of the CPU, which means two or four operations can potentially be done in parallel and function arguments passed in registers by 64 bit calling conventions are nicely in the SSE registers ready to be used. By contrast, long double variables can only be operated on in the x87 floating-point unit and are not passed in registers, slowing the program down.\nConclusion Some might say that using long double improves the accuracy of results. This may be true, but regardless of the amount of digits a fixed precision floating point type has it will be subject to loss of significance if a poorly chosen algorithm is applied to it. Using extended precision rather than double precision may mask this effect in some cases, but in the long term the only solutions are to use algorithms more appropriate for computer calculations or to somehow detect the loss of significance and replace the answer with an appropriate value.\nIn my opinion, if you want to write portable C++ code that not only compiles on multiple architectures but also doesn\u0026rsquo;t have horrendous performance problems on some architectures, long double is best avoided. That\u0026rsquo;s what we do at Prelert – our C++ code doesn\u0026rsquo;t use long double and when we use Boost we define the macro BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS so that Boost.Math doesn\u0026rsquo;t either.\n","date":"0001-01-01T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/1-01/ThePitfallOfLongDouble/","title":"The Pitfall Of Long Double"},{"content":"{% note default %}\nPreface This article is a repost, originally written by Jorengarenar. I found this article when I found that Rust doesn\u0026rsquo;t support dynamically stack allocation, and list this article in my blog for translation. If you want to read the Chinese version, please select the Chinese language at the bottom of this page. {% endnote %}\n","date":"0001-01-01T00:00:00Z","permalink":"https://zyxin.xyz/blog/en/1-01/ThePitfallOfVLA/","title":"The Pitfall Of VLA in C"}]