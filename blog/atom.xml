<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jacob Zhong</title>
  
  <subtitle>b.zyxin.xyz</subtitle>
  <link href="http://zyxin.xyz/blog/atom.xml" rel="self"/>
  
  <link href="http://zyxin.xyz/blog/"/>
  <updated>2021-10-12T21:12:20.096Z</updated>
  <id>http://zyxin.xyz/blog/</id>
  
  <author>
    <name>Jacob Zhong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一句话选择现代编程语言</title>
    <link href="http://zyxin.xyz/blog/2021-08/OneLinePerProgrammingLanguage/"/>
    <id>http://zyxin.xyz/blog/2021-08/OneLinePerProgrammingLanguage/</id>
    <published>2021-08-06T03:14:34.000Z</published>
    <updated>2021-10-12T21:12:20.096Z</updated>
    
    <content type="html"><![CDATA[<p>最近几年一直有新的编程语言变火，也不断的有新概念的出现。我一直有打算了解各种新的编程语言，并且如果有前景的话多学一门语言也是挺好的。因此本文总结我在了解一些流行的现代语言的过程中，记下来他们的各种特点。如果你也有兴趣尝试新的语言，那么希望这个文章可以帮到你~</p><p>关于语言的流行度可以参考<a href="https://www.tiobe.com/tiobe-index/">TIOBE排名</a>、<a href="https://madnight.github.io/githut">Github排名</a>和<a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages-loved">Stack Overflow排名</a>。本文也不会详细介绍每个语言的特性，因为每种语言都用非常多的特性，而且很多也都还在不断开发中。正因如此，本文的评价也仅限用与写下本博客的时候。</p><p>本文主要关注通用程序语言，对于一些领域专用语言（Domain-Specific Language）如SQL就不比较了，因为他们是你需要的时候你就会用，你不需要的话也不需要学。</p><p>关于编程语言的演变，下面是一个很精炼的图（<a href="https://infographicnow.com/educational/languages/educational-infographic-timeline-of-programming-languages-infographic/">来源点我</a>），如果想要更完整的演变关系的话可以参考维基的程序语言编年表（<a href="https://en.wikipedia.org/wiki/History_of_programming_languages">按年代</a>和<a href="https://en.wikipedia.org/wiki/Timeline_of_programming_languages">按年份</a>，推荐后面那个！），或者<a href="https://www.levenez.com/lang/">参考这个网站</a>。</p><span id="more"></span><img src="/blog/2021-08/OneLinePerProgrammingLanguage/timeline-of-programming-languages.jpg" class="" title="编程语言时间图"><h1 id="现代编程语言的特性">现代编程语言的特性<a class="header-anchor" href="#现代编程语言的特性"> ❮</a></h1><p>在介绍语言之前，首先还是要介绍以下各种编程语言的概念，不然会埋没很多语言的优秀属性。语言详细特性的比较可以参考<a href="https://en.wikipedia.org/wiki/Comparison_of_programming_languages#:~:text=General%20comparison%20%20%20%20Language%20%20,%20%20%20%2020%20more%20rows%20">维基百科的比较</a>，这里的介绍也都是粗略的简介，如果你有兴趣的话可以搜一下这些关键词了解了解~</p><ul><li><strong>面向对象(Object-Oriented)</strong>：如果有学过程序设计课程的话应该对这个是有了解的。面向对象主要指的是程序是围绕“类”(Class)来编写的。类包含了某一种对象的定义和方法，并且在此之上定义了继承关系，以便于简化代码。</li><li><strong>动态/静态类型(Dynamic/Static Type)</strong>：静态类型指的是编程语言中所有变量都必须明确指定的类型，而动态类型语言则不需要指定变量类型。这两个特点是在灵活性和程序安全性之间做的权衡。这两个特性也被称为<strong>强/弱类型</strong>。在弱类型语言中，有**鸭子类型(Duck-typing)**的概念，也就是我们不关心变量具体是什么类型，只要它提供了指定的接口就可以了。</li><li><strong>元编程(Meta-Programming)/泛型(Generic Type)</strong>：元编程指的是可以通过代码生成代码，最典型的例子就是C++的模板。而泛型在用法上很像元编程，但是它并不会显式地生成代码，而是可以看作支持带有“类型参数”的代码。</li><li><strong>命令式(Imperative)/声明式(Declarative)/函数式(Functional)</strong>：命令式语言中，你需要一步步指定程序做什么；声明式语言中，你告诉语言你想要达到什么目的；函数式语言中，函数是一等公民，函数本身定义了你想达到什么目标，而程序通过不停地调用函数来实现。</li><li><strong>并行(Parallelism)</strong>：并行指的是程序支持多个代码块同时执行。具体的并行三种方法可以参考我之前的博客<a href="/blog/2019-11/ParallelismInPythonAndCsharp/" title="《进程、线程与协程》">《进程、线程与协程》</a></li><li><strong>数据科学</strong>：一些语言是针对数据科学设计的，他们主要的特点是有对高精度数值类型和多维张量的内置支持。</li><li><strong>测试驱动(Test-driven Development)/契约式(Design by Contract)</strong>：这两个概念其实是不同的编程逻辑，测试驱动指的是程序最终的目的是通过一定的测试，而契约式编程则是指编写时，程序本身需要满足一定的条件关系。对测试和契约的支持虽然不是必须的，但是在现代大型程序中却是能大大提高程序编写效率和安全性的。</li><li><strong>虚拟机/中间语言(Intermediate Language)</strong>：不少语言都通过虚拟机来完成跨平台的实现，编程语言的虚拟机会将语言特定的中间码翻译成机器码。其代表有JVM、CLR、LLVM。</li><li><strong>垃圾回收(Garbage Collection, GC)</strong>：垃圾回收是不少语言运行时内置的功能，在有这个功能的语言中你不用操心变量的生命周期，因为对象的销毁由垃圾回收器帮你实现了。</li></ul><hr/><div class="note primary"><p>下面开始介绍我对各个主流现代编程语言的一句话评价，这些语言主要选择自上文提到的排行榜。知乎<a href="https://zhuanlan.zhihu.com/p/42534137">有个类似的贴子</a>，但是主要都是段子。</p></div><h1 id="一-N-句话描述为什么选择这门语言">一(N)句话描述为什么选择这门语言<a class="header-anchor" href="#一-N-句话描述为什么选择这门语言"> ❮</a></h1><ul><li><strong>C</strong>: YYDS，是这里面最接近汇编的语言，性能好且依赖少，C语言的ABI能够被绝大多数语言调用。</li><li><strong>CoffeeScript</strong>: 加糖版Javascript</li><li><strong>C++</strong>: 最强大的语言之一，完整的面向对象和元编程支持，兼容C</li><li><strong>C#</strong>: 语法糖超级多，最近微软拥抱开源使得编程资源也变多，比Java快</li><li><strong>D</strong>: 目标是替代C++，有很多现代语言特性的支持，如契约编程</li><li><strong>Dart</strong>: 谷歌背书的取代的Javascript的语言，但是也就仅此而已了</li><li><strong>F#</strong>: C#的函数式版本</li><li><strong>Fortran</strong>: 古老的语言，但运行非常快，甚至快过C</li><li><strong>Go</strong>: 编译巨快，独立无依赖的可执行文件，内置有完整的协程支持</li><li><strong>Groovy</strong>: Apache开发的动态类型版Java，对标Ruby</li><li><strong>Haskell</strong>: 函数式语言代表作，有很多语法概念都是从Haskell走出来的</li><li><strong>Java</strong>: 在服务器后端应用特别广的语言，有垃圾收集，包特别多</li><li><strong>Javascript</strong>: 前后端都非常流行的语言，语言灵活，被浏览器支持，也有非常多的包</li><li><strong>Julia</strong>: 面向科学计算的语言，运行速度快，内置支持多维张量，有望替代Fortran</li><li><strong>Kotlin</strong>: JetBrains开发的加语法糖的Java，而且都是很现代的语法糖，可以编译为Java或者Js</li><li><strong>Matlab</strong>: 针对工程师和科学家的语言，工具包非常全，Simulink暂无敌手</li><li><strong>Objective-C</strong>: 有啥优点吗？</li><li><strong>Perl</strong>: 适合用作脚本语言或者胶水语言，字符串处理方便</li><li><strong>PHP</strong>: 可以嵌入HTML，灵活，语法简单，针对服务器端</li><li><strong>Python</strong>: 非常灵活，所有东西都是对象（包括类、函数），可读性强，与C/C++兼容好，包非常丰富</li><li><strong>R</strong>: 针对统计科学家的语言，包也很全</li><li><strong>Ruby</strong>: 链式调用、语法糖、跟Python一样的灵活性</li><li><strong>Rust</strong>: 语法保证的内存安全、无垃圾回收、也就意味着运行很快</li><li><strong>Scala</strong>: 相比于Kotlin，像是JVM上的C++，而Kotlin像是JVM上的C#</li><li><strong>Swift</strong>: 苹果开发来用以替代Obj-C的语言，定位上类似Java</li><li><strong>Typescript</strong>: 强类型版的Javascript</li><li><strong>Vala</strong>: 目标是替代C/C++在Linux的GUI编程中的地位，可以编译成C代码，因此性能不错</li><li><strong>Visual Basic</strong>: 微软曾经在很多软件中都内置支持</li></ul><h1 id="一-N-句话描述为什么劝退这门语言">一(N)句话描述为什么劝退这门语言<a class="header-anchor" href="#一-N-句话描述为什么劝退这门语言"> ❮</a></h1><ul><li><strong>C</strong>: 功能过于简陋，需要用结构体和指针实现面向对象，不安全</li><li><strong>CoffeeScript</strong>: 感觉没有核心竞争力，更多的人会用Typescript</li><li><strong>C++</strong>: 模板编译难以纠错，编译也很慢，语法糖靠各种模板和标准库实现，不优雅，</li><li><strong>C#</strong>: .NetStandard标准混乱，API经常变且不向后兼容</li><li><strong>D</strong>: 没有好爹，没有生态</li><li><strong>Dart</strong>: 感觉不如选择Typescript</li><li><strong>F#</strong>: 没人用哈哈哈哈，要么都去用C#了</li><li><strong>Fortran</strong>: 老式语法，没有什么现代语言特性</li><li><strong>Go</strong>: 没有泛型、不许有未使用的变量和模块</li><li><strong>Groovy</strong>: 如果不限于JVM平台的话有更好的选择</li><li><strong>Haskell</strong>: 学它像是搞工程的人去学理论数学，包也不多</li><li><strong>Java</strong>: 语法繁琐落后，不如C#写着优美，也不如C#性能好</li><li><strong>Javascript</strong>: 单线程，语言过于不严格，参见下面著名的三位一体图</li></ul><img src="/blog/2021-08/OneLinePerProgrammingLanguage/js-triangle.jpg" class="" title="Javascript等号三位一体"><ul><li><strong>Julia</strong>: 超级难用的包管理器，语法也很蛋疼</li><li><strong>Kotlin</strong>: 编译慢，此外没有特别大的缺点，不过如果不限于JVM平台的话有很多其他的选择</li><li><strong>Matlab</strong>: 语言本身是Mathworks的专利，并且使用一定要装Matlab软件，大部分功能都可以用Python和Julia实现了</li><li><strong>Objective-C</strong>: 只有苹果开发曾经在用，可读性差</li><li><strong>Perl</strong>: 晦涩难懂，过于灵活，性能也不行，感觉不如用Python</li><li><strong>PHP</strong>: 单线程，仅适用于Web开发，通用性和社区活跃程度不如JS</li><li><strong>Python</strong>: 性能差，单线程（GIL）</li><li><strong>R</strong>: 比Matlab语法还蛋疼</li><li><strong>Rust</strong>: 编译器太严格、字符串操作很蛋疼</li><li><strong>Ruby</strong>: 目前主要是后端工程师使用，性能差</li><li><strong>Scala</strong>: 比Kotlin难上手，与Java互操作性也较差</li><li><strong>Swift</strong>: 如果不是开发iOS和OSX没必要用</li><li><strong>Typescript</strong>: 如果不是Web开发没必要用</li><li><strong>Vala</strong>: 主要用户是Gnome和ElementaryOS，生态还不是很完善</li><li><strong>Visual Basic</strong>: 如果没有历史包袱就不要用了</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近几年一直有新的编程语言变火，也不断的有新概念的出现。我一直有打算了解各种新的编程语言，并且如果有前景的话多学一门语言也是挺好的。因此本文总结我在了解一些流行的现代语言的过程中，记下来他们的各种特点。如果你也有兴趣尝试新的语言，那么希望这个文章可以帮到你~&lt;/p&gt;
&lt;p&gt;关于语言的流行度可以参考&lt;a href=&quot;https://www.tiobe.com/tiobe-index/&quot;&gt;TIOBE排名&lt;/a&gt;、&lt;a href=&quot;https://madnight.github.io/githut&quot;&gt;Github排名&lt;/a&gt;和&lt;a href=&quot;https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages-loved&quot;&gt;Stack Overflow排名&lt;/a&gt;。本文也不会详细介绍每个语言的特性，因为每种语言都用非常多的特性，而且很多也都还在不断开发中。正因如此，本文的评价也仅限用与写下本博客的时候。&lt;/p&gt;
&lt;p&gt;本文主要关注通用程序语言，对于一些领域专用语言（Domain-Specific Language）如SQL就不比较了，因为他们是你需要的时候你就会用，你不需要的话也不需要学。&lt;/p&gt;
&lt;p&gt;关于编程语言的演变，下面是一个很精炼的图（&lt;a href=&quot;https://infographicnow.com/educational/languages/educational-infographic-timeline-of-programming-languages-infographic/&quot;&gt;来源点我&lt;/a&gt;），如果想要更完整的演变关系的话可以参考维基的程序语言编年表（&lt;a href=&quot;https://en.wikipedia.org/wiki/History_of_programming_languages&quot;&gt;按年代&lt;/a&gt;和&lt;a href=&quot;https://en.wikipedia.org/wiki/Timeline_of_programming_languages&quot;&gt;按年份&lt;/a&gt;，推荐后面那个！），或者&lt;a href=&quot;https://www.levenez.com/lang/&quot;&gt;参考这个网站&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
  </entry>
  
  <entry>
    <title>ACGN收藏 - 音频编码与格式</title>
    <link href="http://zyxin.xyz/blog/2021-07/ACGNAudioFormats/"/>
    <id>http://zyxin.xyz/blog/2021-07/ACGNAudioFormats/</id>
    <published>2021-07-21T03:26:42.000Z</published>
    <updated>2021-07-22T01:59:25.654Z</updated>
    
    <content type="html"><![CDATA[<p>在我的收藏里面，音乐是占大头的。我非常喜欢尝试各种风格的音乐，也非常喜欢日本音乐圈的多样性，因此收集了很多。在这过程中也了解到了一些音频格式的内容~我也<a href="https://github.com/cmpute/audio-codec-benchmark">自己做过一个benchmark</a>，比较不同音频编码的性能区别，如果有兴趣的话可以自己尝试一下~。</p><p>我个人喜欢收藏无损音乐，目的不仅仅是因为高音质，而是无损意味着“无损”，音质与CD或者其他音源是完全一致的（当然，这个一致性音频编码本身并不能保证音源的完整性，但是如果有其他的辅助信息如EAC log，或者AccurateRip测试结果就完全可以保证了）。在这个情况下我把无损压成有损，就能保证这个有损是达到了预期的音质。如果是网上直接下载有损的话，一是很难确定这个有损有没有经过二次压缩，造成额外音质损失，二是有损也最好不要再转换格式了，同样是因为音质损失，这就造成了额外的不便。</p><p>本文就介绍一下我了解的与音频编码相关的知识，以及各种常用音频编码格式的比较。更全面的格式对比可以<a href="https://en.wikipedia.org/wiki/Comparison_of_audio_coding_formats">参考Wikipedia页面</a>。另外需要指明的是，本文的介绍基于音乐收藏和本地播放的目的，与流媒体的需求不同，后者追求稳定的码率、低延迟甚至是低能耗。</p><span id="more"></span><h1 id="音频信号调制">音频信号调制<a class="header-anchor" href="#音频信号调制"> ❮</a></h1><blockquote><p>如果学过信号处理的读者可能已经了解本章内容了，可以跳过这节~</p></blockquote><p>在物理世界中，声音本质上是一种物体震动产生的波，如果要将物理世界中的波存储为数字世界可以存储的格式，则需要进行信号采样（模数转换）和信号调制。波形信号调制主要有两种方法，一种是脉冲编码调制（pulse-code modulation，PCM），一种则是脉冲密度调制（pulse-density modulation，PDM）。简而言之PCM就是通过数字信号的幅度和频率来分别表示模拟信号的幅度和频率，而PDM则通过数字信号的频率和幅度来分别表示模拟信号的幅度和频率（反过来了）。它们对应的音频存储格式是WAV和DSD（Direct Stream Digital），WAV由于编码简单是最广为使用的音频格式，而DSD由于技术和专利的限制则非常罕见，并且音频编辑比WAV复杂很多，因此只有在索尼的SACD上和一些高清音乐网站可以见到。</p><p>PCM的音质在频率上受限于其采样率，根据Nyquist采样定理，两倍以上的采样率可以真实还原出原波形，所以考虑到人耳的听力最高到20kHz，通常PCM音频的采样率都在40kHz以上（如常见的44.1kHz和48kHz）；在振幅上受限于其采样位深。因此采样率低会导致声音高频被裁掉，而采样位深低会导致振幅分辨率下降，音频的动态范围下降，这两者共同导致音频的失真。而PDM由于我没学过，就不评价其音质了。</p><p>在不同的采样方式之间是可能会产生额外失真的。高音质采样到低音质采样就不用说了，反过来也是可能的，如非整数倍地改变采样率（如44.1kHz到48kHz），PCM和PDM的转换。位深由于对应的是二进制的位数，非整数倍提高位深不会产生失真。</p><h1 id="有损（Lossy）编码">有损（Lossy）编码<a class="header-anchor" href="#有损（Lossy）编码"> ❮</a></h1><p>首先是有损编码，有损编码的音乐比较好找，因为（天国的）虾米、网易云、Spotify等网站都可以下到，现在很多平台都提供比较高音质的试听了。但是在曾经的年代，高音质有损编码也是比较难找的，以及现在放在手机上听歌我还是会转换成有损音质。</p><p>不同的有损格式对于“损失”音频的哪一部分、哪一频段是不一样的，他们适合的场景也不一样，比如有的格式设计之初的目的就睡尽量保留人声质量。如果真要比较哪种格式、哪种编码器的音质最好的话，只有A/B测试才是最可靠的，然而A/B测试也会受到被测对象的主观影响，所以如果想选择一个音质最好的编码器的话，可以自行A/B测试来做判断。</p><p>有损音频的音质可以通过码率（birate）直接进行优劣判断。音频的码率指的是每秒文件能够提供的信息量，以CD音质为例，普通CD一般采样率是<code>44.1kHz</code>（理论能够还原频率高达<code>22kHz</code>的波形），采样深度<code>16bit</code>，双声道，那么原始码率就是<code>44100*16*2=1141.2kbps</code>，注意这里的<code>kbps</code>是<code>kilo bits per second</code>。普通能下载到的有损音乐通常是MP3格式（虽然这年头很少有人再下载音乐了），在我高中那会，从QQ音乐等平台上上下载的MP3基本都是128kbps，只有虾米下载的是192kbps甚至320kbps，因此我还是非常喜欢虾米的。</p><p>码率是一个瞬时概念，对于音频编码（甚至视频编码）而言，码率是随时可能变化的。编码器通常提供两种码率控制方法：恒定比特率（Constant BiRate，CBR）和可变比特率（Variable BiRate，VBR）。选择CBR或者VBR需要试场景而定，CBR适合稳定的媒体串流，避免网络波动产生播放不畅，而VBR由于给了编码器更多空间根据媒体内容调节码率，通常而言可以达到更好的质量，适合本地存储回放。</p><p>一种客观的音质测试方式是直接计算编码后音频与原音频信号相差了多少。根据我的测试，有损音频的质量基本和码率成正比（见下图，如果用信号损失的对数值来看的话几乎是线性正比）。而如果使用<a href="https://en.wikipedia.org/wiki/Weighting_filter#Loudness_measurements_with_weighting_filters">根据人听力敏感度加权</a>之后的频谱，那么可以看出在低码率时（如96kbps），AAC的音质较好，这正是AAC设计的目标，即在通话音质（一般就是96kbps）下能够有很好的表现。而在高码率时（如320kbps）WavPack和MP3 CBR的表现更好，因此很多人说MP3格式应该被淘汰，但320k的MP3的音质还是非常好的。</p><p><img src="https://github.com/cmpute/audio-codec-benchmark/raw/master/figs/PLight_-_Bass_tek_2.wav.lossy_err.jpg" alt="有损音质与码率关系图"></p><p>简而言之，我的结论是在同等码率下各种有损格式的音质都差不多，更应该关注的是如何找到高码率的音源。下面介绍几个主流的有损音频编码格式。（我个人非常喜欢用WavPack的有损模式，但是这个很非主流）</p><h2 id="MP3">MP3<a class="header-anchor" href="#MP3"> ❮</a></h2><p>MP3的名字来源于其最开始是作为MPEG-1标准中的第三种音频格式，它应该是（至少在中国）最广为流传的音频编码格式了。而在支持MP3的编码器中，<a href="https://lame.sourceforge.io/">lame</a>是其中最常用的。MP3的编码特性是它会根据码率的设置进行低通滤波，320kbps CBR时滤波在20kHz左右比较接近CD音质的22kHz了，而192kbps CBR滤波则在16kHz左右，128kbps在12KHz左右。因此不同码率MP3的听感区别是非常明显的，通俗来讲音质越差的MP3越像是把喇叭蒙在鼓里的声音，各个频段的特点可以<a href="/blog/2020-12/AudiophileIntroduction/" title="参考我之前的博客">参考我之前的博客</a>。</p><p><a href="https://lame.sourceforge.io/">lame编码器</a>虽然2012年之后就几乎没有怎么更新了，但是它应该仍然是所有提供mp3的音乐平台使用的主要编码器。它支持CBR、VBR和独有的的ABR。CBR可以指定码率，VBR无法直接指定码率，而通过指定参数<code>-V</code>来间接实现码率调整，而ABR则是在可变码率的同时支持指定一个目标平均码率。</p><p>MP3虽然是个很古老的格式，并且有不少为人诟病的缺点，但是因为高码率MP3的音质确实不错，而且MP3的硬件支持非常到位，因此到现在仍然是非常流行的音频格式。</p><h2 id="AAC">AAC<a class="header-anchor" href="#AAC"> ❮</a></h2><p>AAC全名为Advanced Audio Coding，AAC设计目标是成为MP3的后继者。虽然维基上说AAC在同等码率下能够得到比MP3更好的音质，但根据我的测试结果这个结论只在相对较低码率的时候成立。不过AAC设计的定位应该就是针对流媒体，以及现在的蓝牙音频，这些地方音频的码率都是受限的，所以也不能说错。AAC比MP3支持更多的采样率、通道数，在视频编码时其实用的非常多，但是其实它不是针对音乐收藏而设计的。</p><p>AAC音频文件的后缀名通常是<code>m4a</code>和<code>mp4</code>。这两者都是MPEG-4标准定义的流媒体容器后缀名，其中前者专门针对音频，而后者则是音频和视频都可以用。关于容器是什么，我会在之后的视频编码器博客中详细介绍。</p><p>AAC音频编码器除了万能的ffmpeg以外，还有以下这些专门针对AAC的编码器</p><ul><li><a href="http://wiki.hydrogenaud.io/index.php?title=Nero_AAC">NeroAAC</a>：质量最好，但是是商用编码器，不开源。</li><li>QuickTime AAC：由苹果设计、应用在QuickTime和后来的iTunes中、口碑不错。<a href="https://github.com/nu774/qaac">有第三方开源的实现（qaac）</a>。</li><li><a href="https://github.com/knik0/faac">FAAC</a>：Free AAC，开源，但是感觉用的人不多</li></ul><p>总的而言，AAC的特性非常多，也是一个经过深思熟虑后设计的编码器，但由于是针对流媒体设计的，对音频收藏来说并没有什么吸引力。</p><h1 id="无损（Lossless）编码">无损（Lossless）编码<a class="header-anchor" href="#无损（Lossless）编码"> ❮</a></h1><p>无损编码即经过编码压缩之后不会损失信息的编码方式。如果仅仅是为了压缩而言的话，通用的文件压缩理论上也是可以用作音频编码的，但是通用压缩的效率肯定不如专门设计的音频压缩高，并且需要先解压才能播放。无损编码没有音质之差，它们的主要指标则是编码解码耗时，压缩率、对音频格式的支持以及其他附加功能。对音频格式的支持包括多声道（如5.1）、高采样率和位深（如常见的Hi-Res格式96kHz/24bit）、对DSD的支持等。</p><p>下面介绍一些常用的无损格式（其中我选择的就是WavPack）。</p><h2 id="FLAC">FLAC<a class="header-anchor" href="#FLAC"> ❮</a></h2><p>FLAC名为Free Lossless Audio Codec，虽然听起来非常老土和山寨，但应该是目前各平台最通用的格式，像是MP3在有损编码里的地位。FLAC开源、性能好、解码快、硬件支持好、压缩率也不错，无脑选flac一般没什么问题。FLAC是MPEG支持的格式，很多高质量的DVD和BD压缩出来的视频里都会用FLAC作为音频编码。因此通常情况下FLAC编码音频文件的后缀名是<code>.flac</code>，但有时你也能看到<code>.m4a</code>的后缀名。</p><h2 id="APE-TAK">APE/TAK<a class="header-anchor" href="#APE-TAK"> ❮</a></h2><p>APE（Monkey’s Audio）和TAK（Tom’s lossless Audio Kompressor）都是能够提供非常高压缩率的编码器，但是他们俩都是闭源的。在电驴（VeryCD）时代用APE的人非常多，可能就是由于其较高的压缩率吧，但是APE的编码和解码相当慢。TAK的编码解码都很快，估计是利用了多线程或者AVX加速。另外还有一款编码器叫OptimFrog，能够提供最高的压缩率，但是编码和解码都奇慢无比，更像是个Proof of concept的作品，而且还不开源，实际使用就不要考虑了。</p><h2 id="WavPack">WavPack<a class="header-anchor" href="#WavPack"> ❮</a></h2><p>这里隆重推荐我现在使用的WavPack。它开源、功能丰富、支持各种采样率位深和通道数，甚至支持DSD的编码，这个特性是别无二家了。</p><p>不过最吸引我的功能其实是支持混合编码（见后文）。WavPack由于其开源的特点，同样被各大音乐软件所支持，甚至ffmpeg和MKV视频容器都是支持WavPack的，不过MPEG-4仍然不支持比较遗憾。WavPack在硬件上支持可能没有FLAC广，但是WavPack的源码中同样包含了用汇编直接编写的几个核心函数，因此编解码的性能也是非常好的。</p><p>根据我的使用经验，WavPack有损音质好，无损体积小，编码也快，总之除了FLAC之外找WavPack就没错了！</p><h1 id="混合（Hybrid）编码">混合（Hybrid）编码<a class="header-anchor" href="#混合（Hybrid）编码"> ❮</a></h1><p>除了有损无损之外还有一种编码方式是混合编码，它指的是编码器在生成有损压缩音频后还生成一个修正文件（Correction File）。当修正文件和本体音频同时存在时原始音频可以被无损还原。这个编码方式的好处是你可以同时拥有大体积的高音质文件和小体积的低音质文件，非常适合我这样的收藏党，文件本体放在云上，然后小体积的有损部分可以经常下载下来听。有损部分也可以用作demo，如果听了demo之后喜欢上这首音乐了再去下载修正文件提高音质。</p><p>支持混合编码的主要有三种音频格式：LossyWav，WavPack和OptimFrog，其中最后一种非常难用，而且好像和LossyWAV一样不支持无损播放，即需要先解码再播放才能达到无损音质。</p><h2 id="LossyWAV">LossyWAV<a class="header-anchor" href="#LossyWAV"> ❮</a></h2><p>LossyWAV其实不算是一个完整的音频编码器，而是一个预处理软件。LossyWAV只能处理原始的PCM音频，然后生成的也是PCM音频，之后还需要使用其他的（无损）编码器来进行压缩。它的原理是分析原始音频，然后对其进行某种形式的变换使得音频更容易被压缩，从而降低生成的音频文件平均码率。由于这个变换是不可逆的，因此它也是有损压缩，但是LossyWAV支持生成修正文件，因此它可以看作一种混合编码方式。</p><p>经过以上描述，相信大家可以看出来编码过程非常麻烦，如果想要生成混合模式下的音频文件和修正文件，需要先从原始PCM音频生成有损PCM和修正PCM，然后再分别通过其他方式编码器将它们分别压缩，而无损解码的过程则是把他们反过来。因此LossyWAV在编解码速度和文件体积上都完全没有优势，并且这个原理也意味着LossyWav不支持无损播放。在能够选择WavPack的情况下还是不要用LossyWAV了。</p><h2 id="WavPack-2">WavPack<a class="header-anchor" href="#WavPack-2"> ❮</a></h2><p>WavPack内置对混合模式的支持，而且WavPack支持无损播放。这意味着只要播放器能够找到修正文件，那么播放器就能直接以无损音质播放音乐而不需要额外解码。这个特性对我来说就是killer！另外从前文图表可以看出，WavPack在有损模式下也能够达到很好的音质水平，甚至在特定码率下比MP3和AAC都要好。唯一遗憾的地方是混合模式下WavPack音频总体的压缩率是比较低的，通常会比无损模式下的体积要高出5%左右。不过这个年头存储空间越来越不值钱了，所以这个问题也完全可以忽略。</p><p>总而言之我完全找不到理由不使用WavPack，再次向大家推荐这个编码器！</p><hr/><p>本文介绍了在ACG音乐收藏的过程中我了解到的音频编码知识，而在下一篇博客我还会介绍视频编码的内容~</p><blockquote><p>参考资料：</p><ul><li><a href="https://samplerateconverter.com/educational/dsd-pcm">DSD vs PCM</a></li><li><a href="https://github.com/cmpute/audio-codec-benchmark">我自己搭的codec对比benchmark</a></li><li><a href="https://en.wikipedia.org/wiki/Comparison_of_audio_coding_formats">维基百科对音频格式的对比页面</a></li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;在我的收藏里面，音乐是占大头的。我非常喜欢尝试各种风格的音乐，也非常喜欢日本音乐圈的多样性，因此收集了很多。在这过程中也了解到了一些音频格式的内容~我也&lt;a href=&quot;https://github.com/cmpute/audio-codec-benchmark&quot;&gt;自己做过一个benchmark&lt;/a&gt;，比较不同音频编码的性能区别，如果有兴趣的话可以自己尝试一下~。&lt;/p&gt;
&lt;p&gt;我个人喜欢收藏无损音乐，目的不仅仅是因为高音质，而是无损意味着“无损”，音质与CD或者其他音源是完全一致的（当然，这个一致性音频编码本身并不能保证音源的完整性，但是如果有其他的辅助信息如EAC log，或者AccurateRip测试结果就完全可以保证了）。在这个情况下我把无损压成有损，就能保证这个有损是达到了预期的音质。如果是网上直接下载有损的话，一是很难确定这个有损有没有经过二次压缩，造成额外音质损失，二是有损也最好不要再转换格式了，同样是因为音质损失，这就造成了额外的不便。&lt;/p&gt;
&lt;p&gt;本文就介绍一下我了解的与音频编码相关的知识，以及各种常用音频编码格式的比较。更全面的格式对比可以&lt;a href=&quot;https://en.wikipedia.org/wiki/Comparison_of_audio_coding_formats&quot;&gt;参考Wikipedia页面&lt;/a&gt;。另外需要指明的是，本文的介绍基于音乐收藏和本地播放的目的，与流媒体的需求不同，后者追求稳定的码率、低延迟甚至是低能耗。&lt;/p&gt;</summary>
    
    
    
    <category term="ACGN" scheme="http://zyxin.xyz/blog/categories/ACGN/"/>
    
    
  </entry>
  
  <entry>
    <title>MegaFavNumbers - 最喜爱的百万数字</title>
    <link href="http://zyxin.xyz/blog/2021-07/MegaFavNumbers/"/>
    <id>http://zyxin.xyz/blog/2021-07/MegaFavNumbers/</id>
    <published>2021-07-12T01:46:26.000Z</published>
    <updated>2021-07-28T16:17:12.989Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客也是拖了很久了，简直是蹭热度都蹭不到热的。。。去年年底有一帮数学家和喜欢数学的人（Numberphile）发起了一个Youtube系列，叫<a href="https://www.youtube.com/hashtag/megafavnumbers">#MegaFavNumbers</a>，也就是介绍自己最喜欢的大于一百万的数字。虽然没有要求这个数字是整数，但是Numberphile一般只关注整数（甚至仅自然数）。如果没有这个限制的话，那物理化学上就有很多常数了，例如某视频评论区有人提到阿伏伽德罗常数23333</p><p>如果让我来选的话我还真想不太出来，毕竟没学多少数学，顶多会选$2^{32}$这种程序员知道的数字，或者已知最大的质数、孪生质数云云。这个题目真的是很有意思了，很多有特殊性质的数字或者是某数列的第一个数都会比较小，很少会有一个非常大并且独一无二的数字，因此看了3Blue1Brown的视频之后我顿时就来了兴趣，<s>准备</s>写下这篇博客介绍以下各博主选择的数字，又了解一些平常不知道的冷知识~哈哈。我大致将这些数字分了个类，不过不是很严格。</p><span id="more"></span><h1 id="某特殊数列中第一个超过1M的">某特殊数列中第一个超过1M的<a class="header-anchor" href="#某特殊数列中第一个超过1M的"> ❮</a></h1><ul><li><a href="https://www.youtube.com/watch?v=b1wWGRZ9YTE">3 628 800</a> by @Peter Pike：第一个超过1M的阶乘。作者讲了一堆和阶乘有关的可视化，但是数字本身其实比较直观了。</li><li><a href="https://www.youtube.com/watch?v=dJ6pej8SihI">10<sup>69</sup>+69</a> by @Kevin Du：$10^x+x$数列中第个3质数（前两个是$10^1+1$，$10^9+9$），即<a href="https://oeis.org/A089379">OEIS数列A089379</a>的第三个数 （不是很知道为什么没有选$10^9+9$ ┑(￣Д ￣)┍）</li><li><a href="https://www.youtube.com/watch?v=A7eJb8n8zAw">≈1.1698e45</a> by @Stand-up Maths：满足$\tan( p )&gt;p$的第一个质数p，即<a href="https://oeis.org/A249836">OEIS数列A249836</a>中的第一个质数。</li><li><a href="https://www.youtube.com/watch?v=Z3xq4ODNeZs&amp;t=208s">$C^{104}_{39}$</a> by @Zoe Griffiths：在杨辉三角里出现超过5次的数中，大于1M的第一个数。神奇的是前一个数是24310，然后突然就变得很大了！</li><li><a href="https://www.youtube.com/watch?v=a9k_QmZbwX8">640 320<sup>3</sup></a> by @Richard E. BORCHERDS：$\approx e^{\pi\sqrt{163}}-744$。取这个数的原因是它与$e^{\pi\sqrt{67}}-744$和$e^{\pi\sqrt{93}}-744$都神奇地非常接近一个整数，其背后的原因跟椭圆模函数$1/q+744+196884q+21493760q^2+…$有关。这个数由传奇印度数学家Srinivasa Ramanujan发现，也被称为Ramanujan常数，计算这个数需要支持任意精度浮点运算的计算器。</li><li><a href="https://www.youtube.com/watch?v=kIE2JZTwv_k">23 240 400<sub>6</sub> = 720 720<sub>10</sub></a> by jan Misali：即六进制表示的720720。720720是接近1M的超级合数（令$d(n)$表示$n$的因数个数，$f_\epsilon(n)=d(n)/n^\epsilon$，超级合数则是满足$\forall k\in\mathbb{Z}^+$, $k&lt; n, d(n)&gt;d(k), f_\epsilon(n)\geq f_\epsilon(k)$的数$n$），即<a href="https://oeis.org/A002201">OEIS数列A002201</a>中接近1M的一个很满足强迫症的数。博主为了让它超过1M换成了6进制哈哈哈哈。</li></ul><h1 id="某特殊数列最后一个数">某特殊数列最后一个数<a class="header-anchor" href="#某特殊数列最后一个数"> ❮</a></h1><ul><li><a href="https://www.youtube.com/watch?v=5BFDdVqAFZE">73 939 133</a> by @Flammable Maths: 最大的可右截断素数（right truncatable prime），即<a href="http://oeis.org/A024770">OEIS数列</a>最后一个数。</li><li><a href="https://www.youtube.com/watch?v=lKjR60jkUQE">≈1.151322e38</a> by @Normalized Nerd：十进制下最后一个水仙花数，即<a href="http://oeis.org/A005188">OEIS数列A005188</a>最后一个数。</li><li><a href="https://www.youtube.com/watch?v=RAKWgYDcB4k">$3\times2^{402653209}-1$</a> by @timpa’s videos: 从4开始的Goodstein序列的最大一个数，即<a href="http://oeis.org/A005188">OEIS数列A056193</a>中最大数。</li></ul><h1 id="某猜想的第一个正例或者反例">某猜想的第一个正例或者反例<a class="header-anchor" href="#某猜想的第一个正例或者反例"> ❮</a></h1><ul><li><a href="https://www.youtube.com/watch?v=eQCUPQdi6DY">906 150 257</a> by @SparksMaths：<a href="https://en.wikipedia.org/wiki/P%C3%B3lya_conjecture">Pólya猜想</a>的最小反例。<a href="https://www.zhihu.com/question/37164066/answer/71589759">这里有个知乎回答提到了这个例子</a>。</li><li><a href="https://www.youtube.com/watch?v=R2eQVqdUQLI">666 030 256, 696 630 544</a> by @singingbanana：偶亲和数猜想：“偶数亲和数之和为9的倍数”的第一个反例。（亲和数对：A的所有真因数之和等于B，B的所有真因数之和等于A）</li><li><a href="https://www.youtube.com/watch?v=vv0bHK44Q1s">569 936 821 221 962 380 720</a> by @Numberphile：一个著名猜想的任意整数可以写成三个整数的三次方之和，其中$3=x^3+y^3+z^3$的解除了(1,1,1)，(4,4,-5)外找到的第三个解中的正数即为博主选择的数。</li><li><a href="https://www.youtube.com/watch?v=L4ArlAfKTLA">≈8.42443e51</a> by @WillsWei：使得$n^{17}+9$和$(n+1)^{17}+9$不互质的第一个$n$。</li></ul><h1 id="来自非数学领域的数">来自非数学领域的数<a class="header-anchor" href="#来自非数学领域的数"> ❮</a></h1><ul><li><a href="https://www.youtube.com/watch?v=bknybcgfjAk">1 094 795 585</a> by @LiveOverflow：<code>0x41414141</code>，即ASCII码表示的<code>AAAA</code>，被视作缓存溢出的标志</li><li><a href="https://www.youtube.com/watch?v=pCNVkUYUnrY">≈1.01971e1400</a> by @The Comamba: $k\cdot 256^{211}+99$，其中<code>k</code>是一段破解DVD加密的代码的二进制表示。由于这段代码不合法，一个程序员用这个数把它加密成一个质数然后上传到了一个质数网站，也是很有想法了！</li><li><a href="https://www.youtube.com/watch?v=QqbDLoNHqDk">6.187e34</a> by @Tom Rocks Maths: $1/l_p$，$l_p$代表普朗克长度。普朗克提出世界不是连续的，因此普朗克常数就可以用来用整数表达这个世界！</li><li><a href="https://www.youtube.com/watch?v=Zx5B0imgrS8">1 056 006</a> by @Eddie Woo：悉尼歌剧院房顶的瓷砖数，surprise！哈哈哈哈！</li><li><a href="https://www.youtube.com/watch?v=_Y-HRGdYr9s">1 597 463 007</a> by @Rodrigo Aldana: 快速开方算法中的magic常数<code>0x5f3795df</code></li></ul><h1 id="其他">其他<a class="header-anchor" href="#其他"> ❮</a></h1><ul><li><a href="https://www.youtube.com/watch?v=4g_OjRB0wCE">≈4.3252e19</a> by @David Dijon 和 @Philip Hintze: 魔方的组合可能数。</li><li><a href="https://www.youtube.com/watch?v=2SBqn9EaMg0">302 575 350</a> by @blackpenredpen：买到Mega Million彩票的可能性。</li><li><a href="https://www.youtube.com/watch?v=P7Fbfu584ts">12 345 679</a> by @TyYann：也是个很有名的数字了，12345679$\times$11 = 111111111。作者因为小时候的回忆而选择了它。</li><li><a href="https://www.youtube.com/watch?v=mH0oCDa74tE">≈8.08e53</a> by @3Blue1Brown：“魔群”（Monster Group）的大小。魔群是“散在单群”（Sporadic Simple Groups）中最大的群。推荐看完整原视频，解释这个概念也是非常麻烦了。。。另外<a href="https://www.zhihu.com/question/47850518/answer/358979421">知乎这也有个很棒的回答</a>。这个数是我觉得这系列里面最有意思的，一个数学中应该是非常基础的概念里面竟然会有这么大的尺寸，非常神奇！</li></ul><hr/><p>时间有限，这里只总结了这么多。有一类数字没有加进来，就是专门生成大数字的运算符，所产生的最小数字。。。因为不好打出来所以没放。这个合作系列一共有200多个视频，如果有兴趣的话可以去<a href="https://www.youtube.com/hashtag/megafavnumbers">Youtube列表里面查看</a>~另外对有兴趣探寻这些数字游戏的人，我也推荐<a href="https://projecteuler.net/">Project Euler</a>，里面有很多找数字的题目，同时满足了对数字的好奇心和编程练习~</p><blockquote><p><strong>参考链接</strong>：</p><ul><li><a href="https://www.youtube.com/hashtag/megafavnumbers">Youtube #MegaFavNumbers</a></li><li><a href="https://www.zhihu.com/question/37164066">数学史上有哪些看似成立的算式形式猜想，最终被某个大数证明不成立？ - 知乎</a></li><li><a href="https://www.zhihu.com/question/47850518">数学中的“怪兽群”是什么概念</a></li><li><a href="https://projecteuler.net/">Project Euler</a></li><li><a href="https://johncarlosbaez.wordpress.com/2018/09/20/patterns-that-eventually-fail/">Patterns That Eventually Fail</a></li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇博客也是拖了很久了，简直是蹭热度都蹭不到热的。。。去年年底有一帮数学家和喜欢数学的人（Numberphile）发起了一个Youtube系列，叫&lt;a href=&quot;https://www.youtube.com/hashtag/megafavnumbers&quot;&gt;#MegaFavNumbers&lt;/a&gt;，也就是介绍自己最喜欢的大于一百万的数字。虽然没有要求这个数字是整数，但是Numberphile一般只关注整数（甚至仅自然数）。如果没有这个限制的话，那物理化学上就有很多常数了，例如某视频评论区有人提到阿伏伽德罗常数23333&lt;/p&gt;
&lt;p&gt;如果让我来选的话我还真想不太出来，毕竟没学多少数学，顶多会选$2^{32}$这种程序员知道的数字，或者已知最大的质数、孪生质数云云。这个题目真的是很有意思了，很多有特殊性质的数字或者是某数列的第一个数都会比较小，很少会有一个非常大并且独一无二的数字，因此看了3Blue1Brown的视频之后我顿时就来了兴趣，&lt;s&gt;准备&lt;/s&gt;写下这篇博客介绍以下各博主选择的数字，又了解一些平常不知道的冷知识~哈哈。我大致将这些数字分了个类，不过不是很严格。&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="http://zyxin.xyz/blog/categories/Misc/"/>
    
    
    <category term="Math" scheme="http://zyxin.xyz/blog/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>ACGN收藏 - 文件管理</title>
    <link href="http://zyxin.xyz/blog/2021-07/ACGNFileManagement/"/>
    <id>http://zyxin.xyz/blog/2021-07/ACGNFileManagement/</id>
    <published>2021-07-10T20:10:21.000Z</published>
    <updated>2021-07-27T04:57:40.530Z</updated>
    
    <content type="html"><![CDATA[<p>对于ACGN收藏来说，文件管理是一个基础任务，毕竟收藏的文件内容多种多样，例如光盘镜像、压制后的音频视频、小册子扫描、字幕甚至小游戏等。把文件按一定结构整理是必要的，我也专门为整理音乐写了<a href="https://github.com/cmpute/Fluss">一些小工具</a>，不过整理文件的格式因人而异，也没有特别的难度，因此不需要特别描述我是怎么做的。我觉得值得一提的内容是如何对文件进行定期存档和备份，这也是我在硬盘被偷之后立马开始对收藏的文件进行的操作。备份有一个3-2-1的原则：3份备份，2份本地，1份云端，下面会介绍一些本地的备份和云端备份的方法以及我的选择。</p><h1 id="离线备份">离线备份<a class="header-anchor" href="#离线备份"> ❮</a></h1><p>离线备份就是把文件资料整理并存储到另一个设备上，需要考虑的功能有加密、压缩、增量更新、去重、冗余等。如果是最基本的备份，如果只想直接备份，不考虑加密压缩等的话，著名的<a href="https://rsync.samba.org/">rsync</a>是个不错的选择，它可以同步两个目录（可以是挂载FTP的目录），并且有算法来进行去重以减少二进制的传输。</p><span id="more"></span><p>对我而言最大的需求是有冗余（指恢复记录，Recovery Record）和分卷，因为之前有在光盘上存一部分的音乐，而最后有几个压缩包已经无法恢复了，光这一条一卡几乎没剩下几条选项，可以参考<a href="https://en.wikipedia.org/wiki/List_of_archive_formats#Data_recovery">维基百科</a>。内置支持恢复记录的格式最著名且常用的有WinRAR（虽然不开源），另外剩下的里面开源的只有DAR，FreeArc。FreeArc已经10年没更新了，并且代码是毛子用Haskell写的，注释都是俄语。。因此就不考虑了。如果考虑外部支持的话最常用的就是Par2标准。下面对比几种（文件级别）方案的区别</p><blockquote><p>如果有多盘的话那么RAID就是不二选择了。不过选择文件系统以及组RAID或者NAS都是比较折腾，而且多数情况下需要Linux，我现在平时还是难免用Windows当主力，换成Linux做备份还是麻烦，因此本文就不介绍支持备份功能的文件系统了。如有兴趣可以自行了解<a href="https://www.openzfs.org">ZFS</a>、<a href="https://btrfs.wiki.kernel.org/index.php/Main_Page">Btrfs</a>或者<a href="https://wiki.archlinux.org/title/XFS">XFS</a>+<a href="https://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)">LVM</a>。这方面还有有很多博文可以参考（如<a href="https://markmcb.com/2020/01/07/five-years-of-btrfs">这一篇ZFS和Btrfs的比较</a>，以及<a href="https://ownyourbits.com/2019/03/03/how-to-recover-a-btrfs-partition/">这一篇如何从Btrfs恢复数据</a>）</p></blockquote><h2 id="WinRAR">WinRAR<a class="header-anchor" href="#WinRAR"> ❮</a></h2><p><a href="https://www.rarlab.com/">WinRAR</a>除了不开源之外其实没有任何大毛病，它的解压部分也是开源的，因此不用担心以前的rar压缩包以后会打不开。主要的缺陷是WinRAR对增量更新几乎没有支持，最多<a href="https://x443.wordpress.com/2012/07/11/winrar-incremental-differential-backup/">通过文件flag来实现</a>，因此不必指望RAR做增量更新了。如果只是想把收藏做个镜像，那WinRAR就很方便了，有不错的压缩和加密，而且内置支持分卷和恢复记录，这两个功能到2021年仍然是独一家。</p><h2 id="DAR-Par2">DAR + Par2<a class="header-anchor" href="#DAR-Par2"> ❮</a></h2><p>DAR是一个设计来替代Tar的文档格式，内置对Par2的支持，并且支持增量更新，对大量数据的备份其实挺友好的。<a href="https://en.wikipedia.org/wiki/Parchive#Par2">PAR2</a>是个给文件生成外部恢复记录的标准，可以生成一些恢复记录文件，当数据主体文件有一些损坏的时候，可以使用PAR2文件进行恢复，并且PAR2文件本身也是能够允许一部分损坏的。这个方案其实功能上来说很不错，但是由于是针对Linux设计的，对Windows支持用cygwin太不友好了。此外DAR的软件支持也不是很全，不知道为什么没有流行起来。</p><h2 id="7zip-Par2">7zip + Par2<a class="header-anchor" href="#7zip-Par2"> ❮</a></h2><p>如果不限打包软件（不要求对Par2的直接支持和增量更新）的话7zip应该是当前评价最高的压缩软件了。7zip + Par2是个不错的选择，不过设置Par2的参数就有一些麻烦了。这个方案相比WinRAR的优势仅仅在于7zip和Par2都是开源的。7zip有个额外的坏处是它的slice每个分区不能独立打开，rar的话每个slice包都有对应的文件可以解压。Par2相比WinRAR的修复好处在于它可以progressively提供冗余，就是下载的冗余文件不够的话可以下载更多冗余文件来进行修复，弱势是它不能处理32767以上个文件，因此必定需要跟某个archive格式一起使用。</p><h2 id="7zip-SeqBox">7zip + SeqBox<a class="header-anchor" href="#7zip-SeqBox"> ❮</a></h2><p>除了冗余数据之外，另一种保护对象是磁盘系统的文件头。SeqBox是一个用来保护<strong>单一</strong>文件在磁盘文件系统损坏的情况下仍能恢复数据的通用工具，其工作原理是将文件分割成尺寸小于硬盘扇区（sector）大小的块，每个文件块有独立的包含文件UID的文件头，这样哪怕分区表损坏，指定文件还是可以通过一次全盘扫描恢复出来。而BlockyArchive则是基于此之上的改进版，给每个文件块加上了冗余码，使得文件本身的损坏也可以得到恢复。这个方法对数据长期冷存储应该是很有用的。不过它会产生不小的额外存储开销，并且对应的功能其实更适合通过文件系统本身来解决，例如之前提到的著名的ZFS和Btrfs。</p><h1 id="在线备份">在线备份<a class="header-anchor" href="#在线备份"> ❮</a></h1><p>由于在线存储服务商通常都会提供数据完整性check以及数据冗余存储的功能，因此对recovery record的需求没有那么大（百度网盘除外！！！辣鸡网盘下载经常文件损坏）。有许多软件支持数据同步和备份，同步比如Google Drive自带的sync，Onedrive或者<a href="https://rclone.org/">rclone</a>，他们的缺陷是没有加密、压缩，并且支持的snapshot功能有限。相比于本地备份，在线备份更关注的可能就是文件体积了，因为文件体积可能直接会影响收费策略，而冗余和备份通常会有云服务商来保证，因此去重对于在线备份来说是更重要的。</p><p>更针对性的备份软件则对这些都有支持，在<a href="https://alternativeto.net/software/time-machine/?license=opensource">这个网站有一个开源软件的list</a>。这些软件通常支持将数据备份到另一个目录、NAS或者网盘，并且定期执行增量备份。由于Windows或者Mac目前还是不可避免地成为主力系统，因此只考虑支持Windows、Mac的情况下，再加上有GUI，可选项有<a href="https://www.duplicati.com/">Duplicati</a>，<a href="https://duplicacy.com/">Duplicacy</a>，<a href="https://www.urbackup.org/impressions.html">UrBackup</a>和<a href="https://github.com/BlobBackup/BlobBackup">BlobBackup</a>。这些软件有些是针对系统备份设计的，但其实我对系统备份没有什么需求，毕竟重装系统也没有很麻烦。Duplicacy有开源CLI，但GUI是收费的，性能很好。UrBackup的UI都很简陋，而且感觉更新不勤。BlockBackup是个定位简洁的产品，看下来Duplicati和Duplicacy还是个不错的选择，Duplicati支持的后端更多，而Duplicacy的性能更好并且更稳定。关于这些选择有不少比较，例如<a href="https://forum.duplicati.com/t/big-comparison-borg-vs-restic-vs-arq-5-vs-duplicacy-vs-duplicati/9952">Duplicati的论坛里</a>，<a href="https://github.com/gilbertchen/benchmarking">Duplicacy作者的benchmark</a>，可供参考。目前我的选择是Duplicacy，因为稳定并且高效。但Duplicacy由于算法特性，产生的文件块比较小，因此对于大数量的小文件备份不是很友好，如果之后要做日常文件备份的话可能还是会考虑Duplicati。</p><p>这里提以下去重（Deduplication）和<a href="http://dar.linux.free.fr/doc/usage_notes.html#Decremental_Backup">增量（Incremental）/减量（Decremental）/差分（Differential）备份</a>的区别，通常增量备份仅仅会保留完整的新文件而可以跳过没有改动的文件（类似Git的模式），对文件中不同的部分一般不做处理，但在这种情况下如果有大文件进行了内容修改，则会产生大量的浪费，因此有专门的去重算法来针对文件整体内容进行去重，其本质上就是将所有文件看作一个大文件，然后通过特定的方法拆分（通常是使用<a href="https://en.wikipedia.org/wiki/Rolling_hash">Rolling hash</a>）来达到快速查重的效果。这样的一个比较大的问题就是文件会被分成很多小块（通常只有几个MB），因此对于文件传输来说其实很低效（例如上传到网盘、拷入备用磁盘等），并且将文件分块太细也会带来一定的性能和容量损失。在文件内容大部分为大文件，并且不会内部进行小修改的时候，这样的操作其实比较浪费时间。</p><p>这里提到的在线备份工具都可以把本地磁盘看作一个备份目的地，因此也可以用作离线备份。另外离线备份也可以通过同步工具（如rclone）变成在线备份。上文提到的离线备份一般不能做到multi-version（除了ZFS），不过对于比如我这个音乐收集的任务来说，历史记录不是非常重要，因此也是个可行的方案。</p><h1 id="网站归档">网站归档<a class="header-anchor" href="#网站归档"> ❮</a></h1><p>还有一个比较另类的需求，我不仅想备份自己的文件，还想备份别人的<s>文件</s>网站。</p><p>很多同人社团的网站有很多信息，如Discography、世界观设定、Stuff List甚至一些正常的blog等，但是这些内容都不是持久的，很多同人社团停止活动之后网站也没了，因此也想备份他们的网站。这个需求通常可以通过知名网站<a href="https://archive.org/web/">Internet Archive</a>完成，但是这个网站因为是公益性质的，一些多媒体资源并不一定有保存下来，还是自己搭建网站爬虫会比较可靠，Internet Archive可以作为补充。</p><p>网站爬取以前是通过IDM（Internet Download Manager）可以实现，但是IDM不免费因此后面也没有用了。而单页的存档方式之前很流行的一个格式是Firefox的<a href="https://en.wikipedia.org/wiki/Mozilla_Archive_Format">maff</a>，不过Firefox也不再支持这个格式了。现在的计划是下载单独的网页用Save Page WE这个插件来完成，基本可以原封不动地备份一个网页，而对于备份整个网站，计划之后搭建一个自己的<a href="https://github.com/ArchiveBox/ArchiveBox">ArchiveBox</a>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;对于ACGN收藏来说，文件管理是一个基础任务，毕竟收藏的文件内容多种多样，例如光盘镜像、压制后的音频视频、小册子扫描、字幕甚至小游戏等。把文件按一定结构整理是必要的，我也专门为整理音乐写了&lt;a href=&quot;https://github.com/cmpute/Fluss&quot;&gt;一些小工具&lt;/a&gt;，不过整理文件的格式因人而异，也没有特别的难度，因此不需要特别描述我是怎么做的。我觉得值得一提的内容是如何对文件进行定期存档和备份，这也是我在硬盘被偷之后立马开始对收藏的文件进行的操作。备份有一个3-2-1的原则：3份备份，2份本地，1份云端，下面会介绍一些本地的备份和云端备份的方法以及我的选择。&lt;/p&gt;
&lt;h1 id=&quot;离线备份&quot;&gt;离线备份&lt;a class=&quot;header-anchor&quot; href=&quot;#离线备份&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;离线备份就是把文件资料整理并存储到另一个设备上，需要考虑的功能有加密、压缩、增量更新、去重、冗余等。如果是最基本的备份，如果只想直接备份，不考虑加密压缩等的话，著名的&lt;a href=&quot;https://rsync.samba.org/&quot;&gt;rsync&lt;/a&gt;是个不错的选择，它可以同步两个目录（可以是挂载FTP的目录），并且有算法来进行去重以减少二进制的传输。&lt;/p&gt;</summary>
    
    
    
    <category term="ACGN" scheme="http://zyxin.xyz/blog/categories/ACGN/"/>
    
    
  </entry>
  
  <entry>
    <title>ACGN 收藏者的自我修养</title>
    <link href="http://zyxin.xyz/blog/2021-07/ACGNCollection/"/>
    <id>http://zyxin.xyz/blog/2021-07/ACGNCollection/</id>
    <published>2021-07-10T19:06:42.000Z</published>
    <updated>2021-07-12T02:40:53.068Z</updated>
    
    <content type="html"><![CDATA[<p>很久没写博客了，这次想总结一下自己在ACGN收藏这条道路上越走越远，到底都走了哪些弯路哈哈哈哈 <s>（博客画风突变）</s>。这一篇算是一个开篇稿吧，想写的内容有挺多的，一些比较短的内容会放在这一篇底下。</p><span id="more"></span><p><a href="https://en.wikipedia.org/wiki/ACG_(subculture)">ACGN</a>即Animation、Comics、Games、Novel，不知道这个年头还有多少人用这个词，但是这个词确实描述了我的兴趣爱好。虽然ACGN从名字上来看没有特定的文化限制，但是一般都是指源自日本的（日本的文化输出是不得不服啊），尤其是Animation这个词，通常在ACG里面的A其实指的是Anime（Animation的日式发音缩写），特指日本动漫。鄙人虽然喜欢看（日本）动漫小说等，算的上半个二刺螈，但是ACGN产业本身也是良莠不齐的文化产品，其中有很多优秀的产品，也不乏令人无语的奇葩。</p><p>个人认为日本ACGN的吸引力不仅仅在于产品制作精良，更在于其涉猎内容的广泛以及表达形式的多样，再加上各式产业的紧密衔接，让人很容易进这个坑里。我从初中入宅以来也接触了很多ACGN的内容，不过主要是看动漫去了，小说漫画看了个别，而日式游戏基本只接触过俩：雀龙门和东方系列。但真正让我入坑收藏的其实是从东方接触到的同人音乐，同人音乐的世界包罗万象，而又大多是限量发售，因此就勾起了我的收藏欲。之后渐渐的不仅收藏同人音乐，也去收藏起ACGN的产品了。</p><p>以前作为一个高中生，实在是没有什么存储资源存那么多的内容，不过现在好很多了，但是却也没有精力去整这些东西了。更悲催的是大二硬盘被偷了一次，导致我一半的收藏没了，也导致我很长一段时间再也没有收藏的欲望了。。。（于是落下了很多坑，悔不当初）</p><p>之后的几篇博文想介绍以下几个内容，虽是由我收藏的爱好衍生出来的一些技术，但也可以适用于很多其他的场合，因此有想把他们写下来的动力：</p><ol><li><a href="/blog/2021-07/ACGNFileManagement/" title="文件管理">文件管理</a></li><li>音频压制</li><li>音乐整理与播放器</li><li>视频压制</li><li>网页打包</li></ol><p>这篇就写到这里了，希望这个博客的坑最后也能填完orz。。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很久没写博客了，这次想总结一下自己在ACGN收藏这条道路上越走越远，到底都走了哪些弯路哈哈哈哈 &lt;s&gt;（博客画风突变）&lt;/s&gt;。这一篇算是一个开篇稿吧，想写的内容有挺多的，一些比较短的内容会放在这一篇底下。&lt;/p&gt;</summary>
    
    
    
    <category term="ACGN" scheme="http://zyxin.xyz/blog/categories/ACGN/"/>
    
    
  </entry>
  
  <entry>
    <title>“音频发烧友” / “Audiophile” 入门及杂谈</title>
    <link href="http://zyxin.xyz/blog/2020-12/AudiophileIntroduction/"/>
    <id>http://zyxin.xyz/blog/2020-12/AudiophileIntroduction/</id>
    <published>2020-12-17T03:23:00.000Z</published>
    <updated>2021-07-12T02:40:53.068Z</updated>
    
    <content type="html"><![CDATA[<p>最近买了一些新的耳机，但是买完总感觉自己被收智商税了，于是就查查查了好多资料。这篇文章介绍我理解下音频发烧友的一些词汇是什么意思，如果你不烧耳机音响，但是想了解这个群体的，这个文章也能作为一个入门参考～Hifi领域有很多词汇我也没懂的，我也写在文章里了，如果有老烧路过请指教一二。我尝试用我学过的知识来客观解释音频领域的知识，我没上过信号处理，相关课程只上过自动控制和离散控制。</p><h1 id="发烧到底追求的是什么">发烧到底追求的是什么<a class="header-anchor" href="#发烧到底追求的是什么"> ❮</a></h1><p>刚好今天有看到<a href="https://www.youtube.com/watch?v=rM8sxFxmOUw">一个Youtube视频</a>讲到，为什么音乐人并不care那些高端的音频设备。视频内容本身的观点是：一方面音乐人更关注的是音乐本身能不能打动人，另一方面是音乐人很多也没有那么多闲钱哈哈哈。以及底下的评论有很多人说自己是pro musician，然后疯狂喷audiophile追求的东西是虚无飘渺的。我承认烧音频领域有很多玄学都是脑放（脑补出来的），但是做耳机解码之类的厂家也是有很多pro audo engineer，不能否认这里面也是有很多技术门道的。根据这一帮自称pro musician的发言，我估计他们也没有多牛，他们的观点也有幸存者偏差在里面，并且本身不同级别不同类型的音乐也有不同的需求，因此这些评论也就看看就好。不过有一点我是同意的，听音乐最重要的还是音乐本身，对音质的追求不应放于对音乐本身的追求之上。</p><p>再打个比方，对音质的追求和对画质的追求其实是相似的，好的（照片）画质能让我们看清楚世界更多的细节，好的音质能让我们更真切地感受到被乐器包围的感觉。音频处理和视频处理也有很多相似的地方，因为他们都经常被看作信号来处理，后文我也会经常拿画质来打比方。</p><span id="more"></span><h2 id="什么是好的音质">什么是好的音质<a class="header-anchor" href="#什么是好的音质"> ❮</a></h2><p>在找到了自己喜欢的音乐之后，我们当然会希望手里的设备能更好的还原音乐本身，能听到每一点细节。因此对音质好的标准在我看来（我相信也是大多数人的观点），指的是<strong>耳朵听到的声音感觉和你站在录音的地方听到的声音感觉非常相似</strong>。由此可见在现场听，在乐器和人声面前听才能获得<strong>完美的音质</strong>，这是音质的金标准。当然这个也不是那么统一的，例如我并不觉得在歌手演唱会听到的音乐会比手机放出来的好听，因为演唱会非常嘈杂并且音响素质也不见得很好；但如果是在音乐厅听交响乐，我可以拍胸脯保证听到的声音远超电子设备播放出来的。又比如我还听很多电子音乐，里面很多音色都是直接合成出来的，那就无法通过这样的标准来定义了，这种情况下最好的音质可以定义成<strong>你听到的声音和音乐人以及调音师想让你听到的声音一致</strong>。</p><p>上面提到的音质是可以客观定义和测量的，但是另一部分人追求的音质则是他听到的声音符不符合他的口味，例如有些人喜欢温润的女声，有些人喜欢低沉的bass，这些其实都是主观的喜好。这才是发烧友的精髓——定制，就像搞机械键盘什么的，定制和折腾才是发烧友的精髓。不过我对这样的音质并没有什么追求，因为他们通常都可以通过简单的Eq（调整Equilizer）来解决。</p><h2 id="听到的声音的几个指标">听到的声音的几个指标<a class="header-anchor" href="#听到的声音的几个指标"> ❮</a></h2><p>通常对于音频发烧友来说，音质好不好是个比较笼统的词汇，因为音质好大抵是相似的，而音质差则各有各的差法。为了区分这些方面，audiophile们利用以及发明了很多与音质有关的词汇，我把比较常见的以及他们的意思列在下面了</p><table><thead><tr><th>声音基本概念</th><th>(声音的本质是声波)</th></tr></thead><tbody><tr><td>Loudness / 响度</td><td>声波的振幅，通常会取势能来计算平均振幅</td></tr><tr><td>Tone / 音调</td><td>（简单）声波的频率，真实的声音通常会是多个频率的叠加</td></tr><tr><td>Timbre / 音色</td><td>声波的形状，人通过音色区分声音的来源</td></tr></tbody></table><table><thead><tr><th>音频信号</th><th>(如何表征一个音频信号)</th></tr></thead><tbody><tr><td>Spectrogram / 频谱</td><td>频谱描述信号在各个频率上的幅度，一般通过Fourier变换计算，由于Fourier变换是可逆的，因此频谱可以唯一地对应一段声音</td></tr><tr><td>Frequency (Response) / 频率(响应)</td><td>频率响应描述输入信号和输出信号在频域上的差异</td></tr><tr><td>Phase / 相位</td><td>相位本身指周期信号中信号在周期的哪个位置，但是相位本身很少用，用的更多的是相位差。我们常用的是将相位差推广到非周期信号，然后用来描述多个声道之间的信号时间差</td></tr></tbody></table><table><thead><tr><th>可以量化的词汇</th><th>（客观描述音质）</th></tr></thead><tbody><tr><td>Bass / 低频</td><td>20Hz-20kHz的低频部分</td></tr><tr><td>Mid / 中频</td><td>20Hz-20kHz的中间部分</td></tr><tr><td>Treble / 高频</td><td>20-20kHz的高频部分</td></tr><tr><td>Imaging / 声像</td><td>声音的定位准不准，与信号相位有关。<a href="https://www.rtings.com/headphones/tests/sound-quality/imaging">可参考Rtings的测量方法</a></td></tr><tr><td>Sound Stage / 声场</td><td>感受到的空间大小，听起来音源越分散，声场越大。这个主要是针对耳机还原音箱声场的感觉，具体解释参考<a href="https://site.douban.com/widget/notes/275603/note/118007253/">豆瓣这篇文章</a>，测量方法参考<a href="https://www.rtings.com/headphones/tests/sound-quality/passive-soundstage">Rtings的测试流程</a>。</td></tr><tr><td>Dynamic Range / 动态范围</td><td>在同一段声音里同时表现幅度很大和很小的信号的能力，可以参考图像的HDR技术。</td></tr><tr><td>Transient / 瞬态</td><td>这个词我是抱有疑问的，虽然控制器确实有响应时间这个参数，但是用在声音信号上感觉并不算很合适。好像一般通过追踪方波输入来看耳机的瞬态响应。</td></tr><tr><td>Signal to Noise Ratio (SNR) / 信噪比</td><td>字面意思，信号对噪声的比。这个噪音通常是音频电路的底噪。</td></tr><tr><td>Total Harmonic Distortion (THD) / 总谐波失真</td><td>输入一个纯净正弦信号，输出里这个信号的谐波就是谐波失真。</td></tr><tr><td>Intermodulation Distortion (IMD) / 互调失真</td><td>输出两个频率的信号，测输出信号的失真</td></tr><tr><td>Crosstalk / 串扰</td><td>多通道之间的信号干扰</td></tr></tbody></table><table><thead><tr><th>玄学词汇</th><th>（主观描述音质）</th></tr></thead><tbody><tr><td>Fidelity / Resolution / 解析力</td><td>这个词可能指的是低失真？有时候感觉也指超高频的频率响应。被各种厂家的广告用烂了，没有统一的解释</td></tr><tr><td>Punchy / 力度</td><td>通常指的是低频非常重</td></tr><tr><td>Congested / 拥挤 / Shouty</td><td>大概指的是声场小，或者是中高频gain太高</td></tr><tr><td>Sharp / 锐</td><td>一般是在频谱的某一小段中高频上有刺突</td></tr><tr><td>Clean / Clarity / 通透 / 纯净</td><td>应该都指的是中高频比较突出</td></tr><tr><td>Sound quality / 音质</td><td>虽然这里我们客观地讨论了什么是好音质，但是在audiophile社区里面这个词并不都是这么定义的</td></tr><tr><td>Tonality / 调性</td><td>这个词我着实没弄懂，本身是用来形容乐曲的谱调的，但是用来形容音质我也摸不找头脑</td></tr><tr><td>Layered / 层次感</td><td>这虽然我知道是什么意思，以及能听出来区别，但是觉得这个词很模糊。我猜测它与声像和声场都有关。</td></tr></tbody></table><p>其中低中高频的区别这里贴一张<a href="https://crinacle.com/2020/04/08/graphs-101-how-to-read-headphone-measurements/">引自crinacle的图</a></p><img src="/blog/2020-12/AudiophileIntroduction/fr-chart.png" class="" title="频率对应图"><h2 id="人能听出多大差别">人能听出多大差别<a class="header-anchor" href="#人能听出多大差别"> ❮</a></h2><p>在定义了什么是好音质以后，还有个问题是人能听出来多大的音质差别？首先一个基本常识是人的听力范围是在20Hz-20kHz之间（也有说16Hz-20kHz的），这是目前通用的标准，包括音频的采样率定在44100Hz也是参考了这个数据。另外在<a href="https://www.zhihu.com/question/274582289/answer/640857360">这个知乎回答</a>里面，答主引用了这些数据：</p><blockquote><p>人耳所能感知到的纯单音变化最小幅度为0.3dB<br>人耳在最敏感的500Hz~2kHz段所能感知到的频率变化一般是0.2%<br>人耳所能感知的低次谐波失真变化最小量一般在1%上下</p></blockquote><p>以上这些数据可以作为参考，但是它们并不能作为硬性指标，例如说音频信号超过20kHz的部分就是完全没有意义的，我认为是不科学的。一是因为以上都是统计数据，不能否认现实世界有“金耳朵”的存在（不过至少我不是），二是以上数据来源于科学实验，其实验过程与我们听音乐的时候可能并不相同，有可能会导致音频敏感度的差别。不过至少这些数据让我们有一个大概的概念，如果一个音频设备带来的提升远小于这些数，那么极大概率你是听不出他们带来的区别的。</p><h1 id="发烧友字典">发烧友字典<a class="header-anchor" href="#发烧友字典"> ❮</a></h1><p>Hifi界另外一些让人摸不着头脑的地方就是，各种各样的词汇，以及这些词汇似乎指向的东西有时候也很不明确。。。这里把我自己学到的记一下。</p><h2 id="音乐播放器系统组成">音乐播放器系统组成<a class="header-anchor" href="#音乐播放器系统组成"> ❮</a></h2><p>我们这里不考虑录音室的系统组成，而只考虑用户的系统组成。</p><h3 id="音源">音源<a class="header-anchor" href="#音源"> ❮</a></h3><p>好像音源又叫<strong>前端</strong>？整那么邪乎干啥。。。音源有CD机、电脑、唱片机（俗称转盘turntable？），因为现在都是数字音乐了，因此重要的就是源文件的音质。音频格式有很多说法，首先分PCM和DSD两种，PCM是时域采样而DSD是频域采样。PCM又有很多指标，例如位深指音频每个采样的精度（通常是16bit，HiRes则有24bit以上），采样率指采样的频率，根据Nyquist-Shannon采样定律，频率高于20kHz理论上就能做到无损采样。然后音乐文件的格式又分有损和无损，有损格式如果比特率足够高还行，如果很低那就会非常严重地影响音质。然后音源会输出到数字界面。</p><h3 id="数字界面">数字界面<a class="header-anchor" href="#数字界面"> ❮</a></h3><p>虽然机油送我了一个数字界面，但是我并不能听出区别，以及我到现在也不是很清楚这个界面是干什么的。根据<a href="https://www.zhihu.com/question/30806888/answer/50247612">我知乎看到的资料</a>，数字界面是把USB信号转换成DAC芯片能够直接读取的信号。外置数字界面的好处一个是时钟（可能）比内置更加精确，另一个是给没有USB或者火线（IEEE-1394协议）接口的DAC提供输入。这里就涉及另一个玄学的概念，叫<strong>时钟抖动（Jitter）</strong>。由于数字信号的采样（指PCM）是恒定频率的，因此如果数字线路的时钟频率不稳定，是会非常影响DAC转换结果的。抖动可以来源于时钟本身（如晶振），也可能来源于数字信号传输的接口芯片。不过就像知乎另一个回答说的，一般这种抖动都非常非常细微，我并不认为这对信号能有太多影响，并且我确实也听不出来。想感受一下多玄学的可以再看看<a href="http://www.erji.net/forum.php?mod=viewthread&amp;tid=7494&amp;extra=pageD1&amp;page=">耳机大家庭的文章</a>。。。</p><h3 id="解码器（Digital-Analog-Converter，DAC）">解码器（Digital-Analog Converter，DAC）<a class="header-anchor" href="#解码器（Digital-Analog-Converter，DAC）"> ❮</a></h3><p>DAC就是数模转换器，用来将数字信号转成模拟信号。这个过程我觉得挺重要的，因为数模转换（模数转换）带来的信号损失还是很明显的。从控制理论里的零阶保持（ZOH）来理解的话，<a href="https://www.dummies.com/education/science/science-engineering/real-world-signals-and-systems-case-solving-the-dac-zoh-droop-problem-in-the-z-domain/">转换过程会影响信号的相位和高频</a>。DAC的质量在整个音频管道中还是比较重要的。另外一个特性是DAC支持的格式，现在主流的hifi解码都支持高位深和DSD的音频了。</p><h3 id="放大器（Amplifier，Amp）">放大器（Amplifier，Amp）<a class="header-anchor" href="#放大器（Amplifier，Amp）"> ❮</a></h3><p>用于音箱的一般称功放（功率放大器），用于耳机的一般称耳放。放大器的作用就是把解码出来的模拟信号放大到合适的音量。很多设备如手机，甚至一些DAC都把功放集成进去了。独立的放大器设备有两个好处，一个的更好的电磁隔离，更少的底噪，另一个是可以提供更大的功率储备，用来推特别难推的耳机（如低阻低灵敏度的耳机），在极端状态下可以减少失真。</p><p>耳放还分两种：电子管耳放（胆机），晶体管耳放（石机）。我没听过胆机，但都说胆机声音温润，估计说到底就是胆机削低了高频。因此如果纯音质角度看，选一个低失真的耳放就可以了。</p><p>功放有时分前级后级，据我查到的资料说，前级是low-pass filter，用来处理低频，然后后级整体放大？这里我也不懂了，搜到各种不一样的说法，我觉得我还是别管这玩意了。（<a href="https://www.zhihu.com/question/30806888">知乎参考在此</a>）</p><h3 id="接口">接口<a class="header-anchor" href="#接口"> ❮</a></h3><p>再讲一下不同音频设备之间的连接接口，数字的接口一般就是USB和S/PDIF了，模拟信号主要有TRS，TRRS，XLR等等，可以<a href="http://sound.zol.com.cn/512/5124960_all.html">参考这篇文章</a>。这些接口本身没什么差别，虽然说有人对这个很在意，甚至还有人对墙上插座的接口很讲究，但是我觉得这都是玄学= =（就是不科学）</p><h3 id="回放设备">回放设备<a class="header-anchor" href="#回放设备"> ❮</a></h3><p>就是音箱或者耳机，这玩意也是有各种产品。音箱分有源音箱和无源音箱，有源就是内置了放大器的。耳机则分入耳（In-ear, IEM），和头戴式耳机（On-ear/Over-ear）。具体这就不展开了。</p><h2 id="耳机相关">耳机相关<a class="header-anchor" href="#耳机相关"> ❮</a></h2><h3 id="单元">单元<a class="header-anchor" href="#单元"> ❮</a></h3><ul><li>Balanced Armerture / BA / 动铁：平衡铁通过磁场变化，带动振膜运动。</li><li>Dynamic Driver / DD / 动圈：磁场直接驱动线圈，带动振膜运动。</li><li>Planar Magnetic / 平板：磁场直接驱动金属板运动。</li><li>Piezoelectric Ceramic / 压电陶瓷单元：压电晶体带动振膜变形发声。</li><li>Electrostatic / EST / 静电：电场带动振膜运动。<br>(可以参见<a href="https://www.youtube.com/watch?v=BKhS7X8rs74">Linus的视频</a>)</li></ul><h3 id="线材">线材<a class="header-anchor" href="#线材"> ❮</a></h3><p>首先要说明的是，音频线材对声音的影响微乎其微。线材影响声音的原理是不同线材有不同的阻抗、容抗和感抗曲线（主要是阻抗和荣抗），因此可能会微微影响低阻耳机的频率响应。另外，说线材能提升音质的几乎就是扯淡。参见<a href="https://www.zhihu.com/question/274582289">该知乎回答</a>。</p><ul><li>TPC: 电解铜</li><li>OFC: 无氧铜</li><li>OCC: 单结晶无氧铜</li><li>5N/6N/7N: （铜）纯度，几个N就有几个9。</li><li>Litz/Litz2: 绕线方式，参考<a href="https://www.newenglandwire.com/product/litz-wire-types-and-constructions/">Litz官网</a>。并不知道不同绕线方法对感抗有没有什么影响。。<br>现在的线材基本都是无氧铜。个人认为为了好看和功能换线可以，为了换口味换线可以，为了增加屏蔽层减少外部信号噪音可以，但是为了“提升音质”就纯粹是智商税了。另外上面提到的都是传递模拟信号的线材，对那种audio-grade的USB线我是打死都不信有什么区别的，数字信号对这么点阻抗的变化根本不可能有什么反应。</li></ul><h3 id="耳塞-耳垫">耳塞/耳垫<a class="header-anchor" href="#耳塞-耳垫"> ❮</a></h3><p>耳塞(Tip)和耳垫(Pad)可以影响声音在进入耳朵之前的回响，因此也是会改变声音的。耳垫的影响比较大，耳塞我觉得比较小。不过同样的，我认为不同的耳塞耳垫都是相当于给耳机加了EQ，因此不必追求高音质的耳垫。有一点例外，如果耳塞耳垫有漏音的话，会严重影响音质，这种情况下就需要更换了。</p><hr/><p>这大概就是我对audiophile各种知识的笔记了。在了解这么多之后，我还是觉得，选一个小巧、功能多、性能还过得去的DAC和amp，然后选个音质够用的耳机就行了，不用再换了。音质这玩意到最后音质提升的性价比实在太低了，还是找更多好听的音乐来的实在。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近买了一些新的耳机，但是买完总感觉自己被收智商税了，于是就查查查了好多资料。这篇文章介绍我理解下音频发烧友的一些词汇是什么意思，如果你不烧耳机音响，但是想了解这个群体的，这个文章也能作为一个入门参考～Hifi领域有很多词汇我也没懂的，我也写在文章里了，如果有老烧路过请指教一二。我尝试用我学过的知识来客观解释音频领域的知识，我没上过信号处理，相关课程只上过自动控制和离散控制。&lt;/p&gt;
&lt;h1 id=&quot;发烧到底追求的是什么&quot;&gt;发烧到底追求的是什么&lt;a class=&quot;header-anchor&quot; href=&quot;#发烧到底追求的是什么&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;刚好今天有看到&lt;a href=&quot;https://www.youtube.com/watch?v=rM8sxFxmOUw&quot;&gt;一个Youtube视频&lt;/a&gt;讲到，为什么音乐人并不care那些高端的音频设备。视频内容本身的观点是：一方面音乐人更关注的是音乐本身能不能打动人，另一方面是音乐人很多也没有那么多闲钱哈哈哈。以及底下的评论有很多人说自己是pro musician，然后疯狂喷audiophile追求的东西是虚无飘渺的。我承认烧音频领域有很多玄学都是脑放（脑补出来的），但是做耳机解码之类的厂家也是有很多pro audo engineer，不能否认这里面也是有很多技术门道的。根据这一帮自称pro musician的发言，我估计他们也没有多牛，他们的观点也有幸存者偏差在里面，并且本身不同级别不同类型的音乐也有不同的需求，因此这些评论也就看看就好。不过有一点我是同意的，听音乐最重要的还是音乐本身，对音质的追求不应放于对音乐本身的追求之上。&lt;/p&gt;
&lt;p&gt;再打个比方，对音质的追求和对画质的追求其实是相似的，好的（照片）画质能让我们看清楚世界更多的细节，好的音质能让我们更真切地感受到被乐器包围的感觉。音频处理和视频处理也有很多相似的地方，因为他们都经常被看作信号来处理，后文我也会经常拿画质来打比方。&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="http://zyxin.xyz/blog/categories/Misc/"/>
    
    
    <category term="Audiophile" scheme="http://zyxin.xyz/blog/tags/Audiophile/"/>
    
  </entry>
  
  <entry>
    <title>Minecraft 1.12建服及侦测器BUD</title>
    <link href="http://zyxin.xyz/blog/2020-12/MCBud112/"/>
    <id>http://zyxin.xyz/blog/2020-12/MCBud112/</id>
    <published>2020-12-16T23:09:30.000Z</published>
    <updated>2021-07-12T02:40:53.108Z</updated>
    
    <content type="html"><![CDATA[<p>进来给实验室的服务器上装了个Minecraft服务器，给大家闲来无事上来种种菜，顺便体验一下新版本的特性。之前最高只玩过1.8，现在虽然更新到1.16了，但是听说很多Mod都还是只支持到1.12，所以就搭了1.12的服务器。基岩版的MC（Win10自带的那个）虽然性能很好，但是由于不购买就没法玩，所以考虑到大家肯定最开始都不想买，以及那个开服好像很麻烦，就还是搭了Java的服务器。</p><h1 id="一分钟上手Minecraft开服">一分钟上手Minecraft开服<a class="header-anchor" href="#一分钟上手Minecraft开服"> ❮</a></h1><p>以前玩Minecraft的时候都觉得开服务器好麻烦，要知道各种各样的配置方法，因此很佩服服主管理这些东西。直到有一天我搜到了这个：<a href="https://github.com/itzg/docker-minecraft-server">docker-minecraft-server</a>，瞬间感觉一键开服不是梦了！这个repo把Minecraft的服务器版本以及Bukkit/Spigot服务器端Mod框架（可以理解成服务器上的Forge）都嵌进去了，简直不要太方便。数据也是从host的硬盘里mount进去的，因此如果你的服务器要转移或者备份也很方便。有了这个，开服只需要一行命令（假设你服务器上有docker）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 25565:25565 --name mc -e EULA=TRUE itzg/minecraft-server</span><br></pre></td></tr></table></figure><span id="more"></span><p>由于可以设置的环境变量非常多，因此我后来把配置都写到了docker-compose文件里面，这样修改设置后启动服务器就更简单了～目前我的设置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">minecraft:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">itzg/minecraft-server</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;25565:25565&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;/home/jacobz/Minecraft/docker-data:/data&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MEMORY:</span> <span class="string">4G</span></span><br><span class="line">      <span class="attr">EULA:</span> <span class="string">&quot;TRUE&quot;</span></span><br><span class="line">      <span class="attr">VERSION:</span> <span class="number">1.12</span><span class="number">.2</span></span><br><span class="line">      <span class="attr">ENABLE_AUTOPAUSE:</span> <span class="string">&quot;TRUE&quot;</span></span><br><span class="line">      <span class="comment"># OVERRIDE_SERVER_PROPERTIES: &quot;TRUE&quot;</span></span><br><span class="line">      <span class="attr">MAX_TICK_TIME:</span> <span class="string">&quot;-1&quot;</span></span><br><span class="line">      <span class="attr">ONLINE_MODE:</span> <span class="string">&quot;FALSE&quot;</span></span><br><span class="line">      <span class="attr">TZ:</span> <span class="string">US/Eastern</span></span><br><span class="line">      <span class="attr">DIFFICULTY:</span> <span class="string">easy</span></span><br><span class="line">      <span class="attr">TYPE:</span> <span class="string">BUKKIT</span></span><br><span class="line">      <span class="attr">OPS:</span> <span class="string">cmpute</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure><h1 id="侦测器单片BUD">侦测器单片BUD<a class="header-anchor" href="#侦测器单片BUD"> ❮</a></h1><p>在服务器上玩了几天，最终还是想搭一个自动农场来解决温饱问题。再不去骗村民的情况下，最方便的食物我觉得就是南瓜饼了，它的原料（鸡蛋、糖、南瓜）都是非常好自动化的。因此我就想着顺便琢磨一下有侦测器之后自动农场有没有什么更方便的方法。甘蔗机在<a href="/blog/2017-08/MCTowerSugarcane/" title="我以前甘蔗机的博文">我以前甘蔗机的博文</a>里面有写到，侦测器搭甘蔗机的效率不如传统的BUD，因此主要可以改动的就是在南瓜机上了。感觉应该不是很难，因此我本地琢磨了一会，弄出来两种利用侦测器的单片BUD：</p><table>    <tr>        <th>上置型</th>        <th>下置型</th>    <tr>    <tr><td><link rel="stylesheet" href="/blog/css/minecraft.css" type="text/css"><p><div class="layered-blueprint" style="min-height:128px;width:128px"><input type="radio" id="mc_schematic_侧视图_0_活塞-沙子版本" class="layered-blueprint-radio" name="侧视图_0" checked></input><label for="mc_schematic_侧视图_0_活塞-沙子版本" class="layered-blueprint-tab">活塞+沙子版本</label></label><div class="layered-blueprint-layer"><table class="schematic" cellspacing="0" cellpadding="0" style="margin:0; line-height:0"><tbody><tr><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-128px -192px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-512px -96px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-32px -544px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-288px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -224px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="text">O</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-320px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr></tbody></table></div><input type="radio" id="mc_schematic_侧视图_0_粘性活塞版本" class="layered-blueprint-radio" name="侧视图_0" checked="false"></input><label for="mc_schematic_侧视图_0_粘性活塞版本" class="layered-blueprint-tab">粘性活塞版本</label></label><div class="layered-blueprint-layer"><table class="schematic" cellspacing="0" cellpadding="0" style="margin:0; line-height:0"><tbody><tr><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-512px -96px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-32px -544px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-288px -448px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -224px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="text">O</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-320px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr></tbody></table></div></div></p>    </td><td><link rel="stylesheet" href="/blog/css/minecraft.css" type="text/css"><p><div class="layered-blueprint" style="min-height:128px;width:128px"><input type="radio" id="mc_schematic_侧视图_12_活塞-沙子版本" class="layered-blueprint-radio" name="侧视图_12" checked></input><label for="mc_schematic_侧视图_12_活塞-沙子版本" class="layered-blueprint-tab">活塞+沙子版本</label></label><div class="layered-blueprint-layer"><table class="schematic" cellspacing="0" cellpadding="0" style="margin:0; line-height:0"><tbody><tr><td style="width:32px;height:32px"></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-256px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="text">O</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -224px;">&lt;br&#x2F;&gt;</span></div></td><td style="width:32px;height:32px"></td><td><div><span class="sprite schematic-sprite" style="background-position:-96px -544px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-512px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-128px -192px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-288px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr></tbody></table></div><input type="radio" id="mc_schematic_侧视图_12_粘性活塞版本" class="layered-blueprint-radio" name="侧视图_12" checked="false"></input><label for="mc_schematic_侧视图_12_粘性活塞版本" class="layered-blueprint-tab">粘性活塞版本</label></label><div class="layered-blueprint-layer"><table class="schematic" cellspacing="0" cellpadding="0" style="margin:0; line-height:0"><tbody><tr><td style="width:32px;height:32px"></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-256px -352px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="text">O</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -224px;">&lt;br&#x2F;&gt;</span></div></td><td style="width:32px;height:32px"></td><td><div><span class="sprite schematic-sprite" style="background-position:-96px -544px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-512px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-352px -736px;">&lt;br&#x2F;&gt;</span></div></td></tr><tr><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-288px -448px;">&lt;br&#x2F;&gt;</span></div></td><td><div><span class="sprite schematic-sprite" style="background-position:-0px -160px;">&lt;br&#x2F;&gt;</span></div></td></tr></tbody></table></div></div></p>    </td><tr></table><p>上图中O代表检测更新的地方，可以看见上置型的结构比下置的要稍微精简一点点，并且由于南瓜只能生成在泥土上，因此我最后使用了上置型的方法搭了自动南瓜机。对比<a href="#">Post not found: 我之前传统BUD的南瓜机方案</a>，只需要把这个结构横着堆叠一下就行，在南瓜机上面有了侦测器确实可以大大减小粘性活塞的使用。不过由于这个结构比之前的方案宽度多了一格，因此没一层可能只能容纳两排南瓜了，因此如果要更密集的堆叠可能需要考虑改进这个结构。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;进来给实验室的服务器上装了个Minecraft服务器，给大家闲来无事上来种种菜，顺便体验一下新版本的特性。之前最高只玩过1.8，现在虽然更新到1.16了，但是听说很多Mod都还是只支持到1.12，所以就搭了1.12的服务器。基岩版的MC（Win10自带的那个）虽然性能很好，但是由于不购买就没法玩，所以考虑到大家肯定最开始都不想买，以及那个开服好像很麻烦，就还是搭了Java的服务器。&lt;/p&gt;
&lt;h1 id=&quot;一分钟上手Minecraft开服&quot;&gt;一分钟上手Minecraft开服&lt;a class=&quot;header-anchor&quot; href=&quot;#一分钟上手Minecraft开服&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;以前玩Minecraft的时候都觉得开服务器好麻烦，要知道各种各样的配置方法，因此很佩服服主管理这些东西。直到有一天我搜到了这个：&lt;a href=&quot;https://github.com/itzg/docker-minecraft-server&quot;&gt;docker-minecraft-server&lt;/a&gt;，瞬间感觉一键开服不是梦了！这个repo把Minecraft的服务器版本以及Bukkit/Spigot服务器端Mod框架（可以理解成服务器上的Forge）都嵌进去了，简直不要太方便。数据也是从host的硬盘里mount进去的，因此如果你的服务器要转移或者备份也很方便。有了这个，开服只需要一行命令（假设你服务器上有docker）&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker run -d -p 25565:25565 --name mc -e EULA=TRUE itzg/minecraft-server&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="Game" scheme="http://zyxin.xyz/blog/categories/Game/"/>
    
    <category term="Minecraft" scheme="http://zyxin.xyz/blog/categories/Game/Minecraft/"/>
    
    
    <category term="Redstone" scheme="http://zyxin.xyz/blog/tags/Redstone/"/>
    
    <category term="Automation" scheme="http://zyxin.xyz/blog/tags/Automation/"/>
    
    <category term="Docker" scheme="http://zyxin.xyz/blog/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Notes for Algebra Basics</title>
    <link href="http://zyxin.xyz/blog/2020-06/AlgebraBasicsNotes/"/>
    <id>http://zyxin.xyz/blog/2020-06/AlgebraBasicsNotes/</id>
    <published>2020-06-28T01:02:13.000Z</published>
    <updated>2021-10-13T00:23:42.086Z</updated>
    
    <content type="html"><![CDATA[<div class="note warning"><p><strong>本文是用英文写的，且尚未翻译成中文</strong></p></div><blockquote><p>Selected notes from <code>ROB 501</code> and <code>ME 564</code>.<br>$\{x_i\}^b_a$ denotes set $\{x_a, x_{a+1}, \ldots, x_b\}$<br>TODO: add Jordan Form</p></blockquote><h1 id="Algebraic-Structures">Algebraic Structures<a class="header-anchor" href="#Algebraic-Structures"> ❮</a></h1><h2 id="Operation">Operation<a class="header-anchor" href="#Operation"> ❮</a></h2><ul><li>Definition: an (binary, closed) <strong>operation</strong> $\ast$ on a set $S$ is a mapping of $S\times S\to S$</li><li><strong>Commutative</strong>: $x\ast y=y\ast x,\;\forall x,y\in S$</li><li><strong>Associative</strong>: $(x\ast y)\ast z=x\ast (y\ast z),\;\forall x,y,z\in S$</li></ul><h2 id="Group">Group<a class="header-anchor" href="#Group"> ❮</a></h2><ul><li>Definition: a <strong>group</strong> is a pair $(\mathcal{S},\ast)$ with following axioms<ol><li>$\ast$ is associative on $\mathcal{S}$</li><li>(Identity element) $\exists e\in \mathcal{S}\text{ s.t. }x\ast e=e\ast x=x,\;\forall x\in \mathcal{S}$</li><li>(Inverse element) $\forall x\in \mathcal{S}, \exists x’ \in \mathcal{S}\text{ s.t. }x\ast x’=x’\ast x=e$</li></ol></li><li><strong>Abelian</strong>: a group is called <strong>abelian group</strong> if $\ast$ is also commutative</li></ul><span id="more"></span><h2 id="Ring">Ring<a class="header-anchor" href="#Ring"> ❮</a></h2><ul><li>Definition: a <strong>ring</strong> is a triplet $(\mathcal{R},+,\ast)$ consisting of a set of <code>scalars</code> $\mathcal{R}$ and two operators + and $\ast$ with following axioms<ol><li>$(\mathcal{R},+)$ is an abelian group with identity denoted $0$</li><li>$\forall a,b,c \in \mathcal{R}\text{ s.t. }a\ast(b\ast c) = (a\ast b)\ast c$</li><li>$\exists 1\in\mathcal{R}, \forall a\in\mathcal{R}\text{ s.t. }a\cdot 1=a$</li><li>$\ast$ is distributive over $+$</li></ol></li></ul><h2 id="Field">Field<a class="header-anchor" href="#Field"> ❮</a></h2><ul><li>Definition: a <strong>field</strong> $(\mathcal{F},+,\ast)$ is a ring where $(\mathcal{F}\backslash\{0\},\ast)$ is also an abelian group.<blockquote><p>Difference from ring to field is that $\ast$ need to be commutative and have a multiplicative inverse</p></blockquote></li></ul><h2 id="Vector-Space">Vector Space<a class="header-anchor" href="#Vector-Space"> ❮</a></h2><ul><li>Definition: a <strong>vector space</strong> (aka. <strong>linear space</strong>) is a triplet $(\mathcal{U},\oplus,\cdot)$ defined over a field $(\mathcal{F},+,\ast)$ with following axioms, where set $\mathcal{U}$ is called <code>vectors</code>, operator $\oplus$ is called <code>vector addition</code> and mapping $\cdot$ is called <code>scalar multiplication</code>:<ol><li>(<strong>Null vector</strong>) $(\mathcal{U},+)$ is an abelian group with identity element $\emptyset$</li><li>Scalar multiplication is a mapping of $\mathcal{F}\times\mathcal{U}\to\mathcal{U}$</li><li>$\alpha\cdot(x\oplus y) = \alpha\cdot x \oplus \alpha\cdot y,\;\forall x,y\in\mathcal{U};\alpha\in\mathcal{F}$</li><li>$(\alpha+\beta)\cdot x = \alpha\cdot x\oplus\beta\cdot x,\;\forall x\in\mathcal{U};\alpha,\beta\in\mathcal{F}$</li><li>$(\alpha\ast\beta)\cdot x=\alpha\cdot(\beta\cdot x),\;\forall x\in\mathcal{U};\alpha,\beta\in\mathcal{F}$</li><li>$1_\mathcal{F}\cdot x=x$</li></ol><blockquote><p>Usually we don’t distinguish vector addition $\oplus$ and addition of scalar $+$. Juxtaposition is also commonly used for <em>both</em> scalar multiplication $\cdot$ and multiplication of scalars $\ast$</p></blockquote></li><li><strong>Subspace</strong>: a subspace $\mathcal{V}$ of a linear space $\mathcal{U}$ over field $\mathcal{F}$ is a subset of $\mathcal{U}$ which is itself a linear space over $\mathcal{F}$ under same vector addition and scalar multiplication.</li></ul><h3 id="Basis-Coordinate">Basis &amp; Coordinate<a class="header-anchor" href="#Basis-Coordinate"> ❮</a></h3><ul><li><strong>Linear Independence</strong>: Let $\mathcal{V}$ be a vector space over $\mathcal{F}$ and let $X=\{x_i\}^n_1\subset \mathcal{V}$<ul><li>X is <strong>linearly dependent</strong> if $\exists \alpha_1,\ldots,\alpha_n\in\mathcal{F}$ not all 0 s.t. $\sum^n_{i=1} \alpha_i x_i=0$.</li><li>X is <strong>linearly independent</strong> if $\sum^n_{i=1} \alpha_i x_i=0 \Rightarrow \alpha_1=\alpha_2=\ldots=\alpha_n=0$</li></ul></li><li><strong>Span</strong>: Given a set of vectors $V$, the set of linear combinations of vectors in $V$ is called the <strong>span</strong> of it, denoted $\mathrm{span}\{V\}$</li><li><strong>Basis</strong>: A set of linearly independent vectors in a linear space $\mathcal{V}$ is a <strong>basis</strong> if every vector in $\mathcal{V}$ can be expressed as a <em>unique linear combination</em> of these vectors. (see below “Coordinate”)<ul><li>Basis Expansion: Let $(X,\mathcal{F})$ be a vector space of dimension n. If $\{v_i\}^k_1,\;1\leqslant k&lt; n$ is linearly independent, then $\exists \{v_i\}^n_{k+1}$ such that $\{v_i\}_1^n$ is a basis.</li><li><strong>Reciprocal Basis</strong>: Given basis $\{v_i\}^n_1$, a set ${r_i}^1_n$ that satifies $\langle r_i,v_j \rangle=\delta_i(j)$ is a reciprocal basis. It can be generated by Gram-Schmidt Process and $\forall x\in\mathcal{X}, x=\sum^n_{i=1}\langle r_i,x\rangle v_i$.</li></ul></li><li><strong>Dimension</strong>: <em>Cardinality</em> of the basis is called the <strong>dimension</strong> of that vector space, which is equal to <em>the maximum number of linearly independent vectors</em> in the space. Denoted as $dim(\mathcal{V})$.<ul><li>In an $n$-dimensional vector space, any set of $n$ linearly independent vectors is a basis.</li></ul></li><li><strong>Coordinate</strong>: For a vector $x$ in vector space $\mathcal{V}$, given a basis $\{e_1, \ldots, e_n\}$ we can write $x$ as $x=\sum^n_{i=1}\beta_i e_i=E\beta$ where $E=\begin{bmatrix}e_1&amp;e_2&amp;\ldots&amp;e_n\end{bmatrix}$ and $\beta=\begin{bmatrix}\beta_1&amp;\beta_2&amp;\ldots&amp;\beta_n\end{bmatrix}^\top$. Here $\beta$ is called the <strong>representation</strong> (or <strong>coordinate</strong>) of $x$ given the basis $E$.</li></ul><h3 id="Norm-Inner-product">Norm &amp; Inner product<a class="header-anchor" href="#Norm-Inner-product"> ❮</a></h3><ul><li><strong>Inner Product</strong>: an operator on two vectors that produces a scalar result (i.e. $\langle\cdot,\cdot\rangle:\mathcal{V}\to\mathbb{R}\;or\;\mathbb{C}$) with following axioms:<ol><li>(Symmetry) $\langle x,y \rangle=\overline{\langle y,x\rangle},\;\forall x,y\in\mathcal{V}$</li><li>(Bilinearity) $\langle \alpha x+\beta y,z\rangle=\alpha\langle x,z\rangle+\beta\langle y,z\rangle,\;\forall x,y,z\in\mathcal{V};\alpha,\beta\in\mathbb{C}$</li><li>(Pos. definiteness) $\langle x,x\rangle\geqslant 0,\;\forall x\in\mathcal{V}$ and $\langle x,x\rangle=0\Rightarrow x=0_\mathcal{V}$</li></ol></li><li><strong>Inner Product Space</strong>: A linear space with a defined inner product</li><li><strong>Orthogonality</strong>:<ul><li>Perpedicularity of vectors ($x\perp y$): $\langle x,y\rangle=0$</li><li>Perpedicularity of a vector to a set ($y\perp\mathcal{S},\mathcal{S}\subset\mathcal{V}$): $y\perp x,\;\forall x\in\mathcal{S}$</li><li><strong>Orthogonal Set</strong>: set $\mathcal{S}\subset(\mathcal{U},\langle\cdot,\cdot\rangle)$ is orthogonal $\Leftrightarrow x\perp y,\;\forall x,y\in\mathcal{S},x\neq y$</li><li><strong>Orthonormal Set</strong>: set $\mathcal{S}$ is orthonormal iff $\mathcal{S}$ is orthogonal and $\Vert x\Vert=1,\;\forall x\in\mathcal{S}$</li><li>Orthogonality of sets ($\mathcal{X}\perp\mathcal{Y}$): $\langle x,y\rangle=0,\;\forall x\in\mathcal{X};y\in\mathcal{Y}$</li><li><strong>Orthogonal Complement</strong>: Let $(\mathcal{V},\langle\cdot,\cdot\rangle)$ be an inner product space and let $\mathcal{U}\subset\mathcal{V}$ be a subspace of $\mathcal{V}$, the orthogonal complement of $\mathcal{U}$ is $\mathcal{U}^\perp=\left\{v\in\mathcal{V}\middle|\langle v,u\rangle=0,\;\forall u\in\mathcal{U}\right\}$.<ul><li>$\mathcal{U}^\perp\subset\mathcal{V}$ is a subspace</li><li>$\mathcal{V}=\mathcal{U}\overset{\perp}{\oplus}\mathcal{U}^\perp$ ($\oplus$: direct sum, $\overset{\perp}{\oplus}$: orthogonal sum)</li></ul></li></ul></li><li><strong>Norm</strong>: A <strong>norm</strong> on a linear space $\mathcal{V}$ is mapping $\Vert\cdot\Vert:\;\mathcal{V}\to\mathbb{R}$ such that:<ol><li>(Positive definiteness) $\Vert x\Vert\geqslant 0\;\forall x\in \mathcal{V}$ and $\Vert x\Vert =0\Rightarrow x=0_\mathcal{V}$</li><li>(Homogeneous) $\Vert \alpha x\Vert=|\alpha|\cdot\Vert x\Vert,\;\forall x\in\mathcal{V},\alpha\in\mathbb{R}$</li><li>(Triangle inequality) $\Vert x+y\Vert\leqslant\Vert x\Vert+\Vert y\Vert$</li></ol></li><li><strong>Distance</strong>: Norm can be used to measure distance between two vectors. Meanwhile, distance from a vector to a (sub)space is defined as $d(x,\mathcal{S})=\inf_{y\in\mathcal{S}} d(x,y)=\inf_{y\in\mathcal{S}} \Vert x-y\Vert$<ul><li><strong>Projection Point</strong>: $x^* =\arg\min_{y\in\mathcal{S}}\Vert x-y\Vert$ is the projection point of $x$ on linear space $\mathcal{S}$.</li><li><strong>Projection Theorem</strong>: $\exists !x^* \in\mathcal{S}$ s.t. $\Vert x-x^* \Vert=d(x,\mathcal{S})$ and we have $(x-x^*) \perp\mathcal{S}$</li><li><strong>Orthogonal Projection</strong>: $P(x)=x^*:\mathcal{X}\to\mathcal{M}$ is called the orthogonal projection of $\mathcal{X}$ onto $\mathcal{M}$</li></ul></li><li><strong>Normed Space</strong>: A linear space with a defined norm $\Vert\cdot\Vert$, denoted $(\mathcal{V},\mathcal{F},\Vert\cdot\Vert)$<blockquote><p>A inner product space is always a normed space because we can define $\Vert x\Vert=\sqrt{\langle x,x\rangle}$</p></blockquote></li><li>Common $\mathbb{R}^n$ Norms:<ul><li>Euclidean norm (2-norm): $\Vert x\Vert_2=\left(\sum^n_{i=1}|x_i|^2\right)^{1/2}=\left\langle x,x\right\rangle^{1/2}=\left(x^\top x\right)^{1/2}$</li><li>$l_p$ norm (p-norm): $\Vert x\Vert_p=\left(\sum^n_{i=1}|x_i|^p\right)^{1/p}$</li><li>$l_1$ norm: $\Vert x\Vert_1=\sum^n_{i=1}|x_i|$</li><li>$l_\infty$ norm: $\Vert x\Vert_\infty=\max_{i}\{x_i\}$</li></ul></li><li>Common matrix norms:<blockquote><p>Matrix norms are also called <strong>operator norms</strong>, can measure how much a linear operator “magnifies” what it operates on.</p></blockquote><ul><li>A general form induced from $\mathbb{R}^n$ norm: $$\Vert A\Vert=\sup_{x\neq 0}\frac{\Vert Ax\Vert}{\Vert x\Vert}=\sup_{\Vert x\Vert=1}\Vert Ax\Vert$$</li><li>$\Vert A\Vert_1=\max_j\left(\sum^n_{i=1}|a_{ij}|\right)$</li><li>$\Vert A\Vert_2=\left[ \max_{\Vert x\Vert=1}\left\{(Ax)^* (Ax)\right\}\right]^{1/2}=\left[ \lambda_{max}(A^ *A)\right]^{1/2}$ ($\lambda_{max}$: largest eigenvalue)</li><li>$\Vert A\Vert_\infty=\max_i\left(\sum^n_{j=1}|a_{ij}|\right)$</li><li>(Frobenius Norm) $\Vert A\Vert_F=\left[ \sum^m_{i=1}\sum^n_{j=1}\left|a_{ij}\right|^2\right]^{1/2}=\left[ tr(A^*A)\right]^{1/2}$</li></ul></li><li>Useful inequations:<ul><li><strong>Cauchy-Schwarz</strong>: $|\langle x,y\rangle|\leqslant\left\langle x,x\right\rangle^{1/2}\cdot\left\langle y,y\right\rangle^{1/2}$</li><li><strong>Triangle</strong> (aka. $\Delta$): $\Vert x+y\Vert\leqslant\Vert x\Vert+\Vert y\Vert$<blockquote><p>Lemma: $\Vert x-y\Vert \geqslant \left| \Vert x\Vert-\Vert y\Vert \right|$</p></blockquote></li><li><strong>Pythagorean</strong>: $x\perp y \Leftrightarrow \Vert x+y\Vert=\Vert x\Vert+\Vert y\Vert$</li></ul></li></ul><h3 id="Gramian">Gramian<a class="header-anchor" href="#Gramian"> ❮</a></h3><ul><li><strong>Gram-Schmidt Process</strong>: A method to find orthogonal basis $\{v_i\}^n_1$ given an ordinary basis $\{y_i\}^n_1$. It’s done by perform $v_k=y_k-\sum^{k-1}_{j=1}\frac{\langle y_k,v_j\rangle}{\langle v_j,v_j \rangle}\cdot v_j$ iteratively from 1 to $n$. To get an orthonormal basis, just normalize these vectors.</li><li><a href="https://en.wikipedia.org/wiki/Gramian_matrix"><strong>Gram Matrix</strong></a>: The Gram matrix generated from vectors $\{y_i\}_ 1^k$ is denoted $G(y_ 1,y_ 2,\ldots,y_ k)$. Its element $G_{ij}=\langle y_i,y_j\rangle$<ul><li><strong>Gram Determinant</strong>: $g(y_1,y_2,\ldots,y_n)=\det G$</li><li><strong>Normal Equations</strong>: Given subspace $\mathcal{M}$ and its basis $\{y_i\}^n_1$, the projection point of $\forall x\in\mathcal{M}$ can be represented by $$x^*=\alpha y=\begin{bmatrix}\alpha_1&amp;\alpha_2&amp;\ldots&amp;\alpha_n\end{bmatrix}\begin{bmatrix}y_1\\y_2\\ \vdots \\y_n\end{bmatrix},\;\beta=\begin{bmatrix}\langle x,y_1\rangle\\ \langle x,y_2\rangle\\ \vdots\\ \langle x,y_n\rangle\end{bmatrix} where\;G^\top\alpha=\beta$$<blockquote><p>For least-squares problem $Ax=b$, consider $\mathcal{M}$ to be the column space of $A$, then $G=A^\top A,\;\beta=A^\top b,\;G^\top\alpha=\beta\Rightarrow\alpha=(A^\top A)^{-1}A^\top b$. Similarly for weighted least-squares problem ($\Vert x\Vert=x^\top Mx$), let $G=A^\top MA, \beta=A^\top Mb$, we can get $\alpha=(A^\top MA)^{-1}A^\top Mb$</p></blockquote></li></ul></li></ul><h1 id="Linear-Algebra">Linear Algebra<a class="header-anchor" href="#Linear-Algebra"> ❮</a></h1><h2 id="Linear-Operator">Linear Operator<a class="header-anchor" href="#Linear-Operator"> ❮</a></h2><ul><li><p>Definition: a linear operator $\mathcal{A}$ (aka. linear transformation, linear mapping) is a function $f: V\to U$ that operate on a linear space $(\mathcal{V},\mathcal{F})$ to produce elements in another linear space $(\mathcal{U},\mathcal{F})$ and obey $$\mathcal{A}(\alpha_1 x_1+\alpha_2 x_2) = \alpha_1\mathcal{A}(x_1) + \alpha_2\mathcal{A}(x_2),\;\forall x_1,x_2\in V;\alpha_1, \alpha_2\in\mathcal{F}$$</p></li><li><p><strong>Range (Space)</strong>: $\mathcal{R}(\mathcal{A})=\left\{u\in U\middle|\mathcal{A}(v)=u,\;\forall v\in V\right\}$</p></li><li><p><strong>Null Space</strong> (aka. <strong>kernel</strong>): $\mathcal{N}(\mathcal{A})=\left\{v\in V\middle|\mathcal{A}(v)=\emptyset_U\right\}$</p></li><li><p><strong>$\mathcal{A}$-invariant subspace</strong>: Given vector space $(\mathcal{V},\mathcal{F})$ and linear operator $\mathcal{A}:\mathcal{V}\rightarrow \mathcal{V}$, $\mathcal{W}\subseteq\mathcal{V}$ is $A$-invariant if $\forall x\in\mathcal{W}$, $\mathcal{A}x\in\mathcal{W}$.</p><ul><li>Both $\mathcal{R}(\mathcal{A})$ and $\mathcal{N}(\mathcal{A})$ are $\mathcal{A}$-invariant</li></ul></li><li><p>Matrix Representation: Given bases for both $V$ and $U$ (respectively $\{v_i\}^n_1$ and $\{u_j\}^m_1$), matrix representation $A$ satisfies $\mathcal{A}(v_i)=\sum^m_{j=0}A_{ji}u_j$ so that $\beta=A\alpha$ where $\alpha$ and $\beta$ is the representation of a vector under $\{v_i\}$ and $\{u_j\}$ respectively.</p><img src="/blog/2020-06/AlgebraBasicsNotes/linear_map_relations.png" class="" title="Relation between a linear map and its matrix representations"><ul><li>$P$ and $Q$ are change of basis matrices, $A=Q^{-1}\tilde{A}P,\;\tilde{A}=QAP^{-1}$</li><li>The i-th column of $A$ is the coordinates of $\mathcal{A}(v_i)$ represented by the basis $\{u_j\}$, similarly i-th column of $\tilde{A}$ is $\mathcal{A}(\tilde{v}_i)$ represented in $\{\tilde{u}_j\}$</li><li>The i-th column of $P$ is the coordinates of $v_i$ represented by the basis $\{\tilde{v}\}$, similarly i-th column of $Q$ is $u_j$ represented in $\{\tilde{u}\}$</li></ul></li><li><p>Matrix Similarity ($A\sim B$): Two (square) matrix representations ($A,B$) of the same linear operator are called <strong>similar</strong> (or <strong>conjugate</strong>) and they satisfies $\exists P$ s.t. $B=PAP^{-1}$.</p><blockquote><p>From now on we don’t distinguish between linear operator $\mathcal{A}$ and its matrix representation where choice of basis doesn’t matter.</p></blockquote></li><li><p><strong>Rank</strong>: $rank(A)=\rho(A)\equiv dim(\mathcal{R}(A))$</p><ul><li><strong>Sylvester’s Inequality</strong>: $\rho(A)+\rho(B)-n\leqslant \rho(AB)\leqslant \min\{\rho(A), \rho(B)\}$</li><li><strong>Singularity</strong>: $\rho(A)&lt; n$</li></ul></li><li><p><strong>Nullity</strong>: $null(A)=\nu(A)\equiv dim(\mathcal{N}(A))$</p><ul><li>$\rho(A)+\nu(A)=n$ ($n$ is the dimensionality of domain space)</li></ul></li><li><p><strong>Adjoint</strong>: The adjoint of the linear map $\mathcal{A}: \mathcal{V}\to\mathcal{W}$ is the linear map $\mathcal{A}^*: \mathcal{W}\to\mathcal{V}$ such that $\langle y,\mathcal{A}(x)\rangle_\mathcal{W}=\langle \mathcal{A}^ *(y),x\rangle_\mathcal{V}$</p><blockquote><p>For its matrix representation, adjoint of $A$ is $A^ *$, which is $A^\top$ for real numbers.<br><br>Properties of $\mathcal{A}^ *$ is similar to matrix $A^ *$</p></blockquote><ul><li>$\mathcal{U}=\mathcal{R}(A)\overset{\perp}{\oplus}\mathcal{N}(A^ *),\;\mathcal{V}=\mathcal{R}(A^ *)\overset{\perp}{\oplus}\mathcal{N}(A)$</li><li>$\mathcal{N}(A^* )=\mathcal{N}(AA^* )\subseteq\mathcal{U},\;\mathcal{R}(A)=\mathcal{R}(AA^*)\subseteq\mathcal{U}$</li></ul></li><li><p><strong>Self-adjoint</strong>: $\mathcal{A}$ is self-adjoint iff $\mathcal{A}^*=\mathcal{A}$.</p><ul><li>For self-adjoint $\mathcal{A}$, if $\mathcal{V}=\mathbb{C}^{n\times n}$ then $A$ is <strong>hermitian</strong>; if $\mathcal{V}=\mathbb{R}^{n\times n}$ then $A$ is <strong>symmetric</strong>.</li><li>Self-adjoint matrices have real eigenvalues and orthogonal eigenvectors</li><li><strong>Skew symmetric</strong>: $A^*=-A$<blockquote><p>For quadratic form $x^\top Ax=x^\top(\frac{A+A^\top}{2}+\frac{A-A^\top}{2})x$, since $A-A^\top$ is skew symmetric, scalar $x^\top (A-A^\top) x=-x^\top (A-A^\top)x$, so the skew-symmetric part is zero. Therefore for quadratic form $x^\top Ax$ we can always assume $A$ is symmetric.</p></blockquote></li></ul></li><li><p><strong>Definiteness</strong>: (for symmetric matrix $P$)</p><ul><li>Positive definite ($P\succ 0$): $\forall x\in\mathbb{R}^n\neq 0,\; x^\top Px&gt;0 \Leftrightarrow$ all eigenvalues of $P$ are positive.</li><li>Semi-positive definite ($P\succcurlyeq 0$): $x^\top Px\geqslant 0 \Leftrightarrow$ all eigenvalues of $P$ are non-negative.</li><li>Negative definite ($P\prec 0$): $x^\top Px &lt; 0 \Leftrightarrow$ all eigenvalues of $P$ are negative.</li></ul></li><li><p><strong>Orthogonal Matrix</strong>: $Q$ is orthogonal iff $Q^\top Q=I$, iff columns of $Q$ are orthonormal.</p><ul><li>If $A\in\mathbb{R}^{n\times b}$ is symmetric, then $\exists$ orthogonal $Q$ s.t. $Q^\top AQ=\Lambda=\mathrm{diag}\{\lambda_1,\ldots,\lambda_n\}$ (see <a href="#Eigendecomposition-and-Jordan-Form">Eigen-decomposition</a> section below)</li></ul></li><li><p><strong>Orthogonal Projection</strong>: Given linear space $\mathcal{X}$ and subspace $\mathcal{M}$, $P(x)=x^*:\mathcal{X}\to\mathcal{M}$ ($x^ *$ is the projection point) is called orthogonal projection. If $\{v_i\}$ is a orthonormal basis of $\mathcal{M}$, then $P(x)=\sum_i \langle x,v_i\rangle v_i$</p></li></ul><h2 id="Eigenvalue-and-Canonical-Forms">Eigenvalue and Canonical Forms<a class="header-anchor" href="#Eigenvalue-and-Canonical-Forms"> ❮</a></h2><ul><li><strong>Eigenvalue</strong> and <strong>Eigenvector</strong>: Given mapping $\mathcal{A}:\mathcal{V}\rightarrow\mathcal{V}$, if $\exists \lambda\in\mathcal{F}, v\neq \emptyset_{\mathcal{V}}\in\mathcal{V}$ s.t. $\mathcal{A}(v) = \lambda v$, then $\lambda$ is the <strong>eigenvalue</strong>, $v$ is the <strong>eigenvector</strong> (aka. <strong>spectrum</strong>).<ul><li>If eigenvalues are all distinct, then the associated eigenvectors form a basis.</li></ul></li><li><strong>Eigenspace</strong>: $\mathcal{N}_\lambda = \mathcal{N}(\mathcal{A}-\lambda \mathcal{I})$.<ul><li>$q=dim(\mathcal{N}_\lambda)$ is called the <strong>geometric multiplicity</strong> (几何重度)</li><li>$\mathcal{N}_\lambda$ is an $\mathcal{A}$-invariant subspace.</li></ul></li><li><strong>Characteristic Polynomial</strong>: $\phi(s)\equiv\mathcal{det}(A-s I)$ is a polynomial of degree $n$ in $s$<ul><li>Its solutions are the eigenvalues of $A$.</li><li>The multiplicity $m_i$ of root term $(s-\lambda_i)$ here is called <strong>algebraic multiplicity</strong> (代数重度) of $\lambda_i$.</li></ul></li><li><strong>Cayley-Hamilton Theorem</strong>: $\phi(A)=\mathbf{0}$<blockquote><p>Proof needs the eigendecomposition or Jordan decomposition descibed below</p></blockquote></li><li><strong>Minimal Polynomial</strong>: $\psi(s)$ is the minimal polynomial of $A$ iff $\psi(s)$ is the polynomial of least degree for which $\psi(A)=0$ and $\psi$ is monic (coefficient of highest order term is 1)<ul><li>The multiplicity $\eta_i$ of root term $(s-\lambda_i)$ here is called the <strong>index</strong> of $\lambda_i$</li></ul></li><li><strong>Eigendecomposition</strong> (aka. <strong>Spectral Decomposition</strong>) is directly derived from the definition of eigenvalues: $$A=Q\Lambda Q^{-1}, \Lambda=\mathrm{diag}\left\{\lambda_1,\lambda_2,\ldots,\lambda_n\right\}$$<br>where $Q$ is a square matrix whose $i$-th column is the eigenvector $q_i$ corresponding to eigenvalue $\lambda_i$.<ul><li>Feasibility: $A$ can be diagonalized (using eigendecomposition) iff. $q_i=m_i$ for all $\lambda_i$.</li><li>If $A$ has $n$ distinct eigenvalues, then $A$ can be diagonalized.</li></ul></li><li><strong>Generalized eigenvector</strong>: A vector $v$ is a generalized eigenvector of rank $k$ associated with eigenvalue $\lambda$ iff $v\in\mathcal{N}\left((A-\lambda I)^k\right)$ but $v\notin\mathcal{N}\left((A-\lambda I)^{k-1}\right)$<ul><li>If $v$ is a generalized eigenvector of rank $k$, $(A-\lambda I)v$ is a generalized eigenvector of rank $k-1$. This creates a chain of generalized eigenvectors (called <strong>Jordan Chain</strong>) from rank $k$ to $1$, and they are linearly independent.</li><li>$\eta$ (index, 幂零指数) of $\lambda$ is the smallest integer s.t. $dim\left(\mathcal{N}\left((A-\lambda I)^\eta\right)\right)$</li><li>The space spanned by the chain of generalized eigenvectors from rank $\eta$ is called the <strong>generalized eigenspace</strong> (with dimension $\eta$).</li><li>Different generalized eigenspaces associated with the same and with different eigenvalues are orthogonal.</li></ul></li><li><strong>Jordan Decomposition</strong>: Similar to eigendecomposition, but works for all square matrices. $A=PJP^{-1}$ where $J=\mathrm{diag}\{J_1,J_2,\ldots,J_p\}$ is the <strong>Jordan Form</strong> of A consisting of Jordan Blocks.<ul><li><strong>Jordan Block</strong>: $J_i=\begin{bmatrix} \lambda &amp; 1 &amp;&amp;&amp; \\&amp;\lambda&amp;1&amp;&amp;\\&amp;&amp;\lambda&amp;\ddots&amp;\\&amp;&amp;&amp;\ddots&amp;1\\&amp;&amp;&amp;&amp;\lambda\end{bmatrix}$</li><li>Each Jordan block corresponds to a generalized eigenspace</li><li>$q_i$ = the count of Jordan blocks associated with $\lambda_i$</li><li>$m_i$ = the count of $\lambda_i$ on diagonal of $J$</li><li>$\eta_i$ = the dimension of the largest Jordan block associated with $\lambda_i$</li></ul></li></ul><blockquote><p>$\Lambda$ in eigendecomposition, $J$ in Jordan Form and $\Sigma$ in SVD (see below) are three kinds of <strong><a href="https://en.wikipedia.org/wiki/Canonical_form#Linear_algebra">Canonical Forms</a></strong> of a matrix $A$</p></blockquote><ul><li><strong>Function of matrics</strong>: Let $f(\cdot)$ be an analytic function and $\lambda_i$ be an eigenvalue of $A$. If $p(\cdot)$ is a polynomial that satisfies $p(\lambda_i)=f(\lambda_i)$ and $\frac{\mathrm{d}^k}{\mathrm{d}s^k} p(\lambda_i)=\frac{\mathrm{d}^k}{\mathrm{d}s^k} f(\lambda_i)$ for $k=1,\ldots,\eta_i-1$, then $f(A)\equiv p(A)$.<blockquote><ul><li>This extends the functions applicable to matrics from polynomials (trivial) to any analytical functions</li><li>By Cayley-Hamilton, we can always choose $p$ to be order $n-1$</li></ul></blockquote></li><li><strong>Sylvester’s Formula</strong>: $f(A)=\sum^k_{i=1}f(\lambda_i)A_i$ ($f$ being analytic)</li></ul><h2 id="SVD-and-Linear-Equations">SVD and Linear Equations<a class="header-anchor" href="#SVD-and-Linear-Equations"> ❮</a></h2><p>SVD Decomposition is useful in various fields and teached by a lot of courses, its complete version is formulated as $$A=U\Sigma V^*, \Sigma=\begin{bmatrix}\mathbf{\sigma}&amp;\mathbf{0}\\ \mathbf{0}&amp;\mathbf{0}\end{bmatrix}, \mathbf{\sigma}=\mathrm{diag}\left\{\sqrt{\lambda_1},\sqrt{\lambda_2},\ldots,\sqrt{\lambda_r}\right\},V=\begin{bmatrix}V_1&amp;V_2\end{bmatrix},U=\begin{bmatrix}U_1&amp;U_2\end{bmatrix}$$<br>where</p><ul><li>$r=\rho(A)$ is the rank of matrix $A$</li><li>$\sigma_i$ are called <strong>sigular values</strong>, $\lambda_i$ are eigenvalues of $A^* A$</li><li>Columns of $V_1$ span $\mathcal{R}(A^ *A)=\mathcal{R}(A^ *)$, columns of $V_2$ span $\mathcal{N}(A^ *A)=\mathcal{N}(A)$</li><li>Columns of $U_1=AV_1\sigma^{-1}$ span $\mathcal{R}(A)$, columns of $U_2$ span $\mathcal{N}(A^*)$</li></ul><blockquote><p>SVD can be derived by doing eigenvalue decomposition on $A^* A$</p></blockquote><p>With SVD introduced, we can efficiently solve general linear equation $Ax=b$ as $x=x_r+x_n$ where $x_r\in\mathcal{R}(A^\top)$ and $x_n\in\mathcal{N}(A)$.</p><table><thead><tr><th></th><th>$Ax=b$</th><th>tall $A$ ($m&gt;n$)</th><th>fat $A$ ($m&lt; n$)</th></tr></thead><tbody><tr><td></td><td></td><td>Overdetermined, <br> Least Squares, <br> use Normal Equations</td><td>Underdetermined, <br> Quadratic Programming, <br> use Lagrange Multiplies</td></tr><tr><td>I.$b\in\mathcal{R}(A)$</td><td></td><td></td><td></td></tr><tr><td>1.$\mathcal{N}(A)={0}$</td><td>$x$ exist &amp; is unique</td><td>$x=(A^\top A)^{-1}A^\top b=A^+b$</td><td>$x=A^\top(AA^\top)^{-1}b=A^+b$</td></tr><tr><td>2.$\mathcal{N}(A)\neq{0}$</td><td>$x$ exist &amp; not unique</td><td>$x_r=(A^\top A)^{-1}A^\top b=A^+b$</td><td>$x_r=A^\top(AA^\top)^{-1}b=A^+b$</td></tr><tr><td>II.$b\notin\mathcal{R}(A)$</td><td></td><td></td><td></td></tr><tr><td>1.$\mathcal{N}(A)={0}$</td><td>$x$ not exists, $x_r$ exist &amp; is unique</td><td>$x_r=(A^\top A)^{-1}A^\top b=A^+b$</td><td>$x_r=A^\top(AA^\top)^{-1}b=A^+b$</td></tr><tr><td>2.$\mathcal{N}(A)\neq{0}$</td><td>$x$ not exists, $x_r$ not exist</td><td>$(A^\top A)^{-1}$ invertible</td><td>$(AA^\top)^{-1}$ invertible</td></tr></tbody></table><ul><li>$A^+=(A^\top A)^{-1}A^\top$ is left pseudo-inverse, $A^+=A^\top (AA^\top)^{-1}$ is right pseudo-inverse.</li><li>$A^+$ can be unified by the name <strong>Moore-Penrose Inverse</strong> and calculated using SVD by $A^+=V\Sigma^+ U^\top$ where $\Sigma^+$ take inverse of non-zeros.</li></ul><h2 id="Miscellaneous">Miscellaneous<a class="header-anchor" href="#Miscellaneous"> ❮</a></h2><blockquote><p>Selected theorems and lemmas useful in Linear Algebra. For more matrix properties see <a href="/blog/2019-06/MatrixAlgebra/" title="my post about Matrix Algebra">my post about Matrix Algebra</a></p></blockquote><ul><li>Matrix Square Root: $N^\top N=P$, then $N$ is the square root of $P$<blockquote><p>Square root is not unique. Cholesky decomposition is often used as square root.</p></blockquote></li><li><strong>Schur Complement</strong>: Given matrices $A_{n\times n}, B_{n\times m}, C_{m\times m}$, the matrix $M=\begin{bmatrix}A&amp;B\\ B^\top&amp;C\end{bmatrix}$ is symmetric. Then the following are equivalent (TFAE)<ol><li>$M\succ 0$</li><li>$A\succ 0$ and $C-B^\top A^{-1}B\succ 0$ (LHS called Schur complement of $A$ in $M$)</li><li>$C\succ 0$ and $A-B C^{-1}B^\top\succ 0$ (LHS called Schur complement of $C$ in $M$)</li></ol></li><li>Matrix Inverse Lemma: $(A+BCD)^{-1}=A^{-1}-A^{-1}B\left(C^{-1}+DA^{-1}B\right)^{-1}DA$</li><li>Properties of $A^\top A$<ul><li>$A^\top A \succeq 0$ and $A^\top A \succ 0 \Leftrightarrow A$ has full rank.</li><li>$A^\top A$ and $AA^\top$ have same non-zero eigenvalues, but different eigenvectors.</li><li>If $v$ is eigenvector of $A^\top A$ about $\lambda$, then $Av$ is eigenvector of $AA^\top$ about $\lambda$.</li><li>If $v$ is eigenvector of $AA^\top$ about $\lambda$, then $A^\top v$ is eigenvector of $A^\top A$ about $\lambda$.</li><li>$tr(A^\top A)=tr(AA^\top)=\sum_i\sum_j\left|A_{ij}\right|^2$</li><li>$det(A)=\prod_i\lambda_i, tr(A)=\sum_i\lambda_i$</li></ul></li></ul><h1 id="Real-Analysis">Real Analysis<a class="header-anchor" href="#Real-Analysis"> ❮</a></h1><h2 id="Set-theory">Set theory<a class="header-anchor" href="#Set-theory"> ❮</a></h2><blockquote><p>$\text{~}S$ stands for complement of set $S$ in following contents. These concepts are discussed under normed space $(\mathcal{X}, \Vert\cdot\Vert)$</p></blockquote><ul><li><strong>Open Ball</strong>: Let $x_0\in\mathcal{X}$ and let $a\in\mathbb{R}, a&gt;0$, then the open ball of radius $a$ about $x_0$ is $B_a(x_0)=\left\{x\in\mathcal{X}\middle| \Vert x-x_0\Vert &lt; a\right\}$<ul><li>Given subset $S\subset \mathcal{X}$, $d(x,S)=0\Leftrightarrow \forall\epsilon &gt;0, B_\epsilon(x)\cap S\neq\emptyset$</li><li>Given subset $S\subset \mathcal{X}$, $d(x,S)&gt;0\Leftrightarrow \exists\epsilon &gt;0, B_\epsilon(x)\cap S=\emptyset$</li></ul></li><li><strong>Interior Point</strong>: Given subset $S\subset\mathcal{X}$, $x\in S$ is an interior point of $S$ iff $\exists\epsilon &gt;0, B_\epsilon(x)\subset S$<ul><li><strong>Interior</strong>: $\mathring{S}=\{x\in \mathcal{X}|x\text{ is an interior point of }S\}=\{x\in\mathcal{X}|d(x,\text{~}S)&gt;0\}$</li></ul></li><li><strong>Open Set</strong>: $S$ is open if $\mathring{S}=S$</li><li><strong>Closure Point</strong>: Given subset $S\subset\mathcal{X}$, $x\in S$ is a closure point of $S$ iff $\forall\epsilon &gt;0, B_\epsilon(x)\cap S\neq\emptyset$.<ul><li><strong>Closure</strong>: $\bar{S}=\{x\in\mathcal{X}|x\text{ is a closure point of }S\}=\{x\in\mathcal{X}|d(x,S)=0\}$<blockquote><p>Note that $\partial\mathcal{X}=\emptyset$</p></blockquote></li></ul></li><li><strong>Closed Set</strong>: $S$ is closed if $\bar{S}=S$<blockquote><p>$S$ is open $\Leftrightarrow$ $\text{~}S$ is closed, $S$ is closed $\Leftrightarrow$ $\text{~}S$ is open. Set being both open and closed is called <strong>clopen</strong>(e.g. the whole set $\mathcal{X}$), empty set is clopen by convention.</p></blockquote></li><li><strong>Set Boundary</strong>: $\partial S=\bar{S}\cap\overline{\text{~}S}=\bar{S}\backslash\mathring{S}$</li></ul><h2 id="Sequences">Sequences<a class="header-anchor" href="#Sequences"> ❮</a></h2><ul><li><strong>Sequence</strong>($\{x_n\}$): a set of vectors indexed by the counting numbers<ul><li><strong>Subsequence</strong>: Let $1\leqslant n_1&lt; n_2&lt;\ldots$ be an infinite set of increasing integers, then $\{x_{n_i}\}$ is a subsequence of $\{x_n\}$</li></ul></li><li><strong>Convergence</strong>($\{x_n\}\to x\in\mathcal{X}$): $\forall \epsilon&gt;0,\exists N(\epsilon)&lt;\infty\text{ s.t. }\forall n\geqslant N, \Vert x_n-x\Vert &lt;\epsilon$<ul><li>If $x_n \to x$ and $x_n \to y$, then $x=y$</li><li>If $x_n \to x_0$ and $\{x_{n_i}\}$ is a subsequence of $\{x_n\}$, then $\{x_{n_i}\} \to x_0$</li><li><strong>Cauchy Convergence</strong> (necessary condition for convergence): $\{x_n\}$ is cauchy if $\forall \epsilon&gt;0,\exists N(\epsilon)&lt;\infty$ s.t. $\forall n,m\geqslant N, \Vert x_n-x_m\Vert &lt;\epsilon$</li><li>If $\mathcal{X}$ is finite dimensional, $\{x_n\}$ is cauchy $\Rightarrow$ $\{x_n\}$ has a limit in $\mathcal{X}$</li></ul></li><li><strong>Limit Point</strong>: Given subset $S\subset\mathcal{X}$, $x$ is a limit point of $S$ if $\exists \{x_n\}$ s.t. $\forall n\geqslant 1, x_n\in S$ and $x_n\to x$<ul><li>$x$ is a limit point of $S$ iff $x\in\bar{S}$</li><li>$S$ is closed iff $S$ contains its limit points</li></ul></li><li><strong>Complete Space</strong>: a normed space is <strong>complete</strong> if every Cauchy sequence has a limit. A complete normed space $(\mathcal{X}, \Vert\cdot\Vert)$ is called a <strong>Banach space</strong>.<ul><li>$S\subset \mathcal{X}$ is complete if every Cauchy sequence with elements from $S$ has a limit in $S$</li><li>$S\subset \mathcal{X}$ is complete $\Rightarrow S$ is closed</li><li>$\mathcal{X}$ is complete and $S\subset\mathcal{X} \Rightarrow S$ is complete</li><li>All finite dimensional subspaces of $X$ are complete</li></ul></li><li><strong>Completion of Normed Space</strong>: $\mathcal{Y}=\bar{\mathcal{X}}=\mathcal{X}+\{$all limit points of Cauchy sequences in $\mathcal{X}\}$<blockquote><p>E.g. $C[a,b]$ contains continuous functions over $[a,b]$. $(C[a,b], \Vert\cdot\Vert_1)$ is not complete, $(C[a,b], \Vert\cdot\Vert_\infty)$ is complete. Completion of $(C[a,b], \Vert\cdot\Vert_1)$ requires Lebesque integration.</p></blockquote></li><li><strong>Contraction Mapping</strong>: Let $S\subset\mathcal{X}$ be a subset and $T:S\to S$ is a contraction mapping if $\exists 0\leqslant c\leqslant 1$ such that, $\forall x,y \in S, \Vert T(x)-T(y)\Vert\leqslant c\Vert x-y\Vert$<ul><li><strong>Fixed Point</strong>: $x^* \in\mathcal{X}$ is a fixed point of $T$ if $T(x^ *)=x^ *$</li><li><a href="https://en.wikipedia.org/wiki/Banach_fixed-point_theorem"><strong>Contraction Mapping Theorem</strong> (不动点定理)</a>: If $T:S\to S$ is a contraction mapping in a complete subset $S$, then $\exists! x^ *\in\mathcal{X}\text{ s.t. }T(x^ *)=x^ *$. Moreover, $\forall x_0\in S$, the sequence $x_{k+1}=T(x_k),k\geqslant 0$ is Cauchy and converges to $x^ *$.<blockquote><p>E.g. Newton Method: $x_{k+1}=x_k-\epsilon\left[\frac{\partial h}{\partial x}(x_k)\right]^{-1}\left(h(x_k)-y\right)$</p></blockquote></li></ul></li></ul><h2 id="Continuity-and-Compactness">Continuity and Compactness<a class="header-anchor" href="#Continuity-and-Compactness"> ❮</a></h2><ul><li><strong>Continuous</strong>: Let $(\mathcal{X},\Vert\cdot\Vert_\mathcal{X})$ and $(\mathcal{Y},\Vert\cdot\Vert_\mathcal{Y})$ be two normed spaces. A function $f:\mathcal{X}\to\mathcal{Y}$ is continuous at $x_0\in\mathcal{X}$ if $\forall\epsilon &gt;0,\exists \delta(\epsilon,x_0)&gt;0\text{ s.t. }\Vert x-x_0\Vert_\mathcal{X}&lt;\delta \Rightarrow\Vert f(x)-f(x_0)\Vert_\mathcal{Y} &lt;\epsilon$<ul><li>$f$ is continuous on $S\subset\mathcal{X}$ if $f$ is continuous at $\forall x_0\in S$</li><li>If $f$ in continuous at $x_0$ and $\{x_n\}$ is a sequence s.t. $x_n\to x_0$, then the sequence $\{f(x_n)\}$ in $\mathcal{Y}$ converges to $f(x_0)$</li><li>If $f$ is discontinuous at $x_0$, then $\exists \{x_n\}\in\mathcal{X}$ s.t. $x_n\to x_0$ but $f(x_n)\nrightarrow f(x_0)$</li></ul></li><li><strong>Compact</strong>: $S\subset\mathcal{X}$ is (sequentially) compact if every sequence in $S$ has a convergent subsequence with limit in $S$</li><li><strong>Bounded</strong>: $S\subset\mathcal{S}$ is bounded if $\exists r&lt;\infty$ such that $S\subset B_r(0)$<ul><li>$S$ is compact $\Rightarrow$ $S$ is closed and bounded</li><li><strong>Bolzano-Weierstrass Theorem</strong>: In a finite-dimensional normed space, $C$ is closed and bounded $\Leftrightarrow$ for $C$ is compact</li></ul></li><li><strong>Weierstrass Theorem</strong>: If $C\subset\mathcal{X}$ is a compact subset and $f:C\to\mathbb{R}$ is continuous at each point of $C$, then $f$ achieves its extreme values, i.e. $\exists \bar{x}\in C\text{ s.t. }f(\bar{x})=\sup_{x\in C} f(x)$ and $\exists \underline{x}\in C\text{ s.t. }f(\underline{x})=\inf_{x\in C} f(x)$<ul><li>$f:C\to\mathbb{R}$ continuous and $C$ compact $\Rightarrow$ $\sup_{x\in C}f(x)&lt;\infty$</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;div class=&quot;note warning&quot;&gt;&lt;p&gt;&lt;strong&gt;本文是用英文写的，且尚未翻译成中文&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Selected notes from &lt;code&gt;ROB 501&lt;/code&gt; and &lt;code&gt;ME 564&lt;/code&gt;.&lt;br&gt;
$\{x_i\}^b_a$ denotes set $\{x_a, x_{a+1}, \ldots, x_b\}$&lt;br&gt;
TODO: add Jordan Form&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Algebraic-Structures&quot;&gt;Algebraic Structures&lt;a class=&quot;header-anchor&quot; href=&quot;#Algebraic-Structures&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&quot;Operation&quot;&gt;Operation&lt;a class=&quot;header-anchor&quot; href=&quot;#Operation&quot;&gt; ❮&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Definition: an (binary, closed) &lt;strong&gt;operation&lt;/strong&gt; $\ast$ on a set $S$ is a mapping of $S\times S\to S$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Commutative&lt;/strong&gt;: $x\ast y=y\ast x,\;\forall x,y\in S$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Associative&lt;/strong&gt;: $(x\ast y)\ast z=x\ast (y\ast z),\;\forall x,y,z\in S$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Group&quot;&gt;Group&lt;a class=&quot;header-anchor&quot; href=&quot;#Group&quot;&gt; ❮&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Definition: a &lt;strong&gt;group&lt;/strong&gt; is a pair $(\mathcal{S},\ast)$ with following axioms
&lt;ol&gt;
&lt;li&gt;$\ast$ is associative on $\mathcal{S}$&lt;/li&gt;
&lt;li&gt;(Identity element) $\exists e\in \mathcal{S}\text{ s.t. }x\ast e=e\ast x=x,\;\forall x\in \mathcal{S}$&lt;/li&gt;
&lt;li&gt;(Inverse element) $\forall x\in \mathcal{S}, \exists x’ \in \mathcal{S}\text{ s.t. }x\ast x’=x’\ast x=e$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Abelian&lt;/strong&gt;: a group is called &lt;strong&gt;abelian group&lt;/strong&gt; if $\ast$ is also commutative&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Notes" scheme="http://zyxin.xyz/blog/categories/Notes/"/>
    
    <category term="Math" scheme="http://zyxin.xyz/blog/categories/Notes/Math/"/>
    
    
    <category term="Math" scheme="http://zyxin.xyz/blog/tags/Math/"/>
    
    <category term="Algebra" scheme="http://zyxin.xyz/blog/tags/Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Notes for Control System</title>
    <link href="http://zyxin.xyz/blog/2020-06/ControlSystemNotes/"/>
    <id>http://zyxin.xyz/blog/2020-06/ControlSystemNotes/</id>
    <published>2020-06-10T19:25:34.000Z</published>
    <updated>2021-10-13T00:23:42.076Z</updated>
    
    <content type="html"><![CDATA[<div class="note warning"><p><strong>本文是用英文写的，且尚未翻译成中文</strong></p></div><p>$\require{mathtools}$ <!-- load the required TeX package --></p><blockquote><ul><li>This note combines content from ME 564 Linear Systems and ME 561 Discrete Digital Control</li><li>Please read <a href="/blog/2020-06/AlgebraBasicsNotes/" title="the Algebra Basics notes">the Algebra Basics notes</a> first if you are not familiar with related concepts.</li><li>In this note, $f\in\mathbb{F}^\mathbb{G}$ stands for a function with domain in $\mathbb{G}$ and co-domain in $\mathbb{F}$, i.e. $f:\mathbb{F}\to\mathbb{G}$, $H(x)$ generally stands for Heaviside function (step function)</li></ul></blockquote><h1 id="Transforms">Transforms<a class="header-anchor" href="#Transforms"> ❮</a></h1><h2 id="Laplace-Transform">Laplace Transform<a class="header-anchor" href="#Laplace-Transform"> ❮</a></h2><ul><li>Definition: $F(s)=\mathcal{L}\{f(t)\}(s)=\int^\infty_0 f(t)e^{-st}\mathrm{d}t$<blockquote><p>Note that the transform is not well defined for all functions in $\mathbb{C}^\mathbb{R}$. And the transform is only valid for $s$ in a region of convergence, which is usually separated by 0.</p></blockquote></li><li>Laplace Transform is a linear map from $(\mathbb{C}^\mathbb{R}, \mathbb{C})$ to $(\mathbb{C}^\mathbb{C}, \mathbb{C})$ and it’s one-to-one.</li><li>Properties: (see <a href="https://en.wikipedia.org/wiki/Laplace_transform">Wikipedia</a> or <a href="https://lpsa.swarthmore.edu/LaplaceZTable/LaplacePropTable.html">this page</a> for full list)<ul><li>Derivative: $f’(t) \xleftrightarrow{\mathcal{L}} sF(s)-f(0^-)$</li><li>Integration: $\int^t_0 f(\tau)d\tau \xleftrightarrow{\mathcal{L}} \frac{1}{s}F(s)$</li><li>Delay: $f(t-a)H(t-a) \xleftrightarrow{\mathcal{L}} e^{-as}F(s)$</li><li>Convolution: $\int^t_0 f(\tau)g(t-\tau)\mathrm{d}\tau \xleftrightarrow{\mathcal{L}} F(s)G(s)$</li></ul></li><li>Stationary Value: $\lim\limits_{t\to 0} f(t) = \lim\limits_{s\to \infty} sF(s), \lim\limits_{t\to \infty} f(t) = \lim\limits_{s\to 0} sF(s)$</li></ul><span id="more"></span><h3 id="Inverse-Laplace-Transform">Inverse Laplace Transform<a class="header-anchor" href="#Inverse-Laplace-Transform"> ❮</a></h3><blockquote><p>Laplace transform is one-to-one, so we can apply inverse transform on functions in s-space</p></blockquote><p>There are several ways to calculate Laplace transform, the first one is directly evaluating integration while the latter two are converting the function into certain formats that are convenient for table lookup:</p><ol><li>(Mellin’s) Inverse formula: $f(t)=\mathcal{L}^{-1}\{F(s)\}(t)=\frac{1}{2\pi j}\lim\limits_{T\to\infty} \int ^{\gamma+iT}_{\gamma-iT} e^{st}F(s)\mathrm{d}s$ where the integration is done along the vertical line $Re(s)=\gamma$ in the convex s-plane such that $\gamma$ is greater than the real part of all poles of $F(s)$.</li><li>Power Series: $F(s) = \sum^\infty_{n=0} \frac{n!a_n}{s^{n+1}}\xleftrightarrow{\mathcal{L}} f(t) = \sum ^\infty_{n=0} a_n t^n $</li><li>Partial Fractions: $F(s)=\frac{k_1}{s+a}+\frac{k_2}{s+b}+\ldots \xleftrightarrow{\mathcal{L}} f(t)=k_1 e^{-at} + k_2 e^{-bt} + \ldots$<ul><li>To calculate partial fractions, one can use <a href="http://tutorial.math.lamar.edu/Classes/Alg/DividingPolynomials.aspx">Polynomial Division</a> or following lemma:</li><li>Suppose $F(s)=\frac{N(s)}{D(s)}=\frac{N(s)}{\prod^n_{i=1} (s-p_i)^{r_i}}$ where $\mathrm{deg}(N(s)) &lt; \mathrm{deg(D(s))}$ and each $p_i$ is a distinct root of $D(s)$ (i.e. pole) with multiplicity $r_i$, then $F(s)=\sum^n_{i=1}\sum^{r_i}_ {j=1} \frac{k_{ij}}{(s-p_i)j}$ where $k_{ij}=\frac{1}{(r_i-j)!}\left.\frac{\mathrm{d}^{r_i-j}}{\mathrm{d}s^{r_i-j}}(s-p_i)^{r_i}F(s)\right\vert_{s=p_i}$</li></ul></li></ol><h2 id="Z-Transfrom">Z-Transfrom<a class="header-anchor" href="#Z-Transfrom"> ❮</a></h2><ul><li>Definition: $F(z)=\mathcal{Z}\{f(k)_ {k\in\mathbb{N}}\}(z)=\sum^\infty_{k=0} f(k)z^{-k}$</li></ul><blockquote><p>Notice that $f$ is defined on natural numbers. In time domain, it’s usually corresponding to $f(kT)$. Z-transform is also only valid for $z$ in certain region (usually separated by 1)</p></blockquote><ul><li>Laplace Transform is a linear map from $(\mathbb{C}^\mathbb{N}, \mathbb{C})$ to $(\mathbb{C}^\mathbb{C}, \mathbb{C})$ and it’s one-to-one.</li><li>Properties: (see <a href="https://en.wikipedia.org/wiki/Z-transform">Wikipedia</a> or <a href="https://lpsa.swarthmore.edu/LaplaceZTable/LaplacePropTable.html">this page</a> for full list)<ul><li>Accumulation: $\sum^n_{k=-\infty} f(k) \xleftrightarrow{\mathcal{Z}} \frac{1}{1-z^{-1}}F(z)$</li><li>Delay: $f(k-m) \xleftrightarrow{\mathcal{Z}} z^{-m}F(z)$</li><li>Convolution: $\sum^k_{n=0}f_1(n)f_2(k-n) \xleftrightarrow{\mathcal{Z}} F_1(z)F_2(z)$</li></ul></li><li>Stationary Value: $\lim\limits_{t\to 0} f(t) = \lim\limits_{z\to \infty} F(z), \lim\limits_{t\to \infty} f(t) = \lim\limits_{z\to 1} (z-1)F(z)$</li></ul><details><summary>Example: Z-Transform of PID controller</summary>Assume the close-loop error input of the controller is $e(t)$, and $e(kT)$ after sampling. PID controller action in analog is$$m(t)=K\left(e(t)+\frac{1}{T_i}\int^t_0e(t)\mathrm{d}t+T_d\frac{\mathrm{d}e(t)}{\mathrm{d}t}\right)$$We can approximate by trapezoidal rule with two point difference:$$m(kT)=K\left(e(kT)+\frac{T}{T_i}\sum^k_{h=1}\frac{e((h-1)T)+e(hT)}{2}+T_d\left(\frac{e(kT)-e((k-1)T)}{T}\right)\right)$$Lets define $f(hT) = \frac{1}{2}\left(e((h-1)T)+e(hT)\right),\;f(0)=0$Then $$\begin{split}\mathcal{Z}\left(\left\{\sum^k_{h=1}\frac{e((h-1)T)+e(hT)}{2}\right\}_k\right)(z)=\mathcal{Z}\left(\left\{\sum^k_{h=1}f(hT)\right\}_k\right)(z) \\ =\frac{1}{1-z^{-1}}(F(z)-F(0))=\frac{1}{1-z^{-1}}F(z)\end{split}$$Notice that $$F(z)=\mathcal{Z}\left({f(hT)}_h\right)(z)=\frac{1+z^{-1}}{2}E(z)$$so we can calculate the Z-transform of $m(kT)$$$\begin{split} M(z)&=K\left(1+\frac{T}{2T_i}\left(\frac{1+z^{-1}}{1-z^{-1}}\right)+\frac{T_d}{T}(1-z^{-1})\right)E(z)\\&=K\left(1-\frac{T}{2T_i}+\frac{T}{T_i}\frac{1}{1-z^{-1}}+\frac{T_d}{T}(1-z^{-1})\right)E(z)\\&=\left(K_p+K_i\left(\frac{1}{1-z^-1}\right)+K_d(1-z^{-1})\right)E(z) \end{split}$$<p>Here we have</p><ul><li>Proportional Gain $K_p=K-\frac{KT}{2T_i}$</li><li>Integral Gain $K_I=\frac{KT}{T_i}$</li><li>Derivative Gain $K_d=\frac{KT_d}{T}$</li></ul></details><h3 id="Inverse-Z-Transform">Inverse Z-Transform<a class="header-anchor" href="#Inverse-Z-Transform"> ❮</a></h3><ol><li>Inverse formula: $f(k)=\mathcal{Z}^{-1}\{F(z)\}(k)=\frac{1}{2\pi j}\oint _\Gamma z^{k-1}F(z)\mathrm{d}z$ where the integration is done along any closed path $\Gamma$ that encloses all finite poles of $z^{k-1}X(z)$ in the z-plane.<ul><li>According to residual theorem, we can write it as $f(k)=\sum_{p_i}Res(z^{k-1}f(z), pi)$ where $p_i$ are poles of $z^{k-1}f(k)$ and residual $Res(g(z),p)=\frac{1}{(m-1)!}\left.\frac{\mathrm{d}^{m-1}}{\mathrm{d}z^{m-1}}\left((z-p)^mg(z)\right)\right\vert_{z=p}$ with $m$ being the multiplicity of the pole $p$ in $g$.</li></ul></li><li>Power Series: same as inverse laplace.</li><li>Partial Fractions: same as inverse laplace.</li></ol><h3 id="Modified-Z-Transfrom">Modified Z-Transfrom<a class="header-anchor" href="#Modified-Z-Transfrom"> ❮</a></h3><ul><li>Definition: $F(z,m)=\mathcal{Z}_m(f,m)=\mathcal{Z}(\left\{f(kT-(1-m)T)\right\} _{k\in\mathbb{N}^+})(z)$</li><li>We denote corresponding continuous form $\mathcal{L}(f(t-(1-m)T)\delta_ T(t))$ as $F^*(s,m)$</li><li>Residual Theorem: $\mathcal{Z}_m(f,m)=z^{-1}\sum _{p_i} Res(\frac{F(s)e^{mTs}}{1-z^{-1}e^{Ts}}, p_i)$</li><li>ModZ Transform is usually used when there’s delay in the system, use this transform to shift the signal with proper $m$ value.</li></ul><h2 id="Starred-Transform">Starred Transform<a class="header-anchor" href="#Starred-Transform"> ❮</a></h2><ul><li>Definition: $F^* (s)=\sum^\infty_{n=0}f(n*T)e^{-nTs}$</li></ul><blockquote><p>Starred Transform is defined in continuous s-domain, but it only aggregates on discrete s values defined periodically by sampling time T, like Z-Transform. Starred Transform is usually exchangeable with Z-Transform with $z=e^{Ts}$.</p></blockquote><ul><li>Sometimes we also see <code>*</code> as an operator to sample a continuous signal. It converts a continuous signal to discrete delta functions. (See the “Sampler” section below)</li><li>Calculation from Laplace Transform<ul><li>$F^*(s)=\sum_{p_i\in\{poles\;of\;F(\lambda)\}} Res\left(F(\lambda)\frac{1}{1-e^{-T(s-\lambda)}}, p_i\right)$</li><li>$F^*(s)=\frac{1}{T}\sum^\infty_{n=-\infty}F(s+jn\omega_s)+\frac{e(0)}{2}$ where $\omega_s=\frac{2\pi}{T}$</li></ul></li><li>Properties:<ul><li>$F^*(s)$ is periodic in s plane with period $j\omega_s=\frac{2\pi j}{T}$</li><li>If $F(s)$ has a pole at $s=s_0$, then $F^*(s)$ must have poles at $s=s_0+jn\omega_s$ for $m\in\mathbb{Z}$</li><li>$A(s)=B(s)F^* (s) \Rightarrow A^* (s)=B^* (s)F^* (s)$, while usually $A(s)=B(s)F(s) \nRightarrow A^* (s)=B^* (s)F^* (s)$</li></ul></li></ul><h2 id="Fourier-Transform">Fourier Transform<a class="header-anchor" href="#Fourier-Transform"> ❮</a></h2><blockquote><p>Fourier transform is basically to substitute $s=j\omega$ into Laplace transform. Additional properties are not discussed here.</p><ul><li>One important theorem (Shannon-Nyquist Sampling Theorem): Suppose $e:\mathbb{R}_+\to\mathbb{R}$ has a Fourier Transform with no frequency components greater than $f_0$, then $e$ is uniquely determined by the signal $e_s$ generated by ideally sampling $e$ with period $\frac{1}{2}f_0$.</li></ul></blockquote><h1 id="State-Space-Representation">State Space Representation<a class="header-anchor" href="#State-Space-Representation"> ❮</a></h1><h2 id="Continuous-State-Space-Representation">Continuous State Space Representation<a class="header-anchor" href="#Continuous-State-Space-Representation"> ❮</a></h2><h3 id="Definition">Definition<a class="header-anchor" href="#Definition"> ❮</a></h3><p>A continuous-time linear state-space system can be described by following two equations:<br>\begin{align}&amp;\text{State equation}:\;&amp;\dot{x}(t)&amp;=A(t)x(t)+B(t)u(t),&amp;\;x(t)\in\mathbb{R}^n,\;u(t)&amp;\in\mathbb{R}^m \\&amp;\text{Output equation}:\;&amp;y(t)&amp;=C(t)x(t)+D(t)u(t),&amp;\;y(t)&amp;\in\mathbb{R}^p\end{align}</p><p>The input $u:[0,\infty)\to\mathbb{R}^m$, state $x:[0,\infty)\to\mathbb{R}^n$, and output $y:[0,\infty)\to\mathbb{R}^p$ are all <em>signals</em>, i.e. functions of continuous time $t\in[0,\infty)$. The coefficients $A\in\mathbb{R}^{n\times n}$,$B\in\mathbb{R}^{n\times m}$,$C\in\mathbb{R}^{p\times n}$,$D\in\mathbb{R}^{p\times m}$</p><p>This linear time-varying (LTV) system can be written compactly as<br>\begin{align*} \dot{x}&amp;=A(t)x+B(t)u \\ y&amp;=C(t)x+D(t)u\end{align*}<br>Similarly, linear time-invariant (LTI) system can be written as<br>\begin{align} \dot{x}&amp;=Ax+Bu \\ y&amp;=Cx+Du\end{align}</p><p>For non-linear system, the equation will be written as</p><table><tr><th style="text-align:center">time-varying (NLTV) </th><th style="text-align:center">time-invariant (NTLI) </th><th style="text-align:center">time-invariant autonomous</th></tr><tr><td><p>\begin{align*}\dot{x}&amp;=f(x,u,t)\\y&amp;=g(x,u,t)\end{align*}</p></td><td><p>\begin{align*}\dot{x}&amp;=f(x,u)\\y&amp;=g(x,u)\end{align*}</p></td><td><p>\begin{align*}\dot{x}&amp;=f(x)\\y&amp;=g(x)\end{align*}</p></td></tr></table><h3 id="Solution">Solution<a class="header-anchor" href="#Solution"> ❮</a></h3><blockquote><p><em><strong>Math prerequisites here:</strong></em></p><ul><li>For definition of function on matrix, see <a href="/blog/2020-06/AlgebraBasicsNotes/#Eigenvalue-and-Canonical-Forms">my notes for algebra basics</a></li><li>$e^A$ is matrix exponential, <code>expm</code> in MATLAB<ol><li>$\frac{\mathrm{d}}{\mathrm{d}t}e^{At}=Ae^{At}=e^{At}A$</li><li>$e^{(A+B)t}\Leftrightarrow AB=BA$ <strong>(be careful when commute matrices)</strong></li><li>$\mathcal{L}\{e^{At}\}=(sI-A)^{-1}$ (can be derived from property 1 and laplace derivative)</li></ol></li><li>To calculate $e^A$<ol><li>Eigenvalue decomposition</li><li>Jordan form decomposition</li><li>Directly evaluate infinite power series (converges quickly)</li><li>Inverse Laplace transform</li></ol></li><li>For more properties of the matrix function, see <a href="/blog/2019-06/MatrixAlgebra/" title="Matrix Algebra">Matrix Algebra</a></li></ul></blockquote><ul><li><p>For homogeneous LTI system: $$\begin{align}x(t)=e^{A(t-t_0)}x_0\end{align}$$</p><ul><li>“<em>homogeneous</em>” = zero-input, Eq.5 is also called <strong>zero input response</strong> (ZIR).</li><li>“<em>homogeneous equation</em>” = 齐次方程</li></ul></li><li><p>For LTI system:<br>$$\begin{align}x(t)=e^{A(t-t_0)}x(t_0)+\int^t_{t_0}e^{A(t-\tau)}Bu(\tau)d\tau\end{align}$$<br>This result requires $A$ to be time-invariant, $B,C,D$ can be time varying.</p><ul><li>The solution consists of two parts: ZIR and ZSR (<strong>zero state response</strong>, $x(t_0)=0$), which are homogenenous solution (通解) and particular solution (特解) of the ODE.</li><li>ZIR and ZSR are both linear mapping</li></ul></li><li><p>For homogeneous LTV system: $$\begin{align}x(t)=\Phi(t,t_0)x_0\end{align}$$</p><ul><li>Matrix $\Phi$ is called the <strong>state transition matrix</strong>, defined as $$\begin{equation}\begin{split}\Phi(t,t_0)\equiv I+\int^t_{t_0}A(s_1)\mathrm{d}s_1+\int^t_ {t_0}A(s_1)\int^{s_1}_ {t_0}A(s_2)\mathrm{d}s_2\mathrm{d}s_1+\\ \int^t_ {t_0}A(s_1)\int^{s_1}_ {t_0}A(s_2)\int^{s_2}_ {t_0}A(s_3)\mathrm{d}s_3\mathrm{d}s_2\mathrm{d}s_1+\cdots\end{split}\end{equation}$$</li><li>Properties of $\Phi$:<ol><li>$\Phi(t,t)=I$</li><li>$\frac{\mathrm{d}}{\mathrm{d}t}\Phi(t,t_0)=A(t)\Phi(t,t_0)$</li><li>(semigroup property) $\Phi(t,s)\Phi(s,\tau)=\Phi(t,\tau)$</li><li>$\forall t,\tau\geqslant 0,\;[\Phi(t,\tau)]^{-1}=\Phi(\tau,t)$</li></ol></li><li>Eq.6 can be directly derived by evaluating Eq.8</li></ul></li><li><p>For LTV system:<br>$$\begin{align}x(t)=\Phi(t,t_0)x_0+\int^t_{t_0}\Phi(t,\tau)B(\tau)u(\tau)d\tau\end{align}$$</p></li><li><p>Some conclusions:</p><ul><li>The solution given by Eq.9 is unique</li><li>The set of all solutions to ZIR system forms a vector space of dimension $n$</li><li>If $A(t)A(s)=A(s)A(t)$, then $\Phi(t,t_0)=e^{\int^t_{t_0}A(\tau)\mathrm{d}\tau}$</li></ul></li><li><p><strong>Phase Portraits</strong>: A phase portrait is a graph of several zero-input responses on the phase plane ($\dot{x}(t)$ and $x(t)$ are phase variables)</p><blockquote><p>Usually in phase portraits, there are two straight lines corresponding to the eigenvector of A, other lines are growing in or opposite to the direction of the lines.</p></blockquote></li></ul><h3 id="Transfer-function">Transfer function<a class="header-anchor" href="#Transfer-function"> ❮</a></h3><ul><li>For LTI case, $\frac{Y(s)}{U(s)} = C(sI-A)^{-1}B+D$<blockquote><p>This can be derived by take laplace transform of both sides of state equations</p></blockquote></li></ul><h2 id="Discrete-State-Space-Representation">Discrete State Space Representation<a class="header-anchor" href="#Discrete-State-Space-Representation"> ❮</a></h2><h3 id="Definition-2">Definition<a class="header-anchor" href="#Definition-2"> ❮</a></h3><p>A discrete-time linear state-space system can be described by following two equations:<br>$$\begin{align}&amp;\text{State eq.}:\;&amp;x(k+1)&amp;=A(k)x(k)+B(k)u(k),&amp;\;x\in\mathbb{R}^n,\;u&amp;\in\mathbb{R}^m \\ &amp;\text{Output eq.}:\;&amp;y(k)&amp;=C(k)x(k)+D(k)u(k),&amp;\;y&amp;\in\mathbb{R}^p\end{align}$$</p><p>The input $u:\mathbb{N}\to\mathbb{R}^m$, state $x:\mathbb{N}\to\mathbb{R}^n$, and output $y:\mathbb{N}\to\mathbb{R}^p$ are all <em>signals</em>, i.e. functions of continuous time $t\in\mathbb{N}$.</p><p>Discrete LTI system is sometimes written compactly as $$\begin{align} x_{k+1}&amp;=Ax_k+Bu_k \\ y_k&amp;=Cx_k+Du_k \end{align}$$</p><h3 id="Transfer-function-2">Transfer function<a class="header-anchor" href="#Transfer-function-2"> ❮</a></h3><ul><li>For LTI case, $H(z)=C(zI-A)^{-1}B+D$ (pulse tranfer function)</li></ul><h2 id="Controllability-Reachability">Controllability &amp; Reachability<a class="header-anchor" href="#Controllability-Reachability"> ❮</a></h2><blockquote><p>Note: hereafter $\mathfrak{R}$ denotes <a href="/blog/2020-06/AlgebraBasicsNotes/#Linear-Operator">range space</a>, $\mathfrak{N}$ denotes <a href="/blog/2020-06/AlgebraBasicsNotes/#Linear-Operator">null space</a>.</p></blockquote><ul><li><strong>Controllability</strong>: $\exists u$ that drives any initial state $x(t_0)=x_0$ to $x(t_1)=0$</li><li><strong>Reachability</strong>: $\exists u$ that drives initial state $x(t_0)=0$ to any $x(t_1)=x_1$</li></ul><p>Consider the continuous LTV system $\dot{x}=A(t)x+B(t)u,\;x\in\mathbb{R}^n,u\in\mathbb{R}^m$.</p><ul><li><p><strong>Reachable Subspace</strong>: Given $t_0$ &amp; $t_1$, the reachable subspace $\mathcal{R}[t_0, t_1]$ consists of all states $x_1$ for which there exists and input $u:[t_0, t_1]\to\mathbb{R}^m$ that transfers the state from $x(t_0)=0$ to $x(t_1)=x_1$.</p><ul><li>$\mathcal{R}[t_0, t_1]\equiv\left\{x_1\in\mathbb{R}^n\middle|\exists u(\cdot),\;x_1=\int^{t_1}_{t_0}\Phi(t_1,\tau)B(\tau)u(\tau)\mathrm{d}\tau\right\}$</li></ul></li><li><p><strong>Controllable  Subspace</strong>: Given $t_0$ &amp; $t_1$, the controllable subspace $\mathcal{C}[t_0, t_1]$ consists of all states $x_0$ for which there exists an input $u:[t_0, t_1]\to\mathbb{R}^m$ that transfers the state from $x(t_0)=x_0$ to $x(t_1)=0$</p><ul><li>$\mathcal{C}[t_0, t_1]\equiv\left\{x_0\in\mathbb{R}^m\middle|\exists u(\cdot),\;0=\Phi(t_1,t_0)x_0+\int^{t_1}_{t_0}\Phi(t_1,\tau)B(\tau)u(\tau)\mathrm{d}\tau\right\}$</li><li>or $\mathcal{C}[t_0, t_1]\equiv\left\{x_0\in\mathbb{R}^m\middle|\exists u(\cdot),\;x_0=\int^{t_1}_{t_0}\Phi(t_0,\tau)B(\tau)\left[-u(\tau)\right]\mathrm{d}\tau\right\}$</li></ul></li><li><p><strong>Reachability Grammian</strong>: $W_\mathcal{R}(t_0, t_1)\equiv\int^{t_1}_{t_0}\Phi(t_1,\tau)B(\tau)B(\tau)^\top\Phi^\top(t_1,\tau)\mathrm{d}\tau$ given times $t_1&gt;t_0\geqslant0$</p><ul><li>The system is reachable at time $t_0$ iff $\exists t_1$ s.t. $W_\mathcal{R}(t_0,t_1)$ is non-singular.</li></ul><blockquote><p>non-singular for some $t_1$ $\Rightarrow$ non-singular for any $t_1$</p></blockquote><ul><li>$\mathcal{R}[t_0,t_1]=\mathfrak{R}(W_\mathcal{R}(t_0,t_1))$</li><li>if $x_1=W_\mathcal{R}(t_0,t_1)\eta_1\in\mathfrak{R}(W_\mathcal{R}(t_0,t_1))$, the control $u(t)=B^\top(t)\Phi^T(t_1,t)\eta_1$,$t\in[t_0,t_1]$ can be used to transfer the system from $x(t_0)=0$ to $x(t_1)=x_1$ (w/ minimum energy)</li></ul><blockquote><p>minimum energy = minimum $\int^T_0\Vert u(\tau)\Vert^2\mathrm{d}\tau$</p></blockquote><ul><li>For LTI system $W_\mathcal{R}(t_0,t_1)=\int^{t_1}_ {t_ 0}e^{A(t_1-\tau)}BB^\top e^{A^{\top} (t_1-\tau)}\mathrm{d}\tau=\int^{t_1-t_ 0}_ {0}e^{At}BB^\top e^{A^{\top}t}$</li></ul></li><li><p><a href="https://en.wikipedia.org/wiki/Controllability_Gramian"><strong>Controllability Grammian</strong></a>: $W_\mathcal{C}(t_0, t_1)\equiv\int^{t_1}_{t_0}\Phi(t_0,\tau)B(\tau)B(\tau)^\top\Phi^\top(t_0,\tau)\mathrm{d}\tau$ given times $t_1&gt;t_0\geqslant0$</p><ul><li><p>The system is reachable at time $t_0$ iff $\exists t_1$ s.t. $W_\mathcal{C}(t_0,t_1)$ is non-singular.</p></li><li><p>$\mathcal{C}[t_0,t_1]=\mathfrak{R}(W_\mathcal{C}(t_0,t_1))$</p></li><li><p>if $x_0=W_\mathcal{C}(t_0,t_1)\eta_0\in\mathfrak{R}(W_\mathcal{C}(t_0,t_1))$, control $u(t)=-B^\top(t)\Phi^\top(t_0,t)\eta_0$,$t\in[t_0,t_1]$ can be used to transfer the state from $x(t_0)=x_0$ to $x(t_1)=0$ (w/ minimum energy)</p></li><li><p>For LTI system $W_\mathcal{C}(t_0,t_1)=\int^{t_1}_ {t_ 0}e^{A(t_0-\tau)}BB^\top e^{A^{\top} (t_0-\tau)}\mathrm{d}\tau=\int^{t_1-t_ 0}_ {0}e^{-At}BB^\top e^{-A^{\top}t}$</p></li></ul></li><li><p><strong>Controllability Matrix</strong>: For LTI system, controllability matrix $\mathcal{C}=[B\;|\;AB\;|\;A^2B\;\cdots\;A^{n-1}B]$</p><blockquote><p>The controllability matrix works for both continuous and discrete system, and it’s easier to be derived from discrete LTI equations:<br>In discrete LTI, $\mathcal{C}\mathbf{u}=-A^k x_0$ where $\mathbf{u}=\begin{bmatrix}u_{k-1} &amp; u_{k-2} &amp; \ldots &amp; u_0\end{bmatrix}^\top$</p></blockquote><ul><li>For LTI, $\mathcal{R}[t_0,t_1]=\mathfrak{R}(W_\mathcal{R}[t_0,t_1])=\mathfrak{R}(\mathcal{C})=\mathfrak{R}(W_\mathcal{C}[t_0,t_1])=\mathcal{C}[t_0,t_1]$</li></ul><blockquote><p>This implies Controllability $\Leftrightarrow$ Reachability for LTI systems.</p></blockquote><ul><li>The controllable subspace $\mathfrak{\mathcal{C}}$ is the smallest A-invariant subspace that contains $\mathfrak{\mathcal{B}}$</li><li>If the controllability matrix has full rank, the LTI system (or the pair $(A,B)$) is <strong>completely controllable</strong></li></ul></li><li><p><strong>PBH-Eigenvector Test</strong>: An LTI system is not controllable iff there exists a nonzero <em>left</em> eigenvector $v$ of $A$ such that $vB=0$</p></li><li><p><strong>PBH-Rank Test</strong>: An LTI system will be controllable iff $[\lambda I-A \;| \;B]$ has full row rank for all eigenvalue $\lambda$</p></li><li><p>For LTI system, there exists an input $u(\cdot)$ that transfer the state from $x_0$ ito $x_1$ in finite time $T$ iff $x_1-e^{AT}x_0\in\mathfrak{R}(\mathcal{C})$</p><ul><li>The input that transfers any state $x_0$ to any other state $x_1$ in some finite time $T$ is $u(t)=B^\top e^{A^{\top}(T-t)}W_\mathcal{R}^{-1}(0,T)[x_1 -e^{AT}x_0]$, for $t\in[0,T]$ (w/ minimum energy)</li></ul></li></ul><h2 id="Observability">Observability<a class="header-anchor" href="#Observability"> ❮</a></h2><ul><li><p><strong>Observability</strong>: Given any input $u(t)$ and output $y(t)$ over $t\in[t_0,t_1]$, it’s sufficient to determine a unique initial state $\exists !x(t_0)$.</p></li><li><p><a href="https://en.wikipedia.org/wiki/Observability_Gramian"><strong>Observability Grammian</strong></a>: $W_\mathcal{O}(t_0,t_1)\equiv\int^{t_1}_{t_0}\Phi^\top(t_1,\tau)C^\top(\tau)C(\tau)\Phi(t_1,\tau)\mathrm{d}\tau$</p><ul><li><p>The system is observable at time $t_0$ iff $\exists t_1$ s.t. $W_{\mathcal{O}}(0,t)$ is nonsingular.</p></li><li><p>For LTI system $W_{\mathcal{O}}(t_0,t_1)=\int^{t_1}_{t_0} e^{A^{\top}(t_1-\tau)}C^\top Ce^{A(t_1-\tau)}\mathrm{d}\tau=\int^{t_1-t_0}_0 e^{A^{\top}\tau}C^\top Ce^{A\tau}\mathrm{d}\tau$</p></li></ul></li><li><p><strong>Observability Matrix</strong>: For LTI system, observability $\mathcal{O}=\begin{bmatrix}C\\CA\\CA^2\\ \vdots\\CA^{k-1}\end{bmatrix}$</p><blockquote><p>The controllability matrix works for both continuous and discrete system, and it’s easier to be derived from discrete LTI equations:<br>In discrete LTI, $\Psi_{k-1}=\mathcal{O}x_0$ where $$\Psi_k\equiv\begin{bmatrix}y_0\\y_1\\y_2\\ \vdots\\ y_{k-1}\end{bmatrix}-\begin{bmatrix} D &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ CB &amp; D &amp; 0 &amp; \cdots &amp; 0 \\ CAB &amp; CB &amp; D &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ CA^{k-2}B &amp; CA^{k-3}B &amp; CA^{k-4}B &amp; \cdots &amp; 0 \end{bmatrix}\begin{bmatrix}u_0\\u_1\\u_2\\ \vdots \\ u_{k-1}\end{bmatrix}$$</p></blockquote><ul><li>If the controllability matrix has full rank, the LTI system (or the pair $(A,C)$) is <strong>completely observable</strong>.</li></ul></li><li><p><strong>PBH-Rank Test</strong>: An LTI system will be observable iff $\begin{bmatrix}A-\lambda I \\C\end{bmatrix}$ has full column rank for all eigenvalue $\lambda$</p></li></ul><h2 id="Duality">Duality<a class="header-anchor" href="#Duality"> ❮</a></h2><ul><li><strong>Duality Theorem</strong>: The pair $(A,B)$ is controllable iff the pair $(A^\top, B^\top)$ is observable.<ul><li><em>Controllability</em> only depends on matrix $A$ and $B$ while the <em>Observability</em> only depends on matrix $A$ and $C$</li><li>Duality theorem is useful for proof of observability conclusions from controllability</li></ul></li><li><strong>Adjoint System</strong>:</li></ul><table><tr><th></th><th> Original System </th><th> Adjoint System </th></tr><tr><td>Equations</td><td> $$\begin{align*} \dot{x}&=A(t)x+B(t)u \\ y&=C(t)x \end{align*}$$</td><td>$$\begin{align*} \dot{p}&=-A^*(t)p-C^*(t)v \\ z&=B^*(t)p\end{align*}$$</td></tr><tr><td>Initial Condition</td><td>$x(t_0)=x_0$</td><td>$p(t_1)=p_1$</td></tr><tr><td>State Trasition Matrix</td><td> $\Phi(t,t_0)$ </td><td> $\Phi^*(t_1,t)=\left(\Phi^*(t,t_1)\right)^{-1}$</td></tr><tr><td>Zero-State Response</td><td> $$\begin{split}L_u:\;&u(\cdot)\to x(t_1)\\=&\int^{t_1}_{t_0}\Phi(t_1,\tau)B(\tau)u(\tau)\mathrm{d}\tau\end{split}$$</td><td>$$\begin{split}P_u:\;&v(\cdot)\to p(t_0)\\=&\int^{t_1}_{t_0}\Phi^*(\tau,t_0)C^*(\tau)v(\tau)\mathrm{d}\tau\end{split}$$</td></tr><tr><td>Zero-Input Response</td><td> $$\begin{split}L_0:\;&x_0\to y(\cdot)\\=&C(\cdot)\Phi(\cdot,t_0)x_0\end{split}$$ </td><td> $$\begin{split}P_0:\;&p_1\to z(\cdot)\\=&B^*(\cdot)\Phi^*(t_1,\cdot)p_1\end{split}$$ </td></tr><tr><td rowspan="3"> Duality Theorem </td><td> Controllable ($\rho(L_u)=n$) </td><td> Observable ($\rho(P_0^*)=n$)</td></tr><tr><td> Observable ($\rho(L_0^*)=n$) </td><td> Controllable ($\rho(P_u)=n$) </td></tr><tr><td> A state is reachable ($x\in\mathfrak{R}(L_u)$) </td><td> A state is unobservable ($x\in\mathfrak{N}(L_0)$) </td></tr></table>  Note that ZIR and ZSR are both linear mappings and $L_u^*=P_0,\;L_0^*=P_u$<h2 id="Decomposition-and-Realizations">Decomposition and Realizations<a class="header-anchor" href="#Decomposition-and-Realizations"> ❮</a></h2><ul><li><p>Similarity Transform of a (LTI) system: Based on Eq.3 and Eq.4, define $x=P\bar{x}$, then we have $$\begin{align}\dot{\bar{x}}&amp;=P^{-1}AP\bar{x}+P^{-1}Bu&amp;=\bar{A}\bar{x}+\bar{B}u \\ y&amp;=CP\bar{x}+Du&amp;=\bar{C}\bar{x}+Du\end{align}$$</p><ul><li>Similarity transform doesn’t affect transfer function.</li></ul></li><li><p><strong>Controllability Decomposition</strong>: For an uncontrollable LTI system, define matrix $V=[V_1\;V_2]$ where $V_1$ is a basis for $\mathfrak{R}(\mathcal{C})$ and $V_2$ complete a basis for $\mathbb{R}^n$, then after similarity transform with $\bar{x}=V^{-1}x$, we can partition the system like following:<br>$$\begin{align*}\dot{\bar{x}}&amp;=\bar{A}\bar{x}+\bar{B}u&amp;=&amp;\begin{bmatrix}\bar{A}_ {11}&amp;\bar{A}_ {12} \\ \mathbf{0} &amp; \bar{A} _{22}\end{bmatrix}\begin{bmatrix}\bar{x} _1 \\ \bar{x} _2\end{bmatrix}+\begin{bmatrix}\bar{B} _1 \\ \mathbf{0}\end{bmatrix}u \\ y&amp;=\bar{C}\bar{x}+Du&amp;=&amp; \begin{bmatrix}\bar{C} _1 &amp; \bar{C} _2\end{bmatrix}\begin{bmatrix}\bar{x} _1 \\ \bar{x} _2\end{bmatrix} + Du\end{align*}$$<br>Here $\bar{x}_2$ is uncontrollable, and ZSR of the system with or without $\bar{x}_2$ is the same.</p></li><li><p><strong>Observability Decomposition</strong>: For an unobservable LTI system, define matrix $U=\begin{bmatrix}U_1\\U_2\end{bmatrix}$ where $U_1$ is a basis for $\mathfrak{R}(\mathcal{O}^\top)$ and $U_2$ complete a basis for $\mathbb{R}^n$, then after similarity transform with $\hat{x}=Ux$, we can partition the system like following:<br>$$\begin{align*}\dot{\hat{x}}&amp;=\hat{A}\hat{x}+\hat{B}u&amp;=&amp;\begin{bmatrix}\hat{A}_ {11}&amp;\mathbf{0} \\ \hat{A}_ {21} &amp; \hat{A} _{22}\end{bmatrix}\begin{bmatrix}\hat{x} _1 \\ \hat{x} _2\end{bmatrix}+\begin{bmatrix}\hat{B} _1 \\ \hat{B} _2\end{bmatrix}u \\ y&amp;=\hat{C}\hat{x}+Du&amp;=&amp; \begin{bmatrix}\hat{C} _1 &amp; \mathbf{0}\end{bmatrix}\begin{bmatrix}\hat{x} _1 \\ \hat{x} _2\end{bmatrix} + Du\end{align*}$$</p></li><li><p><strong>Realization</strong>: $\Sigma$ (system with Eq.3 and Eq.4) is a realization of $H(s)$ iff $H(s)=C(sI-A)^{-1}B+D$.</p><ul><li><strong>Equivalent</strong>: Two realizations are said to be equivalent if they have the same transfer function</li><li><strong>Algebraically Equivalent</strong>: Two realizations have same transfer function and $n$ (dimension of states). (this implies a similarity transform between them)</li><li><strong>Minimal Realization</strong>: $\Sigma$ is a minimal realization of $H(s)$ iff there doesn’t exists an equivalent realization $\bar{\Sigma}$ with $\bar{n}&lt; n$</li></ul></li><li><p>$\Sigma$ is a minial realization iff $\Sigma$ is completely controllable and observable.</p></li><li><p><strong>Kalman Cannonical Structure Theorem</strong> (aka. Kalman Decomposition): suppose $\rho(\mathcal{C})&lt; n$ and $\rho(\mathcal{O})&lt; n$, $\mathfrak{R}(\mathcal{C})$ are the controllable states, $\mathfrak{N}(\mathcal{O})$ are the unobservable states, define subspaces:</p></li></ul><table><thead><tr><th style="text-align:left">Subspaces</th><th style="text-align:center">Controllable</th><th style="text-align:center">Observable</th></tr></thead><tbody><tr><td style="text-align:left">$V_2\equiv\mathfrak{R}(\mathcal{C})\cup\mathfrak{N}(\mathcal{O})$</td><td style="text-align:center">Yes</td><td style="text-align:center">No</td></tr><tr><td style="text-align:left">$V_1$ s.t. $V_1\oplus V_2=\mathfrak{R}(\mathcal{C})$</td><td style="text-align:center">Yes</td><td style="text-align:center">Yes</td></tr><tr><td style="text-align:left">$V_4$ s.t. $V_4\oplus V_2=\mathfrak{N}(\mathcal{O})$</td><td style="text-align:center">No</td><td style="text-align:center">No</td></tr><tr><td style="text-align:left">$V_3$ s.t. $V_1\oplus V_2\oplus V_3\oplus V_4=\mathbb{C}^n$</td><td style="text-align:center">No</td><td style="text-align:center">Yes</td></tr></tbody></table><p>Then let $$\begin{align*}\tilde{x}=\begin{bmatrix}\tilde{x}_ 1\\ \tilde{x}_ 2\\ \tilde{x}_ 3\\ \tilde{x}_ 4\end{bmatrix},\;\tilde{A}=&amp;\begin{bmatrix}A_ {\mathrm{co}} &amp;&amp;A_{13}&amp;\\A_{21}&amp;A_{\mathrm{c\bar{o}}}&amp;A_{23}&amp;A_{24}\\&amp;&amp;A_{\mathrm{\bar{c}o}}&amp;\\&amp;&amp;A_{43}&amp;A_{\mathrm{\bar{c}\bar{o}}} \end{bmatrix},\;\tilde{B}=\begin{bmatrix}B_{\mathrm{co}}\\ B_{\mathrm{c\bar{o}}} \\ \mathbf{0} \\ \mathbf{0} \end{bmatrix} \\ \tilde{C}=&amp;\begin{bmatrix}C_{\mathrm{co}}&amp;\mathbf{0}\quad&amp;C_{\mathrm{\bar{c}o}}&amp;\mathbf{0}\quad\end{bmatrix}\end{align*}$$<br>$$\tilde{\Sigma}:\begin{cases} \dot{\tilde{x}}=A_{\mathrm{co}}\tilde{x}_ 1+B_{\mathrm{co}}u_1\\ y=C_{\mathrm{co}}\tilde{x}_1\end{cases}$$</p><p>$\tilde{\Sigma}$ is completely controllable and completely observable.</p><hr/>Consider SISO systems $$H(s)=\frac{b(s)}{a(s)}=\frac{b_{n-1}s^{n-1}+\ldots+b_1s+b_0}{s^n+a_{n-1}s^{n-1}+\ldots+a_1s+a_0}=\frac{\sum^{n-1}_{j=0} b_js^j}{s^n+\sum^{n-1}_{i=0} a_is^i}=\frac{Y(s)}{U(s)}$$<ul><li><strong>Controllable Cannonical Form</strong>: $$\begin{align}\dot{x}&amp;=\begin{bmatrix} 0&amp;1&amp;&amp;\\ \vdots &amp; &amp; \ddots &amp; \\ 0&amp;&amp;&amp;1 \\-a_0&amp;-a_1&amp;\cdots&amp;-a_{n-1}\end{bmatrix}x+\begin{bmatrix}0\\ \vdots \\ 0 \\ 1\end{bmatrix}u&amp;=&amp;A_cx+B_cu\\ y&amp;=\begin{bmatrix}\quad b_0 &amp;\quad b_1 &amp;\cdots &amp; \quad b_{n-1}\end{bmatrix}x&amp;=&amp;C_cx \end{align}$$<ul><li>$(A_c, B_c)$ is controllable</li><li>$(A_c, C_c)$ is observable if $a(s)$ and $b(s)$ have no common factors</li></ul></li><li><strong>Observable Cannonical Form</strong>: $$\begin{align}\dot{x}&amp;=\begin{bmatrix} 0&amp;&amp;&amp;&amp;-a_0\\ 1 &amp; \ddots &amp;&amp;&amp;-a_1 &amp; \\ &amp;\ddots&amp;\ddots&amp;&amp;\vdots \\&amp;&amp;\ddots&amp;0&amp;-a_{n-2} \\ &amp;&amp;&amp;1&amp;-a_{n-1}\end{bmatrix}x+\begin{bmatrix}b_0\\ b_1 \\ \vdots \\ b_{n-2} \\ b_{n-1}\end{bmatrix}u&amp;=&amp;A_ox+B_ou\\ y&amp;=\begin{bmatrix}0 &amp; \;\cdots &amp;\;\cdots &amp; 0 &amp; \quad 1\qquad \end{bmatrix}x&amp;=&amp;C_ox \end{align}$$<ul><li>$(A_o, C_o)$ is observable</li><li>$(A_o, B_o)$ is controllable if $a(s)$ and $b(s)$ have no common factors</li></ul></li><li><strong>Model Cannonical Forms</strong>: Do <strong>Spectral Decomposition</strong> (eigen-decomposition) or Jordan Decomposition, and then use the modal matrix (matrix of eigenvectors) to do similarity transform.</li><li><strong>The Gilbert Realization</strong>: Let $G(s)$ be a $p\times m$ rational transfer function with simple poles (nonrepeated) at $\lambda_i,\;i=1,2,\ldots,k$. Calculate partial fraction expansion $$G(s)=\sum^k_{i=1}\frac{R_i}{s-\lambda_i},\qquad \text{Residue}\;R_i=\lim_{s\to\lambda_i}(s-\lambda_i)G(s)$$ Let $r_i=\rho(R_i)$, now write $R_i=C_iB_i$ where $C_ i\in\mathbb{R}^ {p\times r_ i},\;B_ i\in\mathbb{R}^ {r_ i\times p}$, then write $$A=\mathrm{blkdiag}\{\lambda_i I_{r_i}\},\;B^\top=[B_1^\top \;\cdots\; B^\top_k],\;C=[C_1\; \cdots\;C_k]$$, then $(A,B,C)$ is a realization of $G(s)$ with order $n=\sum^k_1 r_i$</li></ul><p>For MIMO system the cannonical forms with be quite complex:</p><ul><li><strong>Controllable Cannonical Form (for MIMO)</strong>: Here we provide a way to convert from controllable LTI system to controllable. The collection of independent columns of $\mathcal{C}$ may be expressed as $$M=[b_1\;Ab_1\; \cdots\;A^{\mu_1-1}b_1\;|\;b_2\;Ab_2\;\cdots\;A^{\mu_2-1}b_2\;|\;\cdots\;|\;b_p\;Ab_p\;\cdots\;A^{\mu_p-1}b_p]$$ Construct $M^{-1}$ and then $T$:$$M^{-1}=\left[m_{11}^\top\;m_{12}^\top\;\cdots\;m_{1\mu_1}^\top\;\middle|\;\cdots\;\middle|\;m_{p1}^\top\;m_{p2}^\top\;\cdots\;m_{p\mu_p}^\top \right]^\top$$ $$T=\left[m_{1\mu_1}^\top\;(m_{1\mu_1}A)^\top\;\cdots\;\left(m_{1\mu_1}A^{\mu_1-1}\right)^\top\;\middle|\;\cdots\;\middle|\; m_{p\mu_p}^\top\;(m_{p\mu_p}A)^\top\;\cdots\;\left(m_{p\mu_p}A^{\mu_p-1}\right)^\top\right]^\top$$<br>Perform similarity transform with $\bar{x}=Tx$ and the canonical form will be obtained like following:<br>$$\bar{A}=\begin{bmatrix}\bar{A}_ {\mu_1\times\mu_1}&amp;\mathbf{0}_ {\cdot\cdot}&amp;\cdots&amp;\mathbf{0}_ {\cdot\cdot} \\ \mathbf{0}_ {\cdot\cdot}&amp;\bar{A}_ {\mu_2\times\mu_2}&amp;\cdots&amp;\mathbf{0}_ {\cdot\cdot}\\ \vdots&amp;\vdots&amp;\ddots&amp;\vdots \\ \mathbf{0}_ {\cdot\cdot}&amp;\mathbf{0}_ {\cdot\cdot}&amp;\cdots&amp;\bar{A}_ {\mu_ p\times\mu_ p} \end{bmatrix},\quad\bar{B}=\begin{bmatrix}\mathbf{0}_ {\cdot n}\\ \mathbf{0}_ {\cdot (n-1)}\\ \vdots\\ \mathbf{0}_ {\cdot 1}\end{bmatrix}$$<br>Here $\bar{A}_ {\mu_ i\times\mu_ i}$ is the same structure as in SISO, $\mathbf{0}_ {\cdot\cdot}$ is a zero matrix except the last row, $\mathbf{0}_ {\cdot i}$ is a zero matrix except for the last row, and in the last row there are $i$ non-zeros on the right with the first element being 1.</li></ul><h1 id="System-Performance">System Performance<a class="header-anchor" href="#System-Performance"> ❮</a></h1><ul><li><p><strong>System Characteristic Equation</strong>: The polynomical with the roots equal to the poles of the output that are independent of the input.</p></li><li><p><strong>System Type</strong>: A plant $G$ can always be written as $G(s)=\frac{K\prod^m_{i=1}(s-s_i)}{s^N\prod^p_{j=1}(s-s_j)},\;z_i,z_j\neq 0$ or $G(z)=\frac{K\prod^m_{i=1}(z-z_i)}{(z-1)^N\prod^p_{j=1}(z-z_j)},\;z_i,z_j\neq 1$. Here $N$ is called the system type of $G(z)$.</p></li><li><p>Properties that matters for a controller:</p><ol><li>Stability</li><li>Steady state accuracy</li><li>Transient response</li><li>Sensitivity</li><li>Exogenous disturbance rejection</li><li>Bounded control effort</li></ol></li></ul><h2 id="Stability">Stability<a class="header-anchor" href="#Stability"> ❮</a></h2><ul><li><strong>Stability</strong> means when the time goes to infinity, the system response is bounded.<ul><li>A system is <strong>stable</strong> if all its poles lies in the left half of $s$-plane or all inside the unit circle of $z$-plane.</li><li>A system is <strong>marginally stable</strong> if one of the pole is on the imaginary axis of $s$-plane or on the unit circle of $z$-plane.</li></ul></li><li>Stability of linear systems is independent of input<ul><li>The stability of a linear system can be evaluated by its characteristic equation $1-G_{op}(z)=0$, where $G_{op}$ is the open-loop transfer function (transfer function when input is eliminated, or feedback route is cut off).</li></ul></li><li>Methods to evaluate stability<ul><li><strong>Routh-Hurwitz Criterion</strong>: $s$-plane (omited here, see <a href="https://en.wikipedia.org/wiki/Routh%E2%80%93Hurwitz_stability_criterion">Wikipedia</a>)<ul><li>For discrete system, a strategy is use bilinear transformation: $z=e^{\omega T}\approx \frac{1+\omega T/2}{1-\omega T/2}$</li></ul></li><li><strong>Jury Criterion</strong>: $z$-plane (see <a href="https://en.wikipedia.org/wiki/Jury_stability_criterion">Wikipedia</a>)</li><li><strong>Root Locus Method</strong>: both $s$- and $z$-plane (see <a href="https://en.wikipedia.org/wiki/Root_locus">Wikipedia</a>, <code>rlocus</code> in MATLAB)</li><li><strong>Nyquist Criterion</strong>: both $s$- and $z$-plane (see <a href="https://en.wikipedia.org/wiki/Nyquist_stability_criterion">Wikipedia</a>, <code>nyquist</code> in MATLAB)<ul><li>It works for both continuous and discrete systems, the difference is that in $s$-plane the detour point is at $s=0$ while in $z$-plane the detour point is at $z=1$.</li></ul></li><li><strong>Bode Diagrams</strong>: draw frequency response for (pulse) transfer function, works for both $s$- and $z$-plane (see <a href="https://en.wikipedia.org/wiki/Bode_plot">Wikipedia</a>, <code>bode</code> in MATLAB)</li></ul><blockquote><p>A review of the stability judgement method <a href="https://www.zhihu.com/question/60272694">here at 知乎</a></p></blockquote></li></ul><h2 id="Lyaponov-Stability">Lyaponov Stability<a class="header-anchor" href="#Lyaponov-Stability"> ❮</a></h2><blockquote><p>Lyaponove Stability is only concerned with the effect of initial conditions on the response of the system (ZIR)</p></blockquote><ul><li><strong>Equilibrium Point</strong> $x_e$: Consider NLTV $\dot{x}(t)=f(x(t),u(t),t)$, equilibrium point satisfies $x(t_0)=x_e,\;u(t)\equiv 0\Rightarrow x(t)=x_e,\;\text{i.e. }f(x_e,0,t)=0,\;\forall t&gt;t_0$<ul><li>For discrete system, it’s $x(k+1)=x(k)=x_e$</li><li>For LTI system, $x_e$ can be calculated from $Ax_e=0$, so the origin $x=0$ is always an equilibrium point.</li><li>Set of equilibrium points in LTI systems are connected.</li></ul></li><li><strong>Lyapunov stability</strong>: An equilibrium point $x_e$ of the system $\dot{x}=A(t)x$ is <strong>stable (in the sense of Lyapunov)</strong> iff $\forall \epsilon&gt;0,\;\exists \delta(t_0,\epsilon)&gt;0$ s.t. $\Vert x(t_0)-x_e\Vert&lt;\delta\Rightarrow\Vert x(t)-x_e\Vert &lt;\epsilon,\;\forall t&gt;t_0$<ul><li>$x_e$ is <strong>uniformly stable</strong> if $\delta=\delta(\epsilon)$ (regardless of $t_0$)</li><li>$x_e$ <em>in LTI</em> is stable $\Rightarrow x_e$ is uniformly stable</li><li>$x_e$ is <strong>asymptotically stable</strong> if $\Vert x(t)-x_e\Vert\to 0$ as $t\to 0$</li><li>$x_e$ is <strong>exponentially stable</strong> if $\Vert x(t)-x_e\Vert \leqslant \gamma e^{-\lambda(t-t_0)}\Vert x(t_0)-x(e)\Vert$</li><li>$x_e$ <em>in LTI</em> is asymptotically stable $\Rightarrow x_e$ is exponentially stable</li><li>$x_e$ is <strong>globally stable</strong> if $\delta$ can be chosen arbitrarily large</li></ul></li><li>For LTV system, the system is stable (the zero solution is stable) iff $\Phi(t,t_0)$ is bounded by $K(t_0)$.<ul><li>If bounded by constant $K$, then the system is uniformly stable.</li><li>If bounded by constant $K$ and $\Vert\Phi(t,0)\Vert\to 0$ as $t\to 0$, then the system is asymptotically stable.</li></ul></li><li>For LTI system $\dot{x}=Ax$, it is Lyapunov stable iff $\mathrm{Re}(\lambda_i)\leqslant 0$ or $\mathrm{Re}(\lambda_i)=0,\;\eta_i=1$. ($\eta_i$ is the multiplicity of $\lambda_i$)<ul><li>If $\mathrm{Re}(\lambda_i)&lt;0$, then the system is asymptotically stable</li></ul></li><li>Internal stability: concerns the state variables</li><li>External stability: concerns the output variables</li></ul><blockquote><p>Notes for contents below:</p><ul><li>Positive definite (pd.) function: function $V$ is pd. wrt. $p$ if $V(x)&gt;0,\;x\neq p$ and $V(x)=0,\;x=p$</li><li>$C^n$ denotes the set of continuous and at least n-th differentiable functions</li></ul></blockquote><ul><li><p><strong>Lyapunov’s Direct Method</strong>: Let $\mathcal{U}$ be an open neighborhood of $p$ and let $V:\mathcal{U}-&gt;\mathbb{R}$ be a countinuous positive definite $C^1$ function wrt. $p$, we have following two conclusions:</p><ol><li>If $\dot{V}\leqslant 0$ on $\mathcal{U}\backslash\{p\}$ then $p$ is a stable fixed point of $\dot{x}=f(x)$</li><li>If $\dot{V}&lt; 0$ on $\mathcal{U}\backslash\{p\}$ then $p$ is an asymptotically stable fixed point of $\dot{x}=f(x)$</li></ol></li><li><p><strong>Lyapunov Function</strong>:</p><ul><li>A function satisfying conclusion 1 is called a Lyapunov function</li><li>A function satisfying conclusion 2 is called a <strong>strict</strong> Lyapunov function</li><li>A function that is $C^1$ and pd. is called a Lyapunov function candidate</li></ul><blockquote><p>The energy function usually can be used as Lyapunov function. If it’s only semi-positive definite, one can use <a href="https://en.wikipedia.org/wiki/LaSalle%27s_invariance_principle">LaSalle’s Theorem</a></p></blockquote></li><li><p>For LTI system, the zero solution of $\dot{x}=Ax$ is asymptotically stable iff $\forall$ pd. hermitian matrices $Q$, equation $A^*P+PA=-Q$ has a unique hermitian solution $P$ that is positive definite.</p><ul><li>$A^*P+PA=-Q$ is called Lyapunov’s Matrix Equation</li></ul><blockquote><p>here $V(x)=x^* Px=\int^\infty_0 x^*(t)Qx(t)dt$, which can be also called cost-to-go, or generalized energy</p></blockquote></li><li><p><strong>Lyapunov’s Indirect Method</strong> (Lyapunov’s First Method / Lyapunov’s Linearization Theorem): The nonlinear system $\dot{x}=f(x)$ is (locally) asymptotically stable near the equilibrium point $x_e$ if the linearized system $\dot{x}_L=\frac{\partial f}{\partial x}(x_e)x_L$ is asymptotically stable.</p></li></ul><h2 id="Bounded-Input-Bounded-Output-Stability">Bounded-Input Bounded-Output Stability<a class="header-anchor" href="#Bounded-Input-Bounded-Output-Stability"> ❮</a></h2><blockquote><p>BIBO stability is only concerned with the response of the system to the input (ZSR).</p></blockquote><ul><li><strong>Bounded-Input Bounded-Output (BIBO) stability</strong>: The LTV system is said to be (uniformly) BIBO stable if there exists a finite constant $g$ s.t. $\forall u(\cdot)$, its forced response $y_f(\cdot)$ satisfies $$ \sup_{t\in[0,\infty)}\Vert y_f(t)\Vert \leqslant g \sup_{t\in[0,\infty)} \Vert u(t)\Vert $$<blockquote><p>The impulse response can be analyzed to assess BIBO stability<br>The LTV system is uniformly BIBO stable iff every entry of $D(t)$ is bounded and $\sup_{t\geqslant 0}\int^t_0|g_{ij}(t,\tau)|d\tau &lt;\infty$ for every entry $g_{ij}$ of the matrix $C(t)\Phi(t,\tau)B(\tau)$.</p></blockquote></li><li>BIBO stability is related with the stability descibed in classical control theory.</li><li>Exponential Lyapunov Stability $\Rightarrow$ BIBO stability</li></ul><h2 id="Steady-State-Accuracy">Steady State Accuracy<a class="header-anchor" href="#Steady-State-Accuracy"> ❮</a></h2><p>Steady state accurary can be derived from the property of Laplace/Z-transform as mentioned above (assuming stability)<br>$$\lim\limits_{t\to \infty} f(t) = \lim\limits_{z\to 1} (z-1)F(z) = \lim\limits_{s\to 0}sF(s)$$</p><h2 id="Transient-Response">Transient Response<a class="header-anchor" href="#Transient-Response"> ❮</a></h2><p>Some measurements of transient response (with step input):</p><ul><li><strong>Rise time</strong> $t_r$: time from 10% to 90% of steady state value</li><li><strong>Peak overshoot</strong>: $M_p$ for overshoot magnitude and $t_p$ for time</li><li><strong>Settling time</strong> $t_s$: time after which the magnitude fall in $1-d$ to $1-d$ final value. $d$ is usually %2~5.</li></ul><h2 id="Sensitivity">Sensitivity<a class="header-anchor" href="#Sensitivity"> ❮</a></h2><p>Given a transfer function $H(z)$ with parameter $\Theta\in\mathbb{R}$, then sensitivity is defined as $S_H=\frac{\partial H}{\partial \Theta}\cdot\frac{\Theta}{H} = \frac{\partial H/H}{\partial \Theta/\Theta}$</p><h1 id="Discretization-and-Linearization">Discretization and Linearization<a class="header-anchor" href="#Discretization-and-Linearization"> ❮</a></h1><h2 id="Discretization-Example">Discretization Example<a class="header-anchor" href="#Discretization-Example"> ❮</a></h2><p>The following image shows a minial example of sampling and hold.</p><img src="/blog/2020-06/ControlSystemNotes/snh.png" class="" title="A minimal example of a conversion process with analog and digital signals"><h2 id="Sampling-A-D">Sampling (A/D)<a class="header-anchor" href="#Sampling-A-D"> ❮</a></h2><ul><li>Ideal sampler (a.k.a impulse modulator) converts a continuous signal $e: \mathbb{R}_+ \to \mathbb{R}$ to a discrete one $\hat{e}: \mathbb{N}\to \mathbb{R}$, such that $$ \hat{e}=e(t)\delta(t-kT)=e(t)\delta_T(t); \forall k\in \mathbb{N} $$<ul><li>Ideal sampler is actually applying starred transform.</li></ul></li><li>How to sample? A rule of thumb used to select sampling rates is chosing a rate of at least 5 samples per time constant.<ul><li>The $\tau$ appearing in the transient response term $ke^{-t/\tau}$ of a first order analog system is called the time constant.</li><li>If the sampling time is too large, it can make the system unstable.</li></ul></li></ul><h2 id="Reconstruction-Hold-D-A">Reconstruction/Hold (D/A)<a class="header-anchor" href="#Reconstruction-Hold-D-A"> ❮</a></h2><ul><li>Zero order hold (ZOH): $ZOH(\{e(k)\}_{k\in\mathbb{N}})(t) = e(k)\;for\;kT\leq t\leq (k+1)T$<ul><li>Alternative form: $ZOH(\{e(k)\})=\sum^\infty_{k=0}e(k)(H(t-kT)-H(t-(k+1)T))$</li><li>Its Laplace Transform: $G_{ZOH}(s)=\frac{1-e^{-Ts}}{s}$</li></ul></li><li>First order hold (FOH): (delayed version) $$FOH(\{e(k)\}_ {k\in\mathbb{N}})(t)=\sum_ {k\in\mathbb{N}}\left[e(kT)+\frac{t-kT}{T}(e(kT)-e((k-1)T)) \right]\left[H(t-kT)-H(t-(k+1)T) \right]$$</li></ul><h2 id="State-Space-Representation-2">State Space Representation<a class="header-anchor" href="#State-Space-Representation-2"> ❮</a></h2><p>Suppose we are given the LTI continuous system<br>$$\begin{align*} \dot{x}(t) &amp;= Ax(t)+Bu(t) \\ y(t)&amp;=Cx(t)+Du(t) \end{align*}$$<br>If the input is sampled and ZOH and the output is sampled, then<br>$$\begin{align*} x(k+1)&amp;=\bar{A}x(k)+\bar{B}u(k) \\ y(k)&amp;=\bar{C}x(k)+\bar{D}u(k)\end{align*}$$<br>where $\bar{A}=\Phi((k+1)T,kT)=e^{AkT}$</br><br>$\bar{B}=\int^{(k+1)T}_{kT}\Phi((k+1)T,\tau)B\mathrm{d}\tau=A^{-1}(e^{AT}-I)$</br><br>$\bar{C}=C$ and $\bar{D}=D$</p><blockquote><p>Steps to apply conversion:</p><ol><li>Dervice SS model for analog system</li><li>Calculate discrete representation (<code>c2d</code> in MATLAB)</li><li>Calculate pulse transfer function (<code>ss2tf</code> in MATLAB)<br>If there is a complex system with multiple sampling and holding, a general rule is</li></ol><ul><li>Each ZOH output is assumed to be an input</li><li>Each sampler input is assumed to be an output<br>and then create continuous state space from analog part of the system, then discretize them to generate discrete equations</li></ul></blockquote><h2 id="s-plane-and-z-plane">$s$-plane and $z$-plane<a class="header-anchor" href="#s-plane-and-z-plane"> ❮</a></h2><p>When converting $s$ to $z$, the complex variables are related by $z=e^{Ts}$. Suppose $s=\sigma+j\omega$, then $z=e^{T\sigma}\angle \omega T$</p><blockquote><p>Note: if frequencies differ in integer multiples of the sampling frequency $\frac{2\pi}{T}=\omega_s$, then they are sampled into the same location in the $z$-plane.</p></blockquote><p>For transient response relationship, suppose $s$-plane poles occur at $s=\sigma\pm j\omega$, then the transient response if $Ae^{\sigma t}\cos(\omega t+\varphi)$. When sampling occurs at $z$-plane poles, then the transient response if $Ae^{\sigma kT}\cos(\omega kT+\varphi)$.</p><details><summary>Example: 2nd order transfer function</summary>$$G(s)=\frac{\omega_n^2}{s^2+2\xi\omega_ns+\omega_n^2}$$The $z$-plane poles occur at $z=r\angle\pm\theta$ where $r=e^{-\xi\omega_n T}$ and $\theta=\omega_n T\sqrt{1-\xi^2}$.<p>Then we can get the inverse relationship</p><ul><li>$\xi=-\ln( r)/\sqrt{\ln^2( r)+\theta^2}$</li><li>$\omega_n=(1/T)\sqrt{\ln^2( r)+\theta^2}$</li><li>(time constant) $\tau=-T/\ln( r)$</li></ul></details><h2 id="Linearization">Linearization<a class="header-anchor" href="#Linearization"> ❮</a></h2><ul><li><strong>Jacobian Linearization</strong>: linearize $\dot{x}=f(x,u)$ at an equilibrium $(x_e, u_e)$ is $$\frac{\mathrm{d}z}{\mathrm{d}t}=Az+Bv,\quad\text{where}\;A=\left.\frac{\mathrm{d}f}{\mathrm{d}x}\right|_ {\begin{split}x=x_e\\u=u_e\end{split}},\;B=\left.\frac{\mathrm{d}f}{\mathrm{d}u}\right|_ {\begin{split}x=x_e\\u=u_e\end{split}},\;z=(x-x_e),\;v=(u-u_e)$$<ul><li>change $(x_e, u_e)$ to a trajectory $(x_e(t), u_e(t))$ we can linearize the system about a trajectory.</li></ul></li></ul><h1 id="Controllers">Controllers<a class="header-anchor" href="#Controllers"> ❮</a></h1><h2 id="Full-State-Feedback">Full State Feedback<a class="header-anchor" href="#Full-State-Feedback"> ❮</a></h2><blockquote><p>This method can be used for both continuous and discrete systems, just make sure to use corresponding method for choosing correct closed-loop transfer function.</p></blockquote><p>For state space systems, with access to all of the state variables, we can change the $A$ matrix and thereby change the system dynamics by feedback.</p><p>Consider SISO LTI system ($u\in\mathbb{R},y\in\mathbb{R}$), we define the input as $u\equiv Kx+Ev$ where $K\in\mathbb{R}^{1\times n},\;E\in\mathbb{R}$ is an input matrix and $v(t)\in\mathbb{R}^\mathbb{R}$ is the exogeneous (externally applied) input. The new system will be $$\begin{align}\dot{x}&amp;=(A+BK)x+BEv\\y&amp;=(C+DK)x+DEv\end{align}$$<br>The mission is to find a state update matrix $A_{\mathrm{CL}}\equiv A+BK$ with desired set of eigenvalues, therefore we can construct $A_{\mathrm{CL}}$ with specific eigenvalues and then calculate $K$. This process will be quite easy if the system is already in controllable cannonical form. (which can be constructed directly from transfer function or using similarity transform)</p><p>Another way (SISO only) to calculate $K$ without controllable cannonical form is using the following formulae given the desired characteristic polynomial $\phi^{\star}(s)=s^n+\sum^{n-1}_ {i=0} a^\star_i s^i$ and original characteristic polynomial $\phi(s)=s^n+\sum^{n-1}_ {i=0} a_i s^i$</p><ul><li><strong>Ackermann’s Formula</strong>: $K=-e^\top_n\mathcal{C}^{-1}\phi^\star(A)$ (here $e_i$ is unit vector with 1 at i-th position)</li><li><strong>Bass-Gura’s Formula</strong>: $$K=-[(a^\star_{n-1}-a_{n-1}) \;\cdots\;(a^\star_0-a_0)]\begin{bmatrix}1&amp;a_{n-1}&amp;a_{n-2}&amp;\cdots&amp;a_1\\&amp;1&amp;a_{n-1}&amp;\cdots&amp;a_2\\ &amp;&amp;\ddots&amp;\ddots&amp;\vdots \\ &amp;&amp;&amp;1&amp;a_{n-1}\\  &amp;&amp;&amp;&amp;1\end{bmatrix}^{-1}\mathcal{C}^{-1}$$</li></ul><p>Note that the zeros of transfer function will not be affected by state feedback.</p><h2 id="State-Estimation-Observer-Design">State Estimation (Observer Design)<a class="header-anchor" href="#State-Estimation-Observer-Design"> ❮</a></h2><blockquote><p>Some times we don’t have the direct access to the state, we need construct an observer<br>For stochastic version, please check <a href="/blog/2019-03/StochasticSystemNotes/#Observation-Filtering">my notes for stochastic system</a></p></blockquote><p>Assume a plant $\Sigma$ and an (<strong>Luenberger</strong>) <strong>observer</strong> $\hat{\Sigma}$:<br>$$\Sigma:\begin{cases}\dot{x}=Ax+Bu\\ y=Cx\end{cases},\quad \hat{\Sigma}:\begin{cases} \dot{\hat{x}}=A\hat{x}+Bu+L(y-\hat{y})\\ y=C\hat{x}\end{cases}$$</p><p>Subtract observer dynamics from plant dynamics and define $e\equiv x-\hat{x}$, the dynamics for $e$ is $\dot{e}=(A-LC)e$ and $y-\hat{y}=Ce$. This error dynamic $A_e=A-LC$ can be easily changed with observable cannonical form. (which similarly can be constructed directly from transfer function or using similarity transform)</p><ul><li><strong>Reduced-order Observer</strong>: If the state length of the system $n$ is large while $n-p$ is small, split the system and let $x_1$ holds the states that can be measured directly while $x_2$ holds states that are to be estimated, (i.e. $y=x_1+Du$). Define $z=\hat{x}_2-Lx_1$ then the system runs like $$\begin{align*}\begin{bmatrix}x_1 \\ \hat{x}_2\end{bmatrix}&amp;=\begin{bmatrix} y-Du\\ z+Lx_1 \end{bmatrix}\qquad\begin{split}&amp;\text{measurement} \\ &amp;\text{observer}\end{split} \\ u&amp;=K\begin{bmatrix}x_1 \\ \hat{x}_2 \end{bmatrix} + v \qquad\text{control law}\end{align*}$$ And then the error we care about is only $e=x_2-\hat{x}_2$.</li><li><strong>Ackermann’s Formula</strong>: $L=\phi^\star(A)\mathcal{O}^{-1}e_n$ ($\phi^\star$ is the desired characteristic function for $A_e$)</li><li><strong>Separation Principle</strong>: If a stable observer and stable state feedback are designed for an LTI system, then the combined observer and feedback will be stable.</li></ul><blockquote><p>Errors from state estimation</p><ol><li>Inaccurate knowledge of $A$ and $B$</li><li>Initial condition uncertainty</li><li>Disturbance or sensor error<br>It’s advised to choose observer poles to be 2-4x faster than closed loop poles</li></ol></blockquote><h2 id="LQR"><a href="https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator">LQR</a><a class="header-anchor" href="#LQR"> ❮</a></h2><blockquote><p>Motivation: handle control constraints and time varying dynamics with performance metric (ideas of optimal control)<br>Note: $x^\top Ax$ is called a <strong>quadratic form</strong>, $x^\top Ay$ is called a <strong>bilinear form</strong></p></blockquote><ul><li>A quadratic function $f(x)=x^\top Dx+C^\top x+c_0$ has one minimizer iff $D\succ 0$, or multiple minimizers iff $D\succeq 0$.</li><li>(discrete finite time) <strong>Linear Quadratic Regulator</strong> (LQR): the control problem is defined as $$\begin{align*}\min_{u\in\left(\mathbb{R}^m\right)^{\{0,\ldots,N\}}} J_{N}(u,x_0)&amp;=\frac{1}{2}\sum^{N}_{k=0}(x^\top(k)Q(k)x(k)+u^\top(k)R(k)u(k)) \\ \mathrm{s.t.}\qquad x(k+1) &amp;= A(k)x(k) + B(k)u(k)\quad \forall k\in\{0,\ldots,N-1\}\\ y(k)&amp;=C(k)x(k)\\ x(0)&amp;=x_0\end{align*}$$ where $Q(k)\succ 0$ and $R(k)\succ 0$</li><li><strong>Bellman’s Principle of Optimality</strong>: If a closed loop control $u^\star$ is optimal over the interval $0\leqslant k\leqslant N$, it’s also optimal over any subinterval $m\leqslant k\leqslant N$ where $m\in\{0,\ldots,N\}$</li><li><strong>The Minimum Principle</strong>: The optimal input to the LQR problem satisfies the following backward equations: $$\begin{align*}u^\star(k)&amp;=-K(x)x(k) \\ K(k)&amp;=\left[B^\top(k) P(k+1)B(k)+\frac{1}{2}R(k)\right]^{-1}B^\top(k)P(k+1)A(k) \\ P(k)&amp;=A^\top(k)P(k+1)[A(k)- B(k)K(k)]+\frac{1}{2}Q(k)\end{align*}$$ and $P(N)=Q(N),\;K(N)=0$. The optimal cost is $J^\star_N=x^\top(0)P(0)x(0)$</li><li>For infinite horizon, $K(k)$ start becoming constants. The optimal input for LQR problem (assuming the system became LTI when $N\to\infty$) is $u^*(k)=-Kx(k)$ where $$K=(B^\top PB+R/2)^{-1}B^\top PA$$ and $P\succ 0$ is the unique solution to the discrete-time <strong>algebraic Riccati Equation</strong>: $$P=A^\top PA-A^\top PB\left(B^\top PB+R/2\right)^{-1}B^\top PA+Q/2$$</li></ul>]]></content>
    
    
    <summary type="html">&lt;div class=&quot;note warning&quot;&gt;&lt;p&gt;&lt;strong&gt;本文是用英文写的，且尚未翻译成中文&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;$\require{mathtools}$ &lt;!-- load the required TeX package --&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;This note combines content from ME 564 Linear Systems and ME 561 Discrete Digital Control&lt;/li&gt;
&lt;li&gt;Please read &lt;a href=&quot;/blog/2020-06/AlgebraBasicsNotes/&quot; title=&quot;the Algebra Basics notes&quot;&gt;the Algebra Basics notes&lt;/a&gt; first if you are not familiar with related concepts.&lt;/li&gt;
&lt;li&gt;In this note, $f\in\mathbb{F}^\mathbb{G}$ stands for a function with domain in $\mathbb{G}$ and co-domain in $\mathbb{F}$, i.e. $f:\mathbb{F}\to\mathbb{G}$, $H(x)$ generally stands for Heaviside function (step function)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Transforms&quot;&gt;Transforms&lt;a class=&quot;header-anchor&quot; href=&quot;#Transforms&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&quot;Laplace-Transform&quot;&gt;Laplace Transform&lt;a class=&quot;header-anchor&quot; href=&quot;#Laplace-Transform&quot;&gt; ❮&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Definition: $F(s)=\mathcal{L}\{f(t)\}(s)=\int^\infty_0 f(t)e^{-st}\mathrm{d}t$
&lt;blockquote&gt;
&lt;p&gt;Note that the transform is not well defined for all functions in $\mathbb{C}^\mathbb{R}$. And the transform is only valid for $s$ in a region of convergence, which is usually separated by 0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Laplace Transform is a linear map from $(\mathbb{C}^\mathbb{R}, \mathbb{C})$ to $(\mathbb{C}^\mathbb{C}, \mathbb{C})$ and it’s one-to-one.&lt;/li&gt;
&lt;li&gt;Properties: (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Laplace_transform&quot;&gt;Wikipedia&lt;/a&gt; or &lt;a href=&quot;https://lpsa.swarthmore.edu/LaplaceZTable/LaplacePropTable.html&quot;&gt;this page&lt;/a&gt; for full list)
&lt;ul&gt;
&lt;li&gt;Derivative: $f’(t) \xleftrightarrow{\mathcal{L}} sF(s)-f(0^-)$&lt;/li&gt;
&lt;li&gt;Integration: $\int^t_0 f(\tau)d\tau \xleftrightarrow{\mathcal{L}} \frac{1}{s}F(s)$&lt;/li&gt;
&lt;li&gt;Delay: $f(t-a)H(t-a) \xleftrightarrow{\mathcal{L}} e^{-as}F(s)$&lt;/li&gt;
&lt;li&gt;Convolution: $\int^t_0 f(\tau)g(t-\tau)\mathrm{d}\tau \xleftrightarrow{\mathcal{L}} F(s)G(s)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stationary Value: $\lim\limits_{t\to 0} f(t) = \lim\limits_{s\to \infty} sF(s), \lim\limits_{t\to \infty} f(t) = \lim\limits_{s\to 0} sF(s)$&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Notes" scheme="http://zyxin.xyz/blog/categories/Notes/"/>
    
    <category term="Control" scheme="http://zyxin.xyz/blog/categories/Notes/Control/"/>
    
    
    <category term="Math" scheme="http://zyxin.xyz/blog/tags/Math/"/>
    
    <category term="Control" scheme="http://zyxin.xyz/blog/tags/Control/"/>
    
  </entry>
  
  <entry>
    <title>终端的特殊控制符</title>
    <link href="http://zyxin.xyz/blog/2020-05/TerminalControlCharacters/"/>
    <id>http://zyxin.xyz/blog/2020-05/TerminalControlCharacters/</id>
    <published>2020-05-10T22:49:54.000Z</published>
    <updated>2021-07-12T02:40:53.188Z</updated>
    
    <content type="html"><![CDATA[<p>之前碰到过很多终端工具可以显示非常好看的进度条，或者显示丰富的颜色，甚至还有的直接可以在终端通过字符绘制UI（a.k.a. <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">TUI</a>），我一直都很好奇是怎么做到的。之后又知道了curses这个Python库和它的一些高层封装（例如asciimatics），然后最终在Stack Overflow里面查到了这些都是通过特殊的终端控制符来实现的。本文就介绍这些终端控制符的使用方法，他们很适合用来写一个简单无依赖的TUI。如果需要更复杂和全面的TUI功能，还是最好使用封装好的库。</p><h1 id="ASCII-控制符">ASCII 控制符<a class="header-anchor" href="#ASCII-控制符"> ❮</a></h1><p>在最开始接触编程的时候，如果你学的是C，那你一定很熟悉<code>\n</code>，这就是一个”换行“的转义字符，代表终端光标令起一行。有时你还会碰到<code>\r</code>，这是”回车“。“回车”这个名字来源于打字机时代，在使用打字机的时候，如果你需要新起一行，那么需要的操作是：转动滚筒把纸往外抽一行，再把字车（相当与打印机的打印头）移到最左端。这两个操作的名字分别是“换行”和“回车”。因此严格来说另起一行的字符串应该是<code>\r\n</code>，这也是Windows的标准，而在Unix中则简化成<code>\n</code>会自动执行回车。</p><span id="more"></span><p>换行和回车是两个非常常用的控制字符，也是定义在了ASCII表中的控制字符。在ASCII表中还定义了其他的控制字符，列在下面了。</p><table><thead><tr><th>ASCII名字</th><th>ASCII码</th><th>printf风格转义</th><th>用途</th></tr></thead><tbody><tr><td>BEL 铃声</td><td>0x07</td><td><code>\a</code></td><td>哔一下（执不执行取决于终端）</td></tr><tr><td>BS 退格</td><td>0x08</td><td><code>\b</code></td><td>*光标回退一格</td></tr><tr><td>ESC 退出</td><td>0x1B</td><td><code>\e</code></td><td>可代表按下ESC键，不是C标准</td></tr><tr><td>FF 换页</td><td>0x0C</td><td><code>\f</code></td><td>光标移到新一页</td></tr><tr><td>LF 换行</td><td>0x0A</td><td><code>\n</code></td><td>光标下移一行</td></tr><tr><td>CR 回车</td><td>0x0D</td><td><code>\r</code></td><td>光标回到行首</td></tr><tr><td>HT 水平制表</td><td>0x09</td><td><code>\t</code></td><td>标记水平制表位（Tab键）</td></tr><tr><td>VT 垂直制表</td><td>0x0B</td><td><code>\v</code></td><td>标记垂直制表位</td></tr><tr><td>NUL 空值</td><td>0x00</td><td><code>\0</code></td><td>代表啥也没有，C里面终结字符串</td></tr><tr><td>-</td><td>-</td><td>**<code>\c</code></td><td>终止输出，基本不被支持了</td></tr></tbody></table><p>*光标这里泛指各类终端的指示当前文本位置的东西，在打字机上叫“type guide”，在显示屏上里面叫“光标 cursor”，而在有些场合也叫指针。<br>**这个用法貌似只在一些终端中有，我也不确定它是否有对应一个字符。在<a href="http://www.gnu.org/software/coreutils/manual/html_node/printf-invocation.html">GNU的文档</a>里有简短解释。</p><h1 id="ANSI-VT100-控制符（串）">ANSI/VT100 控制符（串）<a class="header-anchor" href="#ANSI-VT100-控制符（串）"> ❮</a></h1><p>很多终端都支持彩色文字的输出，而彩色文字的表达方式通常都参考ANSI的色彩标准。而ANSI用来实现色彩显示的转义表还定义了指针控制和设备管理的功能。</p><p>这一类控制符实际上是个字符串，所以应该叫控制串？他们都由<code>&lt;ESC&gt;</code>字符开头，也就是<code>0x1B</code>。所以我推测实际上<code>ESC</code>的双关（退出/转义）也被用到了这里哈哈。以下内容大部分来自 ANSI/VT100 Terminal Control Escape Sequences 表格，详细解释可以参考这个表格以及维基的页面。链接都放在引用部分。</p><blockquote><p><code>0x1B</code>在一些终端中会用<code>^[</code>代表，因此如果你看到了<code>^[[</code>那通常也都是通过这种方法转义的字符序列。</p></blockquote><p>我把这个表中能用于bash的字符都拎出来放在下面了。以下表中的转义序列名称都是我自己翻译的，我不知道有没有统一的中文翻译hhh。</p><h2 id="终端设备相关">终端设备相关<a class="header-anchor" href="#终端设备相关"> ❮</a></h2><table><thead><tr><th>名称</th><th>转义字符串</th></tr></thead><tbody><tr><td>查询设备码</td><td><code>&lt;ESC&gt;[c</code></td></tr><tr><td>报告设备码</td><td><code>&lt;ESC&gt;[&#123;code&#125;0c</code></td></tr><tr><td>查询光标位置</td><td><code>&lt;ESC&gt;[6n</code></td></tr><tr><td>报告光标位置</td><td><code>&lt;ESC&gt;[&#123;ROW&#125;;&#123;COLUMN&#125;R</code></td></tr><tr><td>重置设备</td><td><code>&lt;ESC&gt;c</code></td></tr></tbody></table><blockquote><p>可以在你的终端里输入<code>printf &quot;\x1b[c&quot;</code>，看看会输出什么</p></blockquote><h2 id="光标控制">光标控制<a class="header-anchor" href="#光标控制"> ❮</a></h2><table><thead><tr><th>名称</th><th>转义字符串</th></tr></thead><tbody><tr><td>设置指针位置</td><td><code>&lt;ESC&gt;[&#123;ROW&#125;;&#123;COLUMN&#125;H</code></td></tr><tr><td>指针上移</td><td><code>&lt;ESC&gt;[&#123;COUNT&#125;A</code></td></tr><tr><td>指针下移</td><td><code>&lt;ESC&gt;[&#123;COUNT&#125;B</code></td></tr><tr><td>指针前移（右移）</td><td><code>&lt;ESC&gt;[&#123;COUNT&#125;C</code></td></tr><tr><td>指针后移（左移）</td><td><code>&lt;ESC&gt;[&#123;COUNT&#125;D</code></td></tr><tr><td>保存指针位置</td><td><code>&lt;ESC&gt;[s</code></td></tr><tr><td>复原指针位置（到保存位置）</td><td><code>&lt;ESC&gt;[u</code></td></tr><tr><td>保存指针位置和属性</td><td><code>&lt;ESC&gt;7</code></td></tr><tr><td>复原指针位置和属性</td><td><code>&lt;ESC&gt;8</code></td></tr></tbody></table><h2 id="滚动">滚动<a class="header-anchor" href="#滚动"> ❮</a></h2><table><thead><tr><th>名称</th><th>转义字符串</th></tr></thead><tbody><tr><td>启用滚动</td><td><code>&lt;ESC&gt;[r</code></td></tr><tr><td>启用指定行之间滚动</td><td><code>&lt;ESC&gt;[&#123;START&#125;;&#123;END&#125;r</code></td></tr><tr><td>向下滚动一行</td><td><code>&lt;ESC&gt;D</code></td></tr><tr><td>向上滚动一行</td><td><code>&lt;ESC&gt;M</code></td></tr></tbody></table><h2 id="制表">制表<a class="header-anchor" href="#制表"> ❮</a></h2><table><thead><tr><th>名称</th><th>转义字符串</th></tr></thead><tbody><tr><td>设置对齐位</td><td><code>&lt;ESC&gt;H</code></td></tr><tr><td>清楚对齐位</td><td><code>&lt;ESC&gt;[g</code></td></tr><tr><td>清楚所有对齐位</td><td><code>&lt;ESC&gt;[3g</code></td></tr></tbody></table><h2 id="清除">清除<a class="header-anchor" href="#清除"> ❮</a></h2><table><thead><tr><th>名称</th><th>转义字符串</th></tr></thead><tbody><tr><td>清除文字到行末</td><td><code>&lt;ESC&gt;[K</code></td></tr><tr><td>清除文字到行首</td><td><code>&lt;ESC&gt;[1K</code></td></tr><tr><td>清除整行</td><td><code>&lt;ESC&gt;[2K</code></td></tr><tr><td>清除文字到屏幕底</td><td><code>&lt;ESC&gt;[J</code></td></tr><tr><td>清除文字到屏幕顶</td><td><code>&lt;ESC&gt;[1J</code></td></tr><tr><td>清屏</td><td><code>&lt;ESC&gt;[2J</code></td></tr></tbody></table><h2 id="定义">定义<a class="header-anchor" href="#定义"> ❮</a></h2><ul><li>设置文字绑定: <code>&lt;ESC&gt;[&#123;key&#125;;&quot;&#123;string&#125;&quot;p</code></li></ul><h2 id="显示颜色属性">显示颜色属性<a class="header-anchor" href="#显示颜色属性"> ❮</a></h2><ul><li>设置光标属性: <code>&lt;ESC&gt;[&#123;attr1&#125;;...;&#123;attrn&#125;m</code></li></ul><table><thead><tr><th>属性代码</th><th>属性效果</th><th>属性代码</th><th>属性效果</th><th>属性代码</th><th>属性效果</th></tr></thead><tbody><tr><td>0</td><td>重置</td><td>30</td><td>前景黑</td><td>40</td><td>背景黑</td></tr><tr><td>1</td><td>亮</td><td>31</td><td>前景红</td><td>41</td><td>背景红</td></tr><tr><td>2</td><td>暗</td><td>32</td><td>前景绿</td><td>42</td><td>背景绿</td></tr><tr><td>4</td><td>下划线</td><td>33</td><td>前景黄</td><td>43</td><td>背景黄</td></tr><tr><td>5</td><td>闪烁</td><td>34</td><td>前景蓝</td><td>44</td><td>背景蓝</td></tr><tr><td>7</td><td>反向</td><td>35</td><td>前景紫</td><td>45</td><td>背景紫</td></tr><tr><td>8</td><td>隐藏</td><td>36</td><td>前景青</td><td>46</td><td>背景青</td></tr><tr><td></td><td></td><td>37</td><td>前景白</td><td>47</td><td>背景白</td></tr></tbody></table><h1 id="Reference">Reference<a class="header-anchor" href="#Reference"> ❮</a></h1><p>ASCII转义符</p><ul><li>Wiki <a href="https://en.wikipedia.org/wiki/Escape_sequences_in_C">Escape sequences in C</a></li><li><a href="https://www.bing.com/search?q=ascii+table">Bing ASCII table</a></li><li><a href="https://linux.die.net/man/1/printf"><code>printf</code> Linux man page</a></li></ul><p>ANSI转移符</p><ul><li><a href="http://www.termsys.demon.co.uk/vtansi.htm"><code>ANSI/VT100 Terminal Control Escape Sequences</code></a></li><li>Wiki <a href="https://en.wikipedia.org/wiki/ANSI_escape_code"><code>ANSI escape code</code></a></li></ul><!-- http://ascii-table.com/ansi-escape-sequences-vt-100.phphttp://www.termsys.demon.co.uk/vtansi.htm -->]]></content>
    
    
    <summary type="html">&lt;p&gt;之前碰到过很多终端工具可以显示非常好看的进度条，或者显示丰富的颜色，甚至还有的直接可以在终端通过字符绘制UI（a.k.a. &lt;a href=&quot;https://en.wikipedia.org/wiki/Text-based_user_interface&quot;&gt;TUI&lt;/a&gt;），我一直都很好奇是怎么做到的。之后又知道了curses这个Python库和它的一些高层封装（例如asciimatics），然后最终在Stack Overflow里面查到了这些都是通过特殊的终端控制符来实现的。本文就介绍这些终端控制符的使用方法，他们很适合用来写一个简单无依赖的TUI。如果需要更复杂和全面的TUI功能，还是最好使用封装好的库。&lt;/p&gt;
&lt;h1 id=&quot;ASCII-控制符&quot;&gt;ASCII 控制符&lt;a class=&quot;header-anchor&quot; href=&quot;#ASCII-控制符&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;在最开始接触编程的时候，如果你学的是C，那你一定很熟悉&lt;code&gt;\n&lt;/code&gt;，这就是一个”换行“的转义字符，代表终端光标令起一行。有时你还会碰到&lt;code&gt;\r&lt;/code&gt;，这是”回车“。“回车”这个名字来源于打字机时代，在使用打字机的时候，如果你需要新起一行，那么需要的操作是：转动滚筒把纸往外抽一行，再把字车（相当与打印机的打印头）移到最左端。这两个操作的名字分别是“换行”和“回车”。因此严格来说另起一行的字符串应该是&lt;code&gt;\r\n&lt;/code&gt;，这也是Windows的标准，而在Unix中则简化成&lt;code&gt;\n&lt;/code&gt;会自动执行回车。&lt;/p&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    
    <category term="Shell" scheme="http://zyxin.xyz/blog/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>进程、线程与协程 (C# vs Python)</title>
    <link href="http://zyxin.xyz/blog/2019-11/ParallelismInPythonAndCsharp/"/>
    <id>http://zyxin.xyz/blog/2019-11/ParallelismInPythonAndCsharp/</id>
    <published>2019-11-07T05:57:31.000Z</published>
    <updated>2021-07-12T02:40:53.188Z</updated>
    
    <content type="html"><![CDATA[<p>近来由于项目需要，接触了一下一直没去了解过的Python异步语法，发现和之前我熟悉的C#有很多不同。在深入Python的异步逻辑之后，由于Python在语法上保留了很多语言机制的细节（比如成员函数的<code>self</code>参数），我反而对C#的异步有了更深的了解。这里就来重新梳理一下各种并行方法的区别，以及他们在C#和Python上实现的区别。（这里只讨论单机的并行机制。）</p><p>总的来说，并行机制主要有进程(Process)、线程(Thread)和协程(Coroutine)，其并行实现的开销依次递减，但是他们对每个任务的鲁棒性也是依次递减的。进程是操作系统资源分配的最小单元，线程则是能够被CPU并行处理的最小单元，而协程则是目前实现“并行”的最简单方法。一个进程中可以有多个线程，而一个线程中可以有多个协程。他们具体在特性上有以下区别</p><table><thead><tr><th></th><th>进程</th><th>线程</th><th>协程</th></tr></thead><tbody><tr><td>独立内存堆</td><td>√</td><td>×</td><td>×</td></tr><tr><td>独立处理器（可硬件并行）</td><td>√</td><td>√</td><td>×</td></tr><tr><td>独立上下文</td><td>√</td><td>√</td><td>×</td></tr><tr><td>独立栈、寄存器状态</td><td>√</td><td>√</td><td>√</td></tr></tbody></table><span id="more"></span><h1 id="进程">进程<a class="header-anchor" href="#进程"> ❮</a></h1><p>进程是系统层面实现并行的机制了，进程管理是现代操作系统的一大核心之一。进程之间互不影响，操作系统会保证一个程序崩溃了，其他程序以及系统内核不会崩溃。操作系统还会提供其他的进程管理功能，例如<a href="https://en.wikipedia.org/wiki/Scheduling_(computing)">进程调度</a>、设置进程优先级等等。不同语言底层对进程接口的实现实际上都是对系统接口的封装。</p><h2 id="一些概念">一些概念<a class="header-anchor" href="#一些概念"> ❮</a></h2><p>与进程相关的概念通常都是操作系统课程的必修知识哈哈：</p><ul><li>进程间通信(Inter-process communiation, IPC)：故名思意。常用手段有管道、共享内存、信号量(Semaphore)、消息队列等。</li><li>管道(Pipe)：管道大概是进程间通信的最常用方式？分命名管道和匿名管道, 进程双方均可往其中读写数据。</li><li>远程过程调用(Remote procedure call): 远程过程调用通过特定的消息序列化手段，可以实现进程间通信，其使用形式是把一个“远程”的函数在本地进行执行。</li><li>进程锁：如果为了避免多个进程访问同一个资源的冲突的话，就会用到进程锁，其实现方法有<a href="https://blog.csdn.net/luansxx/article/details/7736618">管道、信号量</a>、以及文件锁等。</li><li>文件锁：文件锁是实现进程互斥的一种常用手段，只需要建立空文件句柄并锁上就可了~并且文件锁还能做到权限控制，非常方便~</li></ul><h2 id="C">C#<a class="header-anchor" href="#C"> ❮</a></h2><p>C#中对进程控制的模块主要通过<a href="https://docs.microsoft.com/dotnet/api/system.diagnostics.process"><code>System.Diagnostics.Process</code></a>实现，可以实现建立进程、管理进程等，还可以指定具体的内存映射参数，如虚拟内存的页大小。而对管道的支持则是在<code>Process</code>类中有一部分，以及在<a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.pipes"><code>System.IO.Pipe</code></a>里面有更全面的接口。我觉得这样的命名空间分类是挺合理的，<code>Process</code>类的API其实只能用来进行程序调用和系统诊断，而<code>Pipe</code>则由于它和<code>Stream</code>的概念比较符合，因此归在IO空间下是合适的。</p><h2 id="Python">Python<a class="header-anchor" href="#Python"> ❮</a></h2><p>Python中对进程的控制以及通信方法的实现都在<code>multiprocess</code>包里，它的一些具体使用方法可以参考<a href="/blog/2017-12/PythonCall/" title="另一篇之前的博文">另一篇之前的博文</a>。值得一提的是，Python中还针对Unix系统提供了<code>fcntl</code>, <code>posix</code>等库专门用来调用系统底层API，这些API有部分是和进程有关的。相关内容还是查阅对应的资料会比较清楚~</p><h1 id="线程">线程<a class="header-anchor" href="#线程"> ❮</a></h1><p>线程是进程中细化的并行机制，线程的实现也需要用到操作系统的接口，不过线程的创建的管理基本都是在进程内部完成的。由于线程之间不独立内存空间，因此在C++这种能够随意操作内存的语言中，一个线程崩了，这个进程也大概率就崩了。但是在C#和Python中，由于有比较完善的Exception机制，并且没有什么机会直接操作内存，一般线程崩了主进程还是能接着跑的。多线程想必应该是大家用的最多的并行方法了~</p><h2 id="一些概念-2">一些概念<a class="header-anchor" href="#一些概念-2"> ❮</a></h2><p>在线程里面又有一些新的概念</p><ul><li>线程池(Thread pool)：线程池与内存池相似，都是为了避免频繁新建和销毁线程(or 内存)而造成额外的开销</li><li>线程锁：线程锁与进程锁相似，是为了避免线程间访问同样的资源而产生冲突（例如<a href="https://stackoverflow.com/questions/34510/what-is-a-race-condition">race condition</a>）。线程间产生访问冲突非常常见，因此程序员掌握线程锁的使用是非常必要的。线程锁在C++中的<code>&lt;mutex&gt;</code>有非常全面的实现。这里面锁的类型具有代表性，分为条件锁、自旋锁等等，具体区别可以参考<a href="https://blog.csdn.net/bian_qing_quan11/article/details/73734157">这篇博客</a>。C++的多线程非常令人头大…这里就不展开了。</li><li>事件(Event)：在多线程体系中，事件是一种常用于线程同步的机制，如果线程需要在运行过程中等待其他线程的运行，就可以使用事件机制。</li></ul><h2 id="C-2">C#<a class="header-anchor" href="#C-2"> ❮</a></h2><p>C#中与线程相关的模块在<a href="https://docs.microsoft.com/dotnet/api/system.threading"><code>System.Threading</code></a>空间下。<code>System.Threading.Thread</code>提供了线程实现的类，使用delegate即可创建线程对象。这个空间底下也提供了<code>SpinLock</code>、<code>Semaphore</code>、<code>Mutex</code>等线程锁，以及<code>AutoResetEvent</code>实现了事件机制。<code>System.Threading.ThreadPool</code>则提供了线程池的实现。另外需要指出的是C#提供了<code>lock</code>关键字，只需对冲突的对象使用<code>lock</code>锁上，那么在其对应的上下文中就能够避免冲突。</p><h2 id="Python-2">Python<a class="header-anchor" href="#Python-2"> ❮</a></h2><p>Python中与线程相关的对象在<a href="https://docs.python.org/library/threading.html"><code>threading</code></a>模块中，其中<code>Thread</code>类提供了线程实现，<code>Lock</code>, <code>Semaphore</code>提供了线程锁，<code>Event</code>实现了事件机制。Python中可以使用<code>with lock:</code>这样的块实现与C#<code>lock</code>相似的语法，但是这个地方的lock仍然需要自己声明，不如C#和Java中的<code>lock</code>用着方便。</p><p>总体而言C#和Python对多线程机制的支持都比较全面，然而CPython有一个臭名昭著的<a href="http://cenalulu.github.io/python/gil-in-python/">全局锁GIL</a>，使得其多线程效率大幅下降。因此在很多Python库中，大家宁愿使用<code>multiprocess</code>多进程来进行并行（即便需要处理进程间通信的问题），也不愿使用<code>threading</code>来完成并行任务。这一点上不得不说Python辣鸡！</p><h1 id="协程">协程<a class="header-anchor" href="#协程"> ❮</a></h1><p>协程应该是21世纪才用的比较多的技术了，并且这个概念应该是在Go里面提的最多。在前文我提到协程是并行时打了引号，这是因为协程本质上还是同一个时刻只能干一件事，没法利用硬件并行，因此我们形容协程都是用“异步”(Asychronized)而不是“并行”(Parallel)。异步是与同步相对的，只要程序能一会干点这个，一会干点那个，不按顺序来，那就可以称作异步了。协程的广泛应用是由于近些年大型服务器的负载越来越大，并发需求越来越高（<s>同时剁手的人越来越多</s>），多任务切换的开销越来越不可忽视，因此协程这个开销最小的方法就被广泛应用了。协程实际上不是一个比线程更小的概念，而是另一类概念（并行/串行 vs 异步/同步)。协程的特点是一个任务能够跑到一半就暂停，然后把状态存起来，等到需要的东西备齐了以后再把状态复原接着跑；至于暂停之前和之后是不是在同一个线程上跑、有没有跟别的任务一块跑并不重要。因此实际上协程是回调(Callback)机制的一个封装升级。</p><h2 id="一些概念-3">一些概念<a class="header-anchor" href="#一些概念-3"> ❮</a></h2><ul><li>事件循环(Event loop)：事件循环是一种非常简单的实现异步的机制，简而言之就是维护一个队列，然后把队列里的任务挨个执行，而任务随时随地可以被添加进队列。</li><li>异步执行/等待(async/await)：这两个关键词在多个语言中都有出现。async用来修饰函数，说明这个函数可以异步执行；await用来等待异步函数的结束，如果没有结束就把当前任务搁着。</li></ul><h2 id="C-3">C#<a class="header-anchor" href="#C-3"> ❮</a></h2><p>C#中没有协程的概念，C#在5.0版本中引入的<code>async</code>/<code>await</code>关键字提供了异步执行的接口。据我所知C#应该是最早一批引入这个概念的语言了，并且C#里面async和await的使用非常顺滑~。C#的async/await调度与Go一样，都是通过线程池实现，因此性能也非常不错。C#中与async/await有关的接口在<a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks%60"><code>System.Threading.Tasks</code></a>下，里面的<code>Task</code>类型是对能够await的对象的封装。</p><p>C#中也有用到Event loop来实现异步的地方，一般是在UI相关的函数中，例如整个C#里面的<code>event</code>机制都是通过事件循环来实现的。使用事件循环来完成与UI相关的异步应该是非常标准的做法了，例如Qt里面也有<code>QEventLoop</code>来实现UI的异步回调。与Event loop相关的是Dispatcher机制，Dispatcher可以将指定任务加进事件循环中执行，例如在WPF中可以用Window的Dispatcher在其他线程中将任务加进UI主线程。</p><p>另外需要指出的是C#还可以通过<code>yield</code>关键词实现异步，<code>yield return</code>可能是C#最早的异步机制了，不过功能有限，只能与<code>IEnumerable</code>合作使用。C#中有一些协程的库（如Unity里的）就是使用<code>yield</code>机制来实现的。具体怎么使用<code>yield</code>还请去学习C#的语法~</p><h2 id="Python-3">Python<a class="header-anchor" href="#Python-3"> ❮</a></h2><p>Python对异步的支持就来的比较晚了，直到<a href="https://www.python.org/dev/peps/pep-0492/">PEP 492</a>才正式加入了对<code>async</code>关键字的支持，放在了<code>asyncio</code>模块中。Python对这对关键词的实现又很辣鸡了，<a href="https://robertoprevato.github.io/Comparisons-of-async-await/">采用的是Event loop机制来实现</a>（可能是因为多线程性能太差了吧= =）。最让人蛋疼是为了执行异步函数你还需要自己开event loop，如果你之前开过一个了，那你还需要把之前那个loop找回来，然后dispatch进去，这是何其难受！。。</p><p>Python中只要对象有<code>__await__</code>、<code>__aiter__</code>或者<code>__aenter__</code>就可以分别支持<code>await</code>、<code>async for</code>和<code>async with</code>的代码块。Python还设计了三个相关概念：Coroutine代表异步对象、Task代表异步执行计划、Future代表异步执行结果。。何必呢？？？像C#用一个Task代表全部不行吗？再配合event loop的接口，就产生了<code>create_task</code>、<code>run_coroutine_threadsafe</code>、<code>run_until_complete</code>、<code>run_in_executor</code>等我总是搞不清区别的函数。。。我爱C#！</p><hr/>以上是我对C#和Python中异步机制的总结，我对各语言底层的了解并不深，如有错漏还请指点~]]></content>
    
    
    <summary type="html">&lt;p&gt;近来由于项目需要，接触了一下一直没去了解过的Python异步语法，发现和之前我熟悉的C#有很多不同。在深入Python的异步逻辑之后，由于Python在语法上保留了很多语言机制的细节（比如成员函数的&lt;code&gt;self&lt;/code&gt;参数），我反而对C#的异步有了更深的了解。这里就来重新梳理一下各种并行方法的区别，以及他们在C#和Python上实现的区别。（这里只讨论单机的并行机制。）&lt;/p&gt;
&lt;p&gt;总的来说，并行机制主要有进程(Process)、线程(Thread)和协程(Coroutine)，其并行实现的开销依次递减，但是他们对每个任务的鲁棒性也是依次递减的。进程是操作系统资源分配的最小单元，线程则是能够被CPU并行处理的最小单元，而协程则是目前实现“并行”的最简单方法。一个进程中可以有多个线程，而一个线程中可以有多个协程。他们具体在特性上有以下区别&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;进程&lt;/th&gt;
&lt;th&gt;线程&lt;/th&gt;
&lt;th&gt;协程&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;独立内存堆&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;×&lt;/td&gt;
&lt;td&gt;×&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;独立处理器（可硬件并行）&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;×&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;独立上下文&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;×&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;独立栈、寄存器状态&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;td&gt;√&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
    <category term="Python" scheme="http://zyxin.xyz/blog/tags/Python/"/>
    
    <category term="C#" scheme="http://zyxin.xyz/blog/tags/C/"/>
    
    <category term="Parallelism" scheme="http://zyxin.xyz/blog/tags/Parallelism/"/>
    
  </entry>
  
  <entry>
    <title>在Cython中操作数组</title>
    <link href="http://zyxin.xyz/blog/2019-08/CythonArray/"/>
    <id>http://zyxin.xyz/blog/2019-08/CythonArray/</id>
    <published>2019-08-28T21:19:01.000Z</published>
    <updated>2021-07-12T02:40:53.098Z</updated>
    
    <content type="html"><![CDATA[<p>Cython提供了很多方法来搭建C/C++内存和Python对象间的桥梁，但是官方的教程只介绍了一些基础的方法。这篇文章就介绍一下我在各个场合学到和用到的Cython封装（多维）数组的技巧。一般而言这个桥梁会分为两部分，Python与Cython和Cython与C/C++。其中Python中的数组主要形式是<code>list</code>、<code>array.array</code>和<code>numpy.ndarray</code>；Cython中的数组形式有<code>[:,:,:]</code>（<a href="https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html?highlight=pointer#view-cython-arrays">Memoryview</a>/<a href="https://www.python.org/dev/peps/pep-3118/">Buffer</a>）和<code>cython.view.array</code>；C/C++的数组形式有<code>**</code>（指针）、<code>vector</code>和<code>Eigen::Vector/Matrix</code>。</p><blockquote><p>本篇介绍的主要内容也来自于Cython的文档：<a href="http://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html">Typed Memoryviews</a>。</p></blockquote><span id="more"></span><p>在这里也先介绍一下Cython中的这几个概念：</p><ul><li><strong>Memoryview</strong>：这是cython提供的一种语法糖，相当于提供了C中<code>int[][][]</code>形式数组的类型。由于Memoryview可以兼容Python的Buffer协议，因此我把他们放在了一起。Memoryview需要指定元素的类型，这个类型必须是内置数值类型或者<strong>C结构体</strong>。</li><li><strong><code>cython.view.array</code></strong>：这是Cython提供的一个多维数组类型，与<code>numpy.ndarray</code>非常相似了。<br>这两个东西也是可以相互转换的，例如</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cython.view cimport array <span class="keyword">as</span> cvarray</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cython array to Memoryview</span></span><br><span class="line">cyarr = cvarray(shape=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>), itemsize=sizeof(<span class="built_in">int</span>), <span class="built_in">format</span>=<span class="string">&quot;i&quot;</span>)</span><br><span class="line">cdef <span class="built_in">int</span> [:, :, :] cyarr_view = cyarr</span><br><span class="line"></span><br><span class="line"><span class="comment"># Memoryview to Cython array</span></span><br><span class="line">cdef cvarray back = cyarr_view</span><br></pre></td></tr></table></figure><h1 id="Python与Cython数组相互转换">Python与Cython数组相互转换<a class="header-anchor" href="#Python与Cython数组相互转换"> ❮</a></h1><p>Python与Cython之间的转换基本上都由Cython的Memoryview提供了接口，实际上直接赋值就可以。例如官方给出的这段例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cpython cimport array <span class="keyword">as</span> cparray</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Memoryview on a NumPy array</span></span><br><span class="line">narr = np.arange(<span class="number">27</span>, dtype=np.dtype(<span class="string">&quot;i&quot;</span>)).reshape((<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">cdef <span class="built_in">int</span> [:, :, :] narr_view = narr</span><br><span class="line"></span><br><span class="line"><span class="comment"># Memoryview on a CPython array</span></span><br><span class="line">parr = cparray.array(<span class="string">&#x27;i&#x27;</span>, <span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line">cdef <span class="built_in">int</span> [:] parr_view = parr</span><br></pre></td></tr></table></figure><p>顺带一提，<code>list</code>对象由于本身不代表一段连续内存，因此需要先转换为<code>array</code>或<code>ndarray</code>再赋值给Memoryview。反过来由于Numpy支持Buffer协议，因此Memoryview和Cython的<code>cython.view.array</code>都可以直接转换为<code>numpy.ndarray</code>，然后转换为<code>array</code>和<code>list</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cpython cimport array <span class="keyword">as</span> cparray</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">parr = cparray.array(<span class="string">&#x27;i&#x27;</span>, <span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line">cdef <span class="built_in">int</span> [:] parr_view = parr</span><br><span class="line">narr = np.array(parr_view) <span class="comment"># explicit version: np.array(parr_view, copy=False)</span></span><br></pre></td></tr></table></figure><blockquote><p>以上这些代码中的等式都没有发生内存拷贝。</p></blockquote><h1 id="Cython数组与C-C-数组相互转换">Cython数组与C/C++数组相互转换<a class="header-anchor" href="#Cython数组与C-C-数组相互转换"> ❮</a></h1><p>Cython的Memoryview同样承担了大量与C/C++数组进行转换的功能，不过Memoryview只支持一种转换方法，就是与raw指针的相互转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> libc.stdlib cimport malloc</span><br><span class="line">cdef double* data = &lt;double*&gt;malloc(sizeof(double) * <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert pointer to Memoryview</span></span><br><span class="line">cdef double[:] view = &lt;double[:<span class="number">2</span>,:<span class="number">2</span>]&gt;data</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert Memoryview to pointer</span></span><br><span class="line">data = &amp;view[<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure><blockquote><p>以上代码的等式中也没有发生内存拷贝。</p></blockquote><p>这里需要指出的是，由于指针本身只是一段内存的代表，因此在转换时制定类型和长度（如<code>&lt;double[4]&gt;</code>），并且需要保证指针指向的数组是C型连续的（多维数组中最后一维的内存是连续的）。如果要将<code>vector</code>和<code>Eigen::Matrix</code>转换为Memoryview，那么也同样需要获取其内存指针（<code>vector::data</code>和<code>Eigen::Matrix::data</code>）。另外，通过<strong>指针转换出来的Memoryview没有引用计数</strong>，因此如果你的指针是某个Cython类的成员，那么不要使用指针转换，而使用Buffer协议的方式进行传递。</p><h1 id="其他直接转换的方法">其他直接转换的方法<a class="header-anchor" href="#其他直接转换的方法"> ❮</a></h1><p>除了上面提到的方法之外还有一些直接转换的方法，但是这些方法往往不会做类型和尺寸检查，以及很重要的内存连续性检查（Memoryview会区分C型内存和Fortran型内存），因此使用时需要谨慎。</p><ul><li><code>cdef vector[int] data; cdef list view = data</code>：Cython提供了list和vector直接转换的接口</li><li><code>cdef np.ndarray[double] data; cdef double* view = &lt;double*&gt; data.data</code></li><li><code>cdef np.ndarray[double, ndim=2] data; cdef double* view = &amp;data[0,0]</code></li><li><code>cdef array.array data; cdef double* view = data.data.as_doubles[0]</code>：利用了<a href="https://cython.readthedocs.io/en/latest/src/tutorial/array.html#zero-overhead-unsafe-access-to-raw-c-pointer">Cython中的API</a></li></ul><h1 id="非内置类型的转换">非内置类型的转换<a class="header-anchor" href="#非内置类型的转换"> ❮</a></h1><p>在实际应用过程中还会碰到由复杂元素构成的数组（例如PCL里面的PointXYZ、SLAM里会用到的Quaternion），这时就有将复杂类型（通常是自定义struct）在Python和C/C++之间转换的需求。这时可以选择利用Cython提供的MemoryView，也可以利用Python的Buffer协议直接将C++对象传递给Python。</p><p>使用Buffer协议的方法请直接参考<a href="https://cython.readthedocs.io/en/latest/src/userguide/buffer.html">Cython文档</a>，使用Memoryview的例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> libc.stdlib cimport malloc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">cdef struct buf: </span><br><span class="line">    <span class="built_in">int</span> size </span><br><span class="line">    <span class="built_in">int</span> count</span><br><span class="line">cdef buf[:] data = &lt;buf[:<span class="number">2</span>]&gt;malloc(sizeof(buf)*<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.array(data).dtype)</span><br><span class="line"><span class="comment"># [(&#x27;size&#x27;, &#x27;&lt;i4&#x27;), (&#x27;count&#x27;, &#x27;&lt;i4&#x27;)]</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;Cython提供了很多方法来搭建C/C++内存和Python对象间的桥梁，但是官方的教程只介绍了一些基础的方法。这篇文章就介绍一下我在各个场合学到和用到的Cython封装（多维）数组的技巧。一般而言这个桥梁会分为两部分，Python与Cython和Cython与C/C++。其中Python中的数组主要形式是&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;array.array&lt;/code&gt;和&lt;code&gt;numpy.ndarray&lt;/code&gt;；Cython中的数组形式有&lt;code&gt;[:,:,:]&lt;/code&gt;（&lt;a href=&quot;https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html?highlight=pointer#view-cython-arrays&quot;&gt;Memoryview&lt;/a&gt;/&lt;a href=&quot;https://www.python.org/dev/peps/pep-3118/&quot;&gt;Buffer&lt;/a&gt;）和&lt;code&gt;cython.view.array&lt;/code&gt;；C/C++的数组形式有&lt;code&gt;**&lt;/code&gt;（指针）、&lt;code&gt;vector&lt;/code&gt;和&lt;code&gt;Eigen::Vector/Matrix&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本篇介绍的主要内容也来自于Cython的文档：&lt;a href=&quot;http://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html&quot;&gt;Typed Memoryviews&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
    <category term="Cython" scheme="http://zyxin.xyz/blog/tags/Cython/"/>
    
    <category term="Python" scheme="http://zyxin.xyz/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Cython中的特殊函数</title>
    <link href="http://zyxin.xyz/blog/2019-08/CythonFunctions/"/>
    <id>http://zyxin.xyz/blog/2019-08/CythonFunctions/</id>
    <published>2019-08-28T18:23:37.000Z</published>
    <updated>2021-07-12T02:40:53.098Z</updated>
    
    <content type="html"><![CDATA[<p>这次来介绍一下Cython中的特殊函数定义，Cython相比Python本身的特殊函数之外还增加了一些新的函数，用来满足对C特性的支持，其中有些内容还经常令人混淆。关于Python中特殊变量和特殊函数名的内容，<a href="https://docs.python.org/3/reference/datamodel.html">请参考Python官方文档</a>。</p><h1 id="def-cdef和cpdef"><code>def</code>, <code>cdef</code>和<code>cpdef</code><a class="header-anchor" href="#def-cdef和cpdef"> ❮</a></h1><p>首先最开始需要分清的便是Cython中的三种函数类型。<code>def</code>定义的对象（包括变量、函数、类型）都是普通的Python对象，是Python可以直接调用的，因此其参数都只能是Python类型或对象；<code>cdef</code>定义的对象则是C/C++层面的，可以直接用C/C++对象作为参数，因此不能被普通Python代码调用，这样减少了很多overhead因此可以提高运行效率。另外尽管<code>cdef</code>的函数不是Python对象，无法当作变量使用，但还是可以获取函数指针的。而<code>cpdef</code>则是同时兼具两方面特性，其本质是用<code>cdef</code>定义函数后再用<code>def</code>定义一个函数封装，使得在Cython中调用时可以调用高效的<code>cdef</code>版本，而在Python中调用的是与Python兼容的<code>def</code>版本。</p><span id="more"></span><h1 id="init-和-cinit"><code>__init__</code>和<code>__cinit__</code><a class="header-anchor" href="#init-和-cinit"> ❮</a></h1><p>在理清了上面几个关键字后另一个经常令人疑惑的点便是<code>__init__</code>和<code>__cinit__</code>的区别。<code>__cinit__</code>和<code>__dealloc__</code>都是Cython特有的特殊函数。<a href="https://cython.readthedocs.io/en/latest/src/userguide/special_methods.html#initialisation-methods-cinit-and-init">官方文档在其用法上解释</a>的并不清楚，只是说<code>__cinit__</code>可以用来进行C/C++级别的初始化。实际上，使用<code>__cinit__</code>的重要原因是源于其特性：<code>__cinit__</code>会像C++一样自动执行基类的<code>__cinit__</code>，因此它保证会在构造时被执行一次（且只被执行一次）。由于Python中的<code>__init__</code>函数默认不会调用基类的<code>__init__</code>，因此如果想保证类型中的<code>cdef</code>成员被初始化，避免可能的堆栈问题（如指针没有初始化），那么就可以选择使用<code>__cinit__</code>。如果理解了这一点就可以知道，什么时候需要使用<code>__cinit__</code>了。</p><p>但是使用<code>__cinit__</code>的时候有很多限制需要了解：</p><ol><li><code>__cinit__</code>有时会带来额外的开销，<a href="https://kaushikghose.wordpress.com/2015/03/08/cython-__cinit__/">这篇博客中有一些分析</a>。</li><li><code>__cinit__</code>的参数声明和<code>__init__</code>必须一致，因为会同时被调用。因此通常<code>__cinit__</code>的参数中会留下<code>*kargs</code>和<code>**kvargs</code>。<a href="https://stackoverflow.com/a/33091422">Stackoverflow上也有人问过这个情况</a>。</li><li><code>__cinit__</code>中如果要用<code>malloc</code>分配内存，记得在<code>__dealloc__</code>中销毁。<code>__dealloc__</code>相当于C++版本的<code>__del__</code></li><li><code>__cinit__</code>和<code>__init__</code>一样也只能使用<code>def</code>声明，不能用<code>__cdef__</code>和<code>__cpdef__</code>。具体原因我并不清楚。</li></ol><h1 id="运算符重载">运算符重载<a class="header-anchor" href="#运算符重载"> ❮</a></h1><p>其他大多数的特殊函数定义和用法几乎和Python相同，但是需要特别指出的是运算符重载的部分。以加法为例，在Python中加法<code>a + b</code>的实现方式是：</p><ol><li>如果<code>a</code>中定义了<code>__add__</code>，那么调用<code>a.__add__(b)</code></li><li>如果<code>a</code>中没有定义，而<code>b</code>中定义了<code>__radd__</code>，那么调用<code>b.__radd(a)</code></li></ol><p>而在Python的C扩展类里（包含Cython和pybind11的实现），其实现方式是寻找接受<code>a</code>和<code>b</code>类型的<code>__add__</code>重载，也就是说本质上在C扩展类中定义的<code>__add__</code>都是<code>__add__</code>的重载，这也是与C++的<code>operator</code>重载理念一致，只不过这个<code>__add__</code>仍然需要定义在类里。在<a href="https://cython.readthedocs.io/en/latest/src/userguide/special_methods.html#arithmetic-operators">Cython文档中给出的运算符列表</a>里，参数里带<code>self</code>的函数都是按照Python中的方法实现的，<code>self</code>不能指定类型；而以<code>x, y</code>这种形式为参数的则是按照C扩展类执行方式的函数，<code>x</code>和<code>y</code>都可以指定类型。</p><p>另外Cython还定义了一个特殊的运算符函数<code>__richcmp__</code>，这个是Python中没有的，不过其功能只是把比较符号（&gt;,&lt;,=）的实现合并了，与Python的<code>__eq__</code>、<code>__lt__</code>等函数没有本质区别。<a href="https://cython.readthedocs.io/en/latest/src/userguide/special_methods.html#rich-comparison-operators">这在官方文档中也有说明</a></p><h1 id="getbuffer"><code>__getbuffer__</code><a class="header-anchor" href="#getbuffer"> ❮</a></h1><p><a href="https://cython.readthedocs.io/en/latest/src/userguide/special_methods.html#buffer-interface-pep-3118-no-python-equivalents-see-note-1">Cython中有两个版本的Buffer协议</a>，一种是提案PEP-3118定义的，另一种是Python官方定义之前Cython自己的定义方式。其中前者在<a href="/blog/2019-08/CythonInterop/" title="之前介绍Cython封装的文章">之前介绍Cython封装的文章</a>中已有介绍，就不多赘述。其相关的特殊函数是<code>__getbuffer__</code>和<code>__releasebuffer__</code>，这两个函数也都是Cython特有的。而后者比较难用，已经被标记为depricated废弃了，也不介绍了。</p><h1 id="属性（property）">属性（property）<a class="header-anchor" href="#属性（property）"> ❮</a></h1><p>Cython中还提供了一套非常方便的属性定义方法。原本在Python中定义属性非常但疼，例如下面的代码定义了名为<code>length</code>的属性，使得你可以通过<code>square.length</code>的方法访问它</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Square</span>:</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">length</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._length</span><br><span class="line"><span class="meta">    @length.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">length</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self._length = value</span><br><span class="line"><span class="meta">    @length.deleter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">length</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._length = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>而在Cython中定义属性就更简单了，它除了支持上面的方法外还有另一种更加直观的定义方式（虽然这个方式也已经被标记为depricated了）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cdef <span class="class"><span class="keyword">class</span> <span class="title">Square</span>:</span></span><br><span class="line">    <span class="built_in">property</span> length:</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__get__</span>(<span class="params">self</span>):</span></span><br><span class="line">            <span class="keyword">return</span> self._length</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__set__</span>(<span class="params">self, value</span>):</span></span><br><span class="line">            self._length = value</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">            self._length = <span class="number">0</span></span><br></pre></td></tr></table></figure><hr/><p>Cython的类型还有各种其他的奇奇怪怪的小特性，在Cython的这两篇文档里有详细介绍：<a href="https://cython.readthedocs.io/en/latest/src/userguide/extension_types.html">Extension Types</a>, <a href="https://cython.readthedocs.io/en/latest/src/userguide/special_methods.html#buffer-interface-pep-3118-no-python-equivalents-see-note-1">Special Methods of Extension Types</a>，仅供参考～</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这次来介绍一下Cython中的特殊函数定义，Cython相比Python本身的特殊函数之外还增加了一些新的函数，用来满足对C特性的支持，其中有些内容还经常令人混淆。关于Python中特殊变量和特殊函数名的内容，&lt;a href=&quot;https://docs.python.org/3/reference/datamodel.html&quot;&gt;请参考Python官方文档&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id=&quot;def-cdef和cpdef&quot;&gt;&lt;code&gt;def&lt;/code&gt;, &lt;code&gt;cdef&lt;/code&gt;和&lt;code&gt;cpdef&lt;/code&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#def-cdef和cpdef&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;首先最开始需要分清的便是Cython中的三种函数类型。&lt;code&gt;def&lt;/code&gt;定义的对象（包括变量、函数、类型）都是普通的Python对象，是Python可以直接调用的，因此其参数都只能是Python类型或对象；&lt;code&gt;cdef&lt;/code&gt;定义的对象则是C/C++层面的，可以直接用C/C++对象作为参数，因此不能被普通Python代码调用，这样减少了很多overhead因此可以提高运行效率。另外尽管&lt;code&gt;cdef&lt;/code&gt;的函数不是Python对象，无法当作变量使用，但还是可以获取函数指针的。而&lt;code&gt;cpdef&lt;/code&gt;则是同时兼具两方面特性，其本质是用&lt;code&gt;cdef&lt;/code&gt;定义函数后再用&lt;code&gt;def&lt;/code&gt;定义一个函数封装，使得在Cython中调用时可以调用高效的&lt;code&gt;cdef&lt;/code&gt;版本，而在Python中调用的是与Python兼容的&lt;code&gt;def&lt;/code&gt;版本。&lt;/p&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
    <category term="Cython" scheme="http://zyxin.xyz/blog/tags/Cython/"/>
    
    <category term="Python" scheme="http://zyxin.xyz/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Cython与C/C++的交互</title>
    <link href="http://zyxin.xyz/blog/2019-08/CythonInterop/"/>
    <id>http://zyxin.xyz/blog/2019-08/CythonInterop/</id>
    <published>2019-08-28T03:47:47.000Z</published>
    <updated>2021-07-12T02:40:53.098Z</updated>
    
    <content type="html"><![CDATA[<p>用Cython也用了很有一段时间了，这次就介绍一下它的最重要功能——使用Cython来封装C/C++代码。最基本的封装方法可以参见Cython文档中的相关页面：<a href="https://cython.readthedocs.io/en/latest/src/userguide/external_C_code.html">Interfacing with External C Code</a>和<a href="https://cython.readthedocs.io/en/latest/src/userguide/wrapping_CPlusPlus.html">Using C++ in Cython</a>，本文介绍主要是比较重要和常用的Cython/C++交互特性，而自定义Python拓展类（而不是封装现有C++）的一些操作可以<a href="https://cython.readthedocs.io/en/latest/src/tutorial/cdef_classes.html">参考官方教程</a>。</p><p>封装C++代码时，最重要的关键词就是<code>extern</code>，在定义函数时使用这个关键字就说明该声明是外部的，而使用<code>cdef extern from</code>语句就能指定声明对应的头文件。例如如果要封装函数<code>func</code>，对应的Cython语句是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;func.c&quot;</span>:</span><br><span class="line">    void func(<span class="built_in">int</span> arg)</span><br></pre></td></tr></table></figure><span id="more"></span><h1 id="文件结构">文件结构<a class="header-anchor" href="#文件结构"> ❮</a></h1><p>首先讲一下Cython的文件结构。如果你之有一个小模块需要封装的话你可以把所有代码写到同一个<code>pyx</code>里进行编译，否则的话你就可以利用Cython的目录结构来管理多个层次的代码。Cython的文件一共有三种：<code>pyx</code>，<a href="https://cython.readthedocs.io/en/latest/src/userguide/language_basics.html#the-include-statement-and-include-files"><code>pxi</code></a>（<a href="https://stackoverflow.com/a/45440199">注意与<code>pyi</code>区分</a>）和<code>pxd</code>（<a href="https://stackabuse.com/differences-between-pyc-pyd-and-pyo-python-files/">注意与<code>pyd</code>区分</a>）。</p><p><code>.pyx</code>是Cython的源文件，类似于<code>.cpp</code>文件在C++中的地位，而对应<code>.h</code>头文件地位的则是<code>pyi</code>。在Cython中添加<code>import 'header.pyi'</code>的语句就会将<code>header.pyi</code>文件中的内容原封不动地直接插入当前位置，这与C++的<code>#include</code>语句的作用是相同的。而<code>pxd</code>则是另一套符号化的逻辑，<code>.pxd</code>文件中只能声明函数、声明类型、不能有函数和类型的定义内容（除了<code>inline</code>函数外），而在<code>cimport</code>了<code>pxd</code>的定义之后当前代码便引入了对应的函数或者类型签名。这个工作方式则更符合C++中头文件的实际用途。定义了<code>pxd</code>后就可以在多个Cython文件之间共享同一个类型了。</p><p>不过既然涉及了<code>include</code>语法，就必然要指定类似于C++的引用路径了。<code>pxi</code>和<code>pxd</code>文件的引用路径可以<a href="https://cython.readthedocs.io/en/latest/src/userguide/sharing_declarations.html#search-paths-for-definition-files">在cythonize过程中手动指定</a>，而<code>pxd</code>由于是符号化的还可以通过新建<code>__init__.pxd</code>的方式来实现类似于Python的引用方法。只要在Cython搜索目录下的文件夹中包含<code>__init__.pxd</code>文件，Cython就会认为这是一个Cython库，之后就可以用<code>cimport</code>语句通过与Python中<code>import</code>相类似的语法将对应模块文件（<code>.pxd</code>文件）引用进来。当然，<code>pxd</code>文件<a href="https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html#compiling-with-the-cythonize-command">也可以通过命令参数直接导入</a>。关于如何组织这些文件以及头文件之间的关系，读者可以参考<a href="https://github.com/cmpute/pcl.py">我写的PCL封装库</a>和<a href="https://cython.readthedocs.io/en/latest/src/userguide/sharing_declarations.html">Cython的相关文档</a>。</p><blockquote><p>函数在pxd中的定义不能显式指定默认参数，而是必须用<code>*</code>代替，例如<code>cdef void func(a=0)</code>在<code>pxd</code>中声明的话需要改为<code>cdef void func(a=*)</code>。</p></blockquote><h1 id="类型封装">类型封装<a class="header-anchor" href="#类型封装"> ❮</a></h1><p>Cython对C++的类型提供了基本可用的封装语法。为什么说基本可用，是因为Cython目前对模板的支持还非常有限，因此实际上可以说Cython只支持到C++98的程度。不过尽管如此，Cython已经能够完成大多数代码的封装需求了。Cython对<code>class</code>的支持通过<code>cdef cppclass &lt;class-name&gt;</code>来实现，这里<code>cppclass</code>关键词是为了和Cython的<code>class</code>关键词进行区分。Cython中<code>class</code>关键词代表的是和Python一致的<code>PyObject</code>对象，代表的是Python类型，而<code>cppclass</code>则指代C++原生类型，由于Cython文件中无法直接编写C++代码，因此<code>cdef cppclass</code>语句通常在<code>cdef extern from</code>的语法块中，用来封装现有的C++类型。另外一点需要注意的地方是Cython<a href="https://cython.readthedocs.io/en/latest/src/userguide/language_basics.html#c-variable-and-type-definitions">提供封装<code>enum</code>和<code>struct</code>的语法</a>，但是针对的是C中的<code>enum</code>和<code>struct</code>，而非C++中的<code>enum class</code>和<code>struct</code>（C++中<code>struct</code>和<code>class</code>几乎没有区别）。如果要封装C++版本的<code>enum</code>和<code>struct</code>可以直接使用<code>cppclass</code>关键词。以下是封装C++类型的一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;test.h&quot;</span>:</span><br><span class="line">    cdef cppclass Test:</span><br><span class="line">        void <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><h2 id="别名与-namespace-关键字">别名与 namespace 关键字<a class="header-anchor" href="#别名与-namespace-关键字"> ❮</a></h2><p>由于Cython最后生成的是全局的C代码，因此在引用C++类时需要明确声明类型含命名空间的全称，这里就需要用到别名的机制。Cython允许从<code>.h</code>文件中导入声明的时候给类型和方法改名字，具体用法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;&lt;header-name&gt;&quot;</span>:</span><br><span class="line">    cdef void &lt;new-function-name&gt; <span class="string">&quot;&lt;origin-function-name&gt;&quot;</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    cdef cppclass &lt;new-<span class="class"><span class="keyword">class</span>-<span class="title">name</span>&gt; &quot;&lt;<span class="title">origin</span>-<span class="title">class</span>-<span class="title">name</span>&gt;&quot;:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>简而言之就是在方法或者类型名称后添加引号，引号里写上原本C++中的名字。这个机制有很多tricky的用法，它可以用来声明带命名空间的方法和类型、可以用来<a href="https://stackoverflow.com/a/25955546">重命名C++中的运算符</a>、可以用来直接声明实例化的模板类型、甚至可以用来把C++常量声明成类型用于模板参数（这种操作可以<a href="https://github.com/wouterboomsma/eigency/blob/master/eigency/core.pxd">参考eigency库中的代码</a>）。</p><p>其中针对第一种用法，为了简化带有命名空间对象的声明，Cython加入了<code>namespace</code>关键字。在<code>cdef</code>语句中添加<code>namespace</code>从句可以使得Cython编译器默认给其包含的语句块中所有的类型加上对应的命名空间，例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;test.h&quot;</span> namespace <span class="string">&quot;ns&quot;</span>:</span><br><span class="line">    cdef cppclass Test:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>与以下代码是等价的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;test.h&quot;</span>:</span><br><span class="line">    cdef cppclass Test <span class="string">&quot;ns::Test&quot;</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h2 id="模板支持">模板支持<a class="header-anchor" href="#模板支持"> ❮</a></h2><p>这个特性在<a href="/blog/2018-12/CythonTypes/" title="之前介绍Cython类型的文章中">之前介绍Cython类型的文章中</a>也有提到过，这里补充一下它的一些特性。Cython对C++模板的支持通过<code>[]</code>符号实现，以下是Cython中对<code>vector</code>的封装代码可供参考</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cdef extern <span class="keyword">from</span> <span class="string">&quot;&lt;vector&gt;&quot;</span> namespace <span class="string">&quot;std&quot;</span> nogil:</span><br><span class="line">    cdef cppclass vector[T,ALLOCATOR=*]:</span><br><span class="line">        ctypedef T value_type</span><br><span class="line">        ctypedef ALLOCATOR allocator_type</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>其中<code>vector[T,ALLOCATOR=*]</code>对应的就是C++中的<code>vector&lt;T, ALLOCATOR&gt;</code>符号。模板参数在Cython中同样可以有复数个，也可以有默认值，<a href="https://gist.github.com/bjodah/3cc42d9c5f70a321af29">似乎现在也支持常数作为模板参数</a>，不过我没有尝试过，而据说老版本是不支持常数模板参数的。</p><p>之前有提到Cython中对模板的支持是阉割过的，主要特征有以下几点：</p><ul><li>Cython不支持模板参数的类型声明访问。例如上面的<code>vector</code>类型声明中不能使用<code>ctypedef allocator_type.size_type size_type</code>这样的语法，而这样的类型推断在C++中是有很多的。</li><li>Cython不支持模板构造函数中包含新的模板参数<br>不过Cython一直在改进对模板的支持，因此以后也很有可能会得到改进。</li></ul><h1 id="Buffer协议">Buffer协议<a class="header-anchor" href="#Buffer协议"> ❮</a></h1><p>Cython还针对性地支持了<a href="https://docs.python.org/3/c-api/buffer.html">Python的Buffer协议</a>，用来传递一块结构化的内存，这个协议的标准被记录在了<a href="https://www.python.org/dev/peps/pep-3118/">提案PEP-3118</a>中。这个协议通过<a href="https://cython.readthedocs.io/en/latest/src/userguide/buffer.html"><code>__getbuffer__</code>和<code>__releasebuffer__</code></a>两个Cython自定义的特殊函数实现，通过这个方式Cython代码就可以将C++内存转化为Python识别的内存。因为Numpy支持将支持Buffer协议的对象转换为ndarray，因此这个Buffer协议的通常用法是将一个C++对象变成Numpy的矩阵。具体的使用案例也可以<a href="https://github.com/cmpute/pcl.py/blob/master/pcl/PointCloud.pyx#L565">参照我的pcl封装库中的对应代码</a>。</p><hr/>本文介绍了Cython中操作C/C++对象的方法，不过仅仅介绍了一些进阶用法。如果是新手的话还是先参照之前提到两篇文档学习基本的函数、类型封装方法吧～]]></content>
    
    
    <summary type="html">&lt;p&gt;用Cython也用了很有一段时间了，这次就介绍一下它的最重要功能——使用Cython来封装C/C++代码。最基本的封装方法可以参见Cython文档中的相关页面：&lt;a href=&quot;https://cython.readthedocs.io/en/latest/src/userguide/external_C_code.html&quot;&gt;Interfacing with External C Code&lt;/a&gt;和&lt;a href=&quot;https://cython.readthedocs.io/en/latest/src/userguide/wrapping_CPlusPlus.html&quot;&gt;Using C++ in Cython&lt;/a&gt;，本文介绍主要是比较重要和常用的Cython/C++交互特性，而自定义Python拓展类（而不是封装现有C++）的一些操作可以&lt;a href=&quot;https://cython.readthedocs.io/en/latest/src/tutorial/cdef_classes.html&quot;&gt;参考官方教程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;封装C++代码时，最重要的关键词就是&lt;code&gt;extern&lt;/code&gt;，在定义函数时使用这个关键字就说明该声明是外部的，而使用&lt;code&gt;cdef extern from&lt;/code&gt;语句就能指定声明对应的头文件。例如如果要封装函数&lt;code&gt;func&lt;/code&gt;，对应的Cython语句是&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cdef extern &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&amp;quot;func.c&amp;quot;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    void func(&lt;span class=&quot;built_in&quot;&gt;int&lt;/span&gt; arg)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
    <category term="Cython" scheme="http://zyxin.xyz/blog/tags/Cython/"/>
    
    <category term="Python" scheme="http://zyxin.xyz/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>如何选择Python与C++之间的胶水</title>
    <link href="http://zyxin.xyz/blog/2019-08/GluePythonCpp/"/>
    <id>http://zyxin.xyz/blog/2019-08/GluePythonCpp/</id>
    <published>2019-08-11T21:05:40.000Z</published>
    <updated>2021-07-12T02:40:53.098Z</updated>
    
    <content type="html"><![CDATA[<p>Python作为一门胶水语言，它与C/C++之间的兼容性（Interoperability）我认为是它相比其他动态语言脱颖而出的最大原因。Python原生支持的是与C语言的接口，Python的发行版自带有<code>Python.h</code>头文件，里面提供了在C中调用Python和反过来在Python中调用C的接口定义。但是C++就不一样了，虽然C++ ⇔ C ⇔ Python的通道是可行的，但是想要完整兼容C++的特性的话需要很多额外的重复代码（boilerplate）。因此相应针对Python/C++绑定的库也就应运而生了，我所了解的库主要有四个：<a href="https://www.boost.org/doc/libs/1_70_0/libs/python/doc/html/index.html">Boost.Python</a>，<a href="https://cython.org/">Cython</a>，<a href="https://pybind11.readthedocs.io/en/stable/">pybind11</a>，<a href="http://www.swig.org/">SWIG</a>。虽然网上也有不少比较三者的页面，但是我觉得都不够详细，这篇博客就介绍一下我基于使用这几个库的经验比较。</p><p>上面说到的这些库我基本都有接触过，其中用过的有pybind11和Cython，分别用在了我正在写的<a href="https://github.com/cmpute/cgal.py">CGAL</a>和<a href="https://github.com/cmpute/pcl.py">PCL</a>的绑定上。另外二者则是在其他库的代码中有读过（如Caffe和CGAL的官方绑定）。总的来说，Boost.Python和pybind11主要用于给现有C++代码提供Python绑定，并且不用学习新的语法;SWIG提供一个给C++代码编写多种语言绑定的框架，它本质上是一种代码生成器，基于SWIG自定义的语法;Cython则是基于Python的C/C++代码封装器，其本质也是代码生成器，但是Cython的语法是Python的超集，也就是说Python的代码可以零成本移植到Cython中。</p><span id="more"></span><h1 id="Boost-Python-vs-pybind11">Boost.Python vs pybind11<a class="header-anchor" href="#Boost-Python-vs-pybind11"> ❮</a></h1><p>Boost.Python是一个Boost框架中封装C++代码的工具，通过宏定义和元编程来简化Python的API调用，消灭bolierplate。Boost.Python还提供对Numpy底层API的封装，因此适用性很强，能满足Python绑定的绝大多数需求。而pybind11则是受Boost.Python启发的一套类似的API，其目标是提供Header-only的易用的Python接口。由于pybind11脱胎于Boost，因此它们的接口非常相似，例如最简单的封装一个函数，Boost.Python代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;boost/python.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">BOOST_PYTHON_MODULE</span>(example)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> boost::python;</span><br><span class="line">    <span class="built_in">def</span>(<span class="string">&quot;add&quot;</span>, add);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而对应的pybind11代码则是</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(example, m) &#123;</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;add&quot;</span>, &amp;add);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此熟练掌握这两者之一的开发者能很快上手另一个库的使用。他们的编译方式也是相似的，只需添加一个工程，写好对应的封装代码，然后利用他们的CMake模块进行编译，生成的动态链接库只要文件名正确就可以直接从Python进行import了。他们二者的区别主要有以下几个方面：</p><ol><li>pybind11是Header-only的，因此只需把它的头文件添加到include目录就算安装好了。而Boost.Python则是需要先编译安装才能使用，需要处理其依赖。</li><li>pybind11的社区更加活跃，Boost.Python则受限于Boost的更新周期，回应反馈可能会比较慢。</li><li>pybind11的易用性更好，文档齐全且友善，由于没有依赖问题，编译方便上手也快。</li><li>Boost.Python兼容旧特性的C++，也兼容Boost自定义的类型（如smartptr），因此如果需要封装的代码是基于Boost的，那可能Boost.Python会比pybind11合适。pybind11针对的环境则是C++1x，并且只支持标准C++库。</li><li>Boost.Python对Numpy的支持比较完备，例如Boost.Python支持自定义<code>numpy.dtype</code>，而pybind11对Numpy的支持主要基于Python的buffer协议。<br>因此基本上如果封装不基于Boost的库的话可以先考虑pybind11，而如果是封装基于Boost的库（如PCL），或者深度操作Numpy，那还是直接上Boost.Python吧～</li></ol><h1 id="Boost-Python-pybind11-vs-Cython">Boost.Python/pybind11 vs Cython<a class="header-anchor" href="#Boost-Python-pybind11-vs-Cython"> ❮</a></h1><p>这两者的选用其实差别非常大，因为他们的代码逻辑都是不同的。而具体选择哪个库就纯粹是根据需求出发了。他们的区别如下（以下pybind11同时也代表了Boost.Python）</p><ol><li>pybind11基于C++，更适合C++工程师。Cython则是基于Python，写习惯的Python的人上手更快，并且能同时方便地兼容Python和C++。</li><li>Cython相比pybind11的环境配置更加简单，用户只需通过pip安装Cython就可以利用Cython的功能了，也无需配置路径。</li><li>Cython封装C++类会比Boost.Python更加繁杂，你需要先定义C++类，再封装成Python类。相当于Cython还多一步翻译头文件的工作。</li><li>Cython支持模板（虽然是阉割版本）！这是Cython独家的一个killer特性，不过是与第3点相关联的。如果你已经翻译好了现有的模板代码，那么用户就可以用Python的语法来自行展开模板了！pybind11需要在编译的时候实例化模板，因此一般只封装常用的实例，或者穷举所有实例化可能（这会导致生成的封装库尺寸爆炸）</li><li>pybind11封装重载函数比Cython要方便太多！Cython封装重载函数的话一般需要定义大量的可选参数和类型判断。</li><li>Cython封装继承类就更加麻烦了，不仅要处理方法重载，还要复制继承关系，十分繁复。</li><li>Cython无法利用上C++的宏定义，这对支持条件编译非常不利，很多时候还需要自己利用<a href="https://cython.readthedocs.io/en/latest/src/userguide/language_basics.html#conditional-statements">Cython的条件语句</a>翻译一套条件编译的逻辑。</li></ol><p>以前很多人使用Cython的原因是Cython可以很方便地加速Python代码，但是<code>numba.jit</code>的出现则让这个功能实际上成了鸡肋，因此Cython最近的使用率也是越来越低了。如果没有很强的对保留模板灵活性的需求，或者不是封装目标不是基于C语言的，那还是选择pybind11来的方便。如果封装接口只是一小部分需求的话也还是用Cython会更加一致，我在自己的PCL绑定项目中使用Cython的原因是有大量基于Python的扩展代码，因此使用Cython还是能更方便。</p><h1 id="SWIG">SWIG<a class="header-anchor" href="#SWIG"> ❮</a></h1><p>SWIG是个很神奇的东西，他能够将C++代码封装成Python/C#/Java/Ruby等多种语言，但是也正因为这个灵活性，它对C++的高级特性的支持就比较辣鸡了。在<a href="https://github.com/sciencectn/cgal-bindings">CGAL官方的绑定库</a>中可以看到有不少代码需要针对Python和Java打补丁，因此如果没有多语言的需求的话SWIG应该是下下策了。这应该也是SWIG一直没啥发展的原因吧～</p><hr/>本文介绍了Boost.Python/pybin11/Cython/SWIG之间的特性与区别，而具体用法则是一笔带过。如果大家对其中的某工具感兴趣的话可以直接去官网看教程～]]></content>
    
    
    <summary type="html">&lt;p&gt;Python作为一门胶水语言，它与C/C++之间的兼容性（Interoperability）我认为是它相比其他动态语言脱颖而出的最大原因。Python原生支持的是与C语言的接口，Python的发行版自带有&lt;code&gt;Python.h&lt;/code&gt;头文件，里面提供了在C中调用Python和反过来在Python中调用C的接口定义。但是C++就不一样了，虽然C++ ⇔ C ⇔ Python的通道是可行的，但是想要完整兼容C++的特性的话需要很多额外的重复代码（boilerplate）。因此相应针对Python/C++绑定的库也就应运而生了，我所了解的库主要有四个：&lt;a href=&quot;https://www.boost.org/doc/libs/1_70_0/libs/python/doc/html/index.html&quot;&gt;Boost.Python&lt;/a&gt;，&lt;a href=&quot;https://cython.org/&quot;&gt;Cython&lt;/a&gt;，&lt;a href=&quot;https://pybind11.readthedocs.io/en/stable/&quot;&gt;pybind11&lt;/a&gt;，&lt;a href=&quot;http://www.swig.org/&quot;&gt;SWIG&lt;/a&gt;。虽然网上也有不少比较三者的页面，但是我觉得都不够详细，这篇博客就介绍一下我基于使用这几个库的经验比较。&lt;/p&gt;
&lt;p&gt;上面说到的这些库我基本都有接触过，其中用过的有pybind11和Cython，分别用在了我正在写的&lt;a href=&quot;https://github.com/cmpute/cgal.py&quot;&gt;CGAL&lt;/a&gt;和&lt;a href=&quot;https://github.com/cmpute/pcl.py&quot;&gt;PCL&lt;/a&gt;的绑定上。另外二者则是在其他库的代码中有读过（如Caffe和CGAL的官方绑定）。总的来说，Boost.Python和pybind11主要用于给现有C++代码提供Python绑定，并且不用学习新的语法;SWIG提供一个给C++代码编写多种语言绑定的框架，它本质上是一种代码生成器，基于SWIG自定义的语法;Cython则是基于Python的C/C++代码封装器，其本质也是代码生成器，但是Cython的语法是Python的超集，也就是说Python的代码可以零成本移植到Cython中。&lt;/p&gt;</summary>
    
    
    
    <category term="Coding" scheme="http://zyxin.xyz/blog/categories/Coding/"/>
    
    <category term="Language" scheme="http://zyxin.xyz/blog/categories/Coding/Language/"/>
    
    
    <category term="Python" scheme="http://zyxin.xyz/blog/tags/Python/"/>
    
    <category term="C++" scheme="http://zyxin.xyz/blog/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>ROS参数设置方法总结</title>
    <link href="http://zyxin.xyz/blog/2019-08/ROSParameter/"/>
    <id>http://zyxin.xyz/blog/2019-08/ROSParameter/</id>
    <published>2019-08-02T15:54:25.000Z</published>
    <updated>2021-07-12T02:40:53.188Z</updated>
    
    <content type="html"><![CDATA[<p>最近在研究ROS节点（ROS Node）的参数设置方式，由于系统比较复杂，并且会变得更加复杂，因此需要一个统一的参数设置方式。这里就比较一下四种参数获取方案的区别～</p><h1 id="命令行-文件输入">命令行/文件输入<a class="header-anchor" href="#命令行-文件输入"> ❮</a></h1><p>由于ROS节点本身也只是普通的可执行程序，因此它可以正常地从启动参数中读取参数，另外也可以从配置文件中读取参数。这两种方法都是常规程序读取参数的方法。从命令行中读取参数有C++的<code>Boost.Program_options</code>库和Python的<code>argparse</code>的库，用来解析命令行参数输入，支持可选参数、重复参数、参数分组等等。而从文件输入的话，常见的设置格式有<code>json</code>，<code>yaml</code>，<code>toml</code>甚至<code>ini</code>等等。从这些文件中读取比较灵活，但是无法利用ROS框架，并且需要自行统一格式。</p><h1 id="参数服务器">参数服务器<a class="header-anchor" href="#参数服务器"> ❮</a></h1><p>ROS中很有名的支持参数设置的结构是参数服务器，参数服务器是一个包含在master结点里的集中式字典结构，在ROS的Wiki上有介绍：<a href="http://wiki.ros.org/Parameter%20Server/cn">中文</a>|<a href="http://wiki.ros.org/Parameter%20Server">英文</a>。参数服务器也可以从文件中读取参数，文件格式是<code>yaml</code>，读取的方式是在<code>.launch</code>文件中添加<code>&lt;rosparam&gt;</code>标签，并指定键值或者文件路径。</p><span id="more"></span><h2 id="rosparam">rosparam<a class="header-anchor" href="#rosparam"> ❮</a></h2><p><code>rosparam</code>是操作参数服务器的一套工具，你可以从程序中调用<code>rosparam</code>的API，或者使用命令行工具对指定参数进行动态更改。命令行的用法参见<a href="http://wiki.ros.org/rosparam#rosparam_command-line_tool">ROS Wiki</a></p><h2 id="rosrun">rosrun<a class="header-anchor" href="#rosrun"> ❮</a></h2><p><code>rosrun</code>和<code>roslaunch</code>都是运行ROS模块的工具，其中<code>rosrun</code>只能运行单个节点，而<code>roslaunch</code>则支持更加复杂的启动体系。用<code>rosrun</code>进行参数服务器的设置的方式是在启动参数中添加<code>key:=value</code>。</p><h2 id="roslaunch">roslaunch<a class="header-anchor" href="#roslaunch"> ❮</a></h2><p>用<code>roslaunch</code>进行参数服务器的设置的方式是在文件中添加<code>&lt;param&gt;</code>标签。<param><code>和</code><rosparam><code>实质上功能相似，前者设置的是单个参数，而后者针对的是一套参数。另外</code>roslaunch<code>还支持从命令行读取参数，格式也是</code>key:=value<code>，读取进来后存入的是</code><arg><code>标签，而如果要使用这类参数的话需要使用</code>roslaunch<code>的</code>$(arg key)<code>语法。具体的</code>roslaunch`语法<a href="http://wiki.ros.org/roslaunch/XML">参见ROS Wiki</a>。</p><h1 id="dynamic-reconfigure">dynamic_reconfigure<a class="header-anchor" href="#dynamic-reconfigure"> ❮</a></h1><p>ROS中还提供了另一种机制叫<a href="http://wiki.ros.org/dynamic_reconfigure"><code>dynamic_reconfigure</code></a>也可以用来动态设置参数。它与参数服务器的区别在于它的参数更新是基于回调机制，而参数服务器实际上是轮询机制。ROS程序会主动询问参数服务器以获取参数，而<code>dynamic_reconfigure</code>则是动态地告知ROS程序参数更新事件。<code>dynamic_reconfigure</code>的使用方法是定义<code>.cfg</code>文件，并在其中通过Python程序定义可动态设置的参数。<code>cfg</code>文件在CMakeLists.txt中需要注册，注册语法及顺序参见<a href="http://wiki.ros.org/catkin/CMakeLists.txt#Example">CMakeLists.txt的Wiki</a>和<a href="http://wiki.ros.org/dynamic_reconfigure/Tutorials/HowToWriteYourFirstCfgFile"><code>.cfg</code>文件的Wiki</a>。个人感觉实际上<code>dynamic_reconfigure</code>实现的效果和自己定义ROS服务来更新参数是相似的。</p><blockquote><p>最后总结下来的话ROS参数服务器还是最常用的，但是参数服务器的名称同样也有命名空间的限制，也分私有参数和公有参数等等。。这两个的区别我其实现在还没有搞清楚= =</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在研究ROS节点（ROS Node）的参数设置方式，由于系统比较复杂，并且会变得更加复杂，因此需要一个统一的参数设置方式。这里就比较一下四种参数获取方案的区别～&lt;/p&gt;
&lt;h1 id=&quot;命令行-文件输入&quot;&gt;命令行/文件输入&lt;a class=&quot;header-anchor&quot; href=&quot;#命令行-文件输入&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;由于ROS节点本身也只是普通的可执行程序，因此它可以正常地从启动参数中读取参数，另外也可以从配置文件中读取参数。这两种方法都是常规程序读取参数的方法。从命令行中读取参数有C++的&lt;code&gt;Boost.Program_options&lt;/code&gt;库和Python的&lt;code&gt;argparse&lt;/code&gt;的库，用来解析命令行参数输入，支持可选参数、重复参数、参数分组等等。而从文件输入的话，常见的设置格式有&lt;code&gt;json&lt;/code&gt;，&lt;code&gt;yaml&lt;/code&gt;，&lt;code&gt;toml&lt;/code&gt;甚至&lt;code&gt;ini&lt;/code&gt;等等。从这些文件中读取比较灵活，但是无法利用ROS框架，并且需要自行统一格式。&lt;/p&gt;
&lt;h1 id=&quot;参数服务器&quot;&gt;参数服务器&lt;a class=&quot;header-anchor&quot; href=&quot;#参数服务器&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;ROS中很有名的支持参数设置的结构是参数服务器，参数服务器是一个包含在master结点里的集中式字典结构，在ROS的Wiki上有介绍：&lt;a href=&quot;http://wiki.ros.org/Parameter%20Server/cn&quot;&gt;中文&lt;/a&gt;|&lt;a href=&quot;http://wiki.ros.org/Parameter%20Server&quot;&gt;英文&lt;/a&gt;。参数服务器也可以从文件中读取参数，文件格式是&lt;code&gt;yaml&lt;/code&gt;，读取的方式是在&lt;code&gt;.launch&lt;/code&gt;文件中添加&lt;code&gt;&amp;lt;rosparam&amp;gt;&lt;/code&gt;标签，并指定键值或者文件路径。&lt;/p&gt;</summary>
    
    
    
    <category term="System" scheme="http://zyxin.xyz/blog/categories/System/"/>
    
    <category term="ROS" scheme="http://zyxin.xyz/blog/categories/System/ROS/"/>
    
    
    <category term="Ubuntu" scheme="http://zyxin.xyz/blog/tags/Ubuntu/"/>
    
    <category term="ROS" scheme="http://zyxin.xyz/blog/tags/ROS/"/>
    
    <category term="Robotics" scheme="http://zyxin.xyz/blog/tags/Robotics/"/>
    
    <category term="Autonomy" scheme="http://zyxin.xyz/blog/tags/Autonomy/"/>
    
  </entry>
  
  <entry>
    <title>折腾 KDE Neon 的配置</title>
    <link href="http://zyxin.xyz/blog/2019-07/ConfigureKdeNeon/"/>
    <id>http://zyxin.xyz/blog/2019-07/ConfigureKdeNeon/</id>
    <published>2019-08-01T03:13:47.000Z</published>
    <updated>2021-07-12T02:40:53.088Z</updated>
    
    <content type="html"><![CDATA[<p>最近我已经将KDE Neon作为主力系统之一了，Plasma桌面真的是太好用了！于是给家里的主机也装上了Neon，这篇文章就记录一下安装配置和美化的过程啦～</p><img src="/blog/2019-07/ConfigureKdeNeon/neon.png" class="" title="Plasma桌面折腾结果～"><h1 id="系统安装及Boot设置">系统安装及Boot设置<a class="header-anchor" href="#系统安装及Boot设置"> ❮</a></h1><h2 id="双系统安装">双系统安装<a class="header-anchor" href="#双系统安装"> ❮</a></h2><p>安装Neon还是非常简单的，直接从官网下载系统镜像，烧进U盘正常安装即可。不过由于我选择的是与Windows双系统安装，因此需要手动分区。这里要纠正一下之前<a href="/blog/2018-09/LinuxDualSystem/" title="安装双系统博文中的分区方式">安装双系统博文中的分区方式</a>。现在的Linux系统实际上只需要给根目录<code>/</code>分区就可以了，<code>/home</code>分区以前建议单独分区的原因是为了便于系统的更改，这样在修改系统分区之后（如重装系统）还能保留<code>/home</code>底下的文件，但其实现在很多系统已经能做到重装并保留<code>/home</code>分区了，这时对于我这小硬盘的笔记本来说反而导致空间利用不灵活。而交换分区<code>/swap</code>也是没有必要的，交换分区的存在类似于Windows下的虚拟内存，用硬盘的一部分来虚拟内存，避免内存不足的情况。新Linux可以利用交换文件完成类似功能，因此不必专门给<code>/swap</code>分区。（不过我猜专门给它分个区可能能提高性能？）。最后最关键的是不要给<code>/boot</code>分区了,<code>/boot</code>分区是为了保证boot文件区不被占满，以致无法正常启动。利用EFI方式启动的系统只需要有<code>efi</code>分区即可，而且多个系统可以利用同一个EFI分区。因此只需告诉安装器使用EFI分区作为启动分区，关于EFI的详细信息请看后文~</p><blockquote><p>分区的时候还看到了之前的系统里有标记为<code>msr</code>的分区，是Windows的预留分区，好像具体没啥用。这里贴<a href="http://bbs.wuyou.net/forum.php?mod=viewthread&amp;tid=374959">一篇考据文章</a>。</p></blockquote><span id="more"></span><h2 id="rEFind设置">rEFind设置<a class="header-anchor" href="#rEFind设置"> ❮</a></h2><p>安装完系统后我还准备安装rEFind来替代默认的bootloader——GRUB(GRUB实在是太丑了…)。由于Windows10禁掉了启动其他系统的入口，因此之前只能用GRUB。rEFind是一个更加强大的启动器，并且可自定义的部分也多～rEFind是基于UEFI的启动器，相比GRUB能支持更多的功能，甚至可以在启动阶段就加载一些驱动，这就使得rEFind可以有高清的界面哈哈哈～关于UEFI与传统BIOS的区别可以参考<a href="https://wiki.manjaro.org/index.php?title=Some_basics_of_MBR_v/s_GPT_and_BIOS_v/s_UEFI">Manjaro论坛的这篇帖子</a>和<a href="https://www.zhihu.com/question/36313402/answer/66947818">知乎的这篇帖子</a>。UEFI和BIOS都是主板ROM程序启动后调用的bootloader类型，当bootloader通过UEFI或者BIOS过程加载之后就会启动系统内核。而UEFI相比BIOS可以支持更大的bootloader和并行启动，是现在大部分系统采用的启动方式～</p><p>rEFind在Ubuntu下安装非常方便～直接用<code>apt</code>安装即可。安装完重启就会发现默认进入的已经是rEFind界面了～不过默认的界面主题非常丑，也有很多多余的启动项，因此还需要稍微设置一下～设置教程网上有很多了，主题在官网和搜索引擎也都可以搜到，这里就不赘述。我的设置文件<a href="https://github.com/cmpute/dotfiles/blob/master/refind/user.conf">可以在Github找到</a>～我保留了GRUB的chainload入口，避免rEFind崩了进不去系统，然后另外添加了一个直接启动Linux内核的入口。最后界面效果如下，还是很赏心悦目的～</p><img src="/blog/2019-07/ConfigureKdeNeon/refind.jpg" class="" title="rEFInd界面照片"><p>安装完成以后就接着<a href="/blog/2018-09/LinuxDualSystem/" title="参考之前的文章">参考之前的文章</a>继续设置就可以了。其中最必要的两个操作是把系统时间调成<code>local-rtc</code>避免与Windows冲突，以及把Plasma环境中鼠标单击的行为从打开改为选择。。。</p><h2 id="输入法安装">输入法安装<a class="header-anchor" href="#输入法安装"> ❮</a></h2><p>Neon安装完后默认是没有输入法的，不过反正中文输入法都是要安装<a href="https://wiki.archlinux.org/index.php/fcitx">fcitx</a>的，还避免了使用ibus的冲突～fcitx的安装<a href="https://blog.ctang.me/the-first-story-on-medium-8a132a1b62fe">参考这篇文章</a>即可，其中<code>fcitx-qt-impanel</code>这个包可以让fcitx的状态显示在任务栏里～最近好像fcitx在开发新版本(<a href="https://a-wing.top/linux/2018/08/14/fcitx5.html">fcitx5</a>)，不过目前还只有Arch linux有包可以直接用，因此也就没折腾了。</p><p>安装完成之后还需要让fcitx框架跟随系统在后台启动，在Ubuntu底下修改的文件是<code>.xprofile</code>，而KDE桌面环境不会加载<code>.xprofile</code>，而是加载<code>.xsessionrc</code>，修改方式参见<a href="https://wiki.archlinux.org/index.php/fcitx#Set_environment_variables_for_IM_modules">Arch Wiki</a>，最后好像还需要加<code>fcitx &amp;</code>来确保启动= =</p><blockquote><ul><li>折腾这些玩意的过程中发现<a href="https://wiki.archlinux.org/index.php">Arch Wiki</a>真是个好东西啊～KDE桌面的大部分问题都可以搜到解答～</li><li><code>.xinitrc</code>, <code>.xprofile</code>，<code>.xsession</code>这些设置文件我真的是被搞蒙了。。<a href="https://www.reddit.com/r/linux/comments/1p6orz/bashrc_bash_profile_inputrc_profile_xprofile/">这里有一篇帖子</a>和<a href="https://unix.stackexchange.com/questions/281858/difference-between-xinitrc-xsession-and-xsessionrc/281923#281923">一篇回答</a>梳理了他们的关系，可供参考～</li></ul></blockquote><h2 id="rclone配置">rclone配置<a class="header-anchor" href="#rclone配置"> ❮</a></h2><p>另一个必装的好东西是rclone，之前在<a href="/blog/2019-04/LinuxRemoteSetup/" title="远程桌面设置的文章">远程桌面设置的文章</a>中有提到。由于KDE内置的GoogleDrive和OneDrive连接不太好使，还是用rclone来访问网盘吧= =。在设置好rclone之后可以通过自定义服务的方式让rclone在系统启动时自动挂载网盘到指定路径，然后在Dolphin（KDE的文件管理器）里面将这两个位置添加到左侧目录就可以啦～这样就可以直接从文件管理器访问了～具体的配置文件可以参考我的Github<TODO>。</p><blockquote><ul><li>如果自定义服务添加到的位置是系统服务位置，那么可能会碰到权限问题，<a href="https://forum.rclone.org/t/rclone-gdrive-not-mounting-permissions-or-fuse-issue/8067/2">这里有解决方法</a></li><li>关于systemd的服务设置可以<a href="https://wiki.archlinux.org/index.php/Systemd/User">参考Arch Wiki</a></li></ul></blockquote><h1 id="主题设置美化">主题设置美化<a class="header-anchor" href="#主题设置美化"> ❮</a></h1><h2 id="Plasma主题设置">Plasma主题设置<a class="header-anchor" href="#Plasma主题设置"> ❮</a></h2><p>KDE Plasma最大的优点就是流畅以及好看！不折腾一下主题真的是对不起这么好的环境了～我大概主要进行了以下修改</p><ul><li>风格选择<code>Breeze Dark</code>， 透明度设置为70%左右</li><li>图标使用<code>Papirus Dark</code></li><li>使用透明桌面主题<a href="https://store.kde.org/p/1170816/"><code>Breeze Transparent Dark</code></a></li><li>Firefox浏览器去掉titlebar，主题设为Dark</li><li>添加全局菜单添加到底部<blockquote><p>注意默认的Firefox去掉titlebar的话<a href="https://www.reddit.com/r/kde/comments/bn2klu/firefox_csd_bug_with_kde_global_menu_plasmoid/">对全局菜单的Plasmoid支持有问题</a></p></blockquote></li><li>fcitx主题选择Dark</li><li>在桌面特效中选择喜欢的窗口动画，调节窗口透明度～</li></ul><p>剩下的换壁纸、配色主题什么的都来一遍就可以了～最后的桌面效果见标题图，还是很顺眼的～</p><h2 id="其他小工具">其他小工具<a class="header-anchor" href="#其他小工具"> ❮</a></h2><h3 id="窗口附着缩放">窗口附着缩放<a class="header-anchor" href="#窗口附着缩放"> ❮</a></h3><p>这个KWin脚本名叫Sticky Window Snapping，真的是神器！可以让附着在一块的窗口同时进行尺寸调整！这个功能相当于Windows分屏功能的升级版，这酸爽谁用谁知道啊！～下载地址<a href="https://store.kde.org/p/1112552">见KDE商城</a>，使用效果在官网有动图可以参考～还<a href="https://store.kde.org/p/1112554/">有个类似的脚本</a>可以做到让窗口严格按照网格排列，不过相比之下就显然鸡肋很多了。</p><blockquote><p>这些功能的Windows替代品可以<a href="https://zhuanlan.zhihu.com/p/33722847">参见少数派的文章</a>，不过貌似没有免费的软件可以做到Tilting</p></blockquote><h3 id="Redshift（红移）">Redshift（红移）<a class="header-anchor" href="#Redshift（红移）"> ❮</a></h3><p>红移是Linux底下提供“护眼模式”的软件，有点类似f.lux，这个对我们这个天天盯电脑的还是很有用啦～安装直接<code>apt install redshift plasma-applet-redshift-control</code>即可，第二个软件是Redshift的Plasma插件，可以在任务栏通过它来调节红移，非常方便～安装完后应该就可以通过Plasma挂件来设置红移了，如果不能自动识别地理位置的话<a href="https://wiki.archlinux.org/index.php/Redshift#Automatic_location_based_on_GPS">参考Arch Wiki中描述的geoclue工具</a></p><blockquote><p>其他还有一些KDE下非常好用的软件，也一并列在这里了～以后用多了再专门开个文章～</p><ul><li>Kdenlive / Audacity：免费的视频/音频剪辑软件，基本够用了～</li><li>Meld：文件比较器</li><li>Remmina / KRDC：远程桌面的客户端，后者是KDE自家的，感觉比Remmina还是差点</li><li>VLC：视频播放器，可以部分替代PotPlayer</li><li>Peek / Kazam：录屏软件</li><li>Flameshot：截屏软件</li><li>Gimp：图片编辑软件，堪比Photoshop</li><li>Krfb / Xrdp：远程桌面的服务器</li><li>DeaDBeeF：音乐播放器，对cue和utf的支持非常好，可以部分替代fb2k</li><li>KDE Partition Manager：KDE版GParted，功能差不多而且界面美观～</li><li>fzf / ripgrep：模糊搜索工具</li><li>Golden Dict：强大的词典框架</li><li>KGet / aria2：下载器</li><li>youtube-dl：视频下载器（Python）</li><li><a href="http://wps-community.org/">WPS</a> / OnlyOffice：办公套装</li></ul></blockquote><!-- Reference Software List -->  <!-- https://alim0x.gitbooks.io/awesome-linux-software-zh_cn/content -->  <!-- KDE 全家桶 -->  <!-- Deepin 全家桶 -->  <!-- KDE snap全家桶 -->]]></content>
    
    
    <summary type="html">&lt;p&gt;最近我已经将KDE Neon作为主力系统之一了，Plasma桌面真的是太好用了！于是给家里的主机也装上了Neon，这篇文章就记录一下安装配置和美化的过程啦～&lt;/p&gt;
&lt;img src=&quot;/blog/2019-07/ConfigureKdeNeon/neon.png&quot; class=&quot;&quot; title=&quot;Plasma桌面折腾结果～&quot;&gt;
&lt;h1 id=&quot;系统安装及Boot设置&quot;&gt;系统安装及Boot设置&lt;a class=&quot;header-anchor&quot; href=&quot;#系统安装及Boot设置&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&quot;双系统安装&quot;&gt;双系统安装&lt;a class=&quot;header-anchor&quot; href=&quot;#双系统安装&quot;&gt; ❮&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;安装Neon还是非常简单的，直接从官网下载系统镜像，烧进U盘正常安装即可。不过由于我选择的是与Windows双系统安装，因此需要手动分区。这里要纠正一下之前&lt;a href=&quot;/blog/2018-09/LinuxDualSystem/&quot; title=&quot;安装双系统博文中的分区方式&quot;&gt;安装双系统博文中的分区方式&lt;/a&gt;。现在的Linux系统实际上只需要给根目录&lt;code&gt;/&lt;/code&gt;分区就可以了，&lt;code&gt;/home&lt;/code&gt;分区以前建议单独分区的原因是为了便于系统的更改，这样在修改系统分区之后（如重装系统）还能保留&lt;code&gt;/home&lt;/code&gt;底下的文件，但其实现在很多系统已经能做到重装并保留&lt;code&gt;/home&lt;/code&gt;分区了，这时对于我这小硬盘的笔记本来说反而导致空间利用不灵活。而交换分区&lt;code&gt;/swap&lt;/code&gt;也是没有必要的，交换分区的存在类似于Windows下的虚拟内存，用硬盘的一部分来虚拟内存，避免内存不足的情况。新Linux可以利用交换文件完成类似功能，因此不必专门给&lt;code&gt;/swap&lt;/code&gt;分区。（不过我猜专门给它分个区可能能提高性能？）。最后最关键的是不要给&lt;code&gt;/boot&lt;/code&gt;分区了,&lt;code&gt;/boot&lt;/code&gt;分区是为了保证boot文件区不被占满，以致无法正常启动。利用EFI方式启动的系统只需要有&lt;code&gt;efi&lt;/code&gt;分区即可，而且多个系统可以利用同一个EFI分区。因此只需告诉安装器使用EFI分区作为启动分区，关于EFI的详细信息请看后文~&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;分区的时候还看到了之前的系统里有标记为&lt;code&gt;msr&lt;/code&gt;的分区，是Windows的预留分区，好像具体没啥用。这里贴&lt;a href=&quot;http://bbs.wuyou.net/forum.php?mod=viewthread&amp;amp;tid=374959&quot;&gt;一篇考据文章&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="System" scheme="http://zyxin.xyz/blog/categories/System/"/>
    
    <category term="Linux" scheme="http://zyxin.xyz/blog/categories/System/Linux/"/>
    
    
    <category term="Linux" scheme="http://zyxin.xyz/blog/tags/Linux/"/>
    
    <category term="Ubuntu" scheme="http://zyxin.xyz/blog/tags/Ubuntu/"/>
    
    <category term="KDE" scheme="http://zyxin.xyz/blog/tags/KDE/"/>
    
  </entry>
  
  <entry>
    <title>终端（Terminal）美化与扩展</title>
    <link href="http://zyxin.xyz/blog/2019-07/BeautifyTerminal/"/>
    <id>http://zyxin.xyz/blog/2019-07/BeautifyTerminal/</id>
    <published>2019-07-13T15:36:15.000Z</published>
    <updated>2021-07-12T02:40:53.068Z</updated>
    
    <content type="html"><![CDATA[<p>最近由于工作需要，和终端命令行打交道的时间越来越多了，最近便查了一下美化命令行的方法，记录在此以供查阅～另外还推荐一个网站<a href="https://terminalsare.sexy/">terminalsare.sexy</a>，提供了很多与terminal美化相关的软件。</p><h1 id="命令提示符（Prompt）美化">命令提示符（Prompt）美化<a class="header-anchor" href="#命令提示符（Prompt）美化"> ❮</a></h1><p>相信不少朋友也见过如下图所示美化过的命令提示符<br><img src="https://raw.github.com/b-ryan/powerline-shell/master/bash-powerline-screenshot.png" alt="powerline-shell">这个效果的实现方式是通过安装名为<strong>Powerline</strong>的扩展程序。Powerline是一套可拓展的状态栏提示工具，可以给各种Terminal Emulator和Vim等工具增加状态栏的提示，并且十分好用～</p><p>Powerline有很多版本，有直接通过shell配置脚本实现的，也有通过独立程序进行显示的（如下列所示）。我选择的是原版powerline，安装方便，适用软件多，并且可以自行扩展。</p><ul><li><a href="https://github.com/powerline/powerline"><strong>powerline</strong></a>: 这应该是最初的也是最全的powerline，基于Python</li><li><a href="https://github.com/b-ryan/powerline-shell"><strong>powerline-shell</strong></a>: 这是针对美化shell的版本，同样基于Python，配置比上面的简单</li><li><a href="https://github.com/justjanne/powerline-go"><strong>powerline-go</strong></a>: 用go语言写的版本，运行更快</li><li><a href="https://github.com/riobard/bash-powerline"><strong>bash-powerline</strong></a>: 用bash编写的用于bash的powerline</li></ul><span id="more"></span><p>原版powerline的安装非常简单，用<code>pip</code>安装即可：<code>(sudo) pip install powerline-status</code>。安装完以后<a href="https://powerline.readthedocs.io/en/latest/usage.html#plugins">根据官网的教程</a>更改对应的配置文件即可～我只对bash进行了美化，因为bash是最常用的shell。使用bash的话建议<a href="https://powerline.readthedocs.io/en/latest/usage/shell-prompts.html#bash-prompt">按照教程里的指示</a>，在命令行配置文件中开启daemon来提高加载速度。另外一个小技巧是，由于Python2的启动速度比Python3快，因此推荐用Python2来安装powerline。</p><p>安装好powerline后下一步是自定义，这部分内容在powerline的文档里也有描述，不过它的文档写的不太好。。参考powerline安装目录下的配置文件（如果用系统pip安装的话位置是在<code>/usr/local/lib/python2.7/dist-packages/powerline/config_files</code>下），在用户配置目录下<code>~/.config/powerline</code>新建对应的配置文件，然后修改相应的条目即可自定义配置了～比较实用的一项修改是<a href="https://github.com/powerline/powerline/issues/186#issuecomment-247810572">将shell的默认theme改为<code>default_leftonly</code></a>，不增加这个改动的话不会有git状态的显示。。（并不知道是什么原理）</p><p>如果使用原生Ubuntu或者VSCode内置terminal的话还可能会遇到提示符乱码的原因，这是由于powerline使用了非常规的符号，因此需要安装额外的字体。一般会选择安装<a href="http://nerdfonts.com/">NerdFont</a>，这是一系列打上符号补丁的字体，其中我个人比较喜欢的字体是<code>DejaVu Mono Nerd</code>～这些字体还可以在<a href="https://app.programmingfonts.org/">programmingfonts</a>在线预览，挑选喜欢的后将Terminal默认字体更改即可。（注：ubuntu下的查看字体列表命令是<code>fc-list</code>）</p><h1 id="tmux安装及美化">tmux安装及美化<a class="header-anchor" href="#tmux安装及美化"> ❮</a></h1><p>tmux是非常著名的Terminal Multiplexer，也就是终端多开程序。很多命令行模拟器其实已经支持多标签页了，如gnome terminal和Konsole，多开的功能其实也已经得到满足了。（顺带一题，ubuntu下新开terminal窗口的默认快捷键是<kbd>Ctrl</kbd>+<kbd>Alt</kbd>+T，新开标签页的默认快捷键是<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+T。）。但还需要tmux是因为需要tmux的session管理功能，这个对远程访问的时候非常有用。有时希望在服务器远端跑一个训练，开上以后就不想管了，那这时如果使用ssh的话就得一直把远程的session开着，或者运行命令后移到后台，但这时停止程序就蛋疼了。另外如果想远程开几个terminal的话也很麻烦，要开好几个ssh的窗口。有了tmux就简单了，你可以用tmux多开然后一次性detach多个session，之后再attach回来进行管理，tmux支持多个程序显示在同一个terminal里，也就不用开很多个ssh了！总之用上tmux后感觉还是很爽的，只不过tmux有一定的学习成本。</p><p>tmux安装也很简单，ubuntu下的话直接使用<code>apt</code>安装即可。另外还可以安装<a href="https://github.com/tmuxinator/tmuxinator">tmuxinator</a>来简化tmux的一些流程。上面用到的powershell也是支持tmux的，可以美化tmux的状态栏。具体安装方法<a href="https://powerline.readthedocs.io/en/latest/usage/other.html#tmux-statusline">参见powerline文档</a>。另外tmux的操作方法可以去搜cheatsheet～这也有<a href="https://hackernoon.com/a-gentle-introduction-to-tmux-8d784c404340">一篇博文介绍了tmux的基本操作</a>，可以参考～</p><h1 id="历史记录搜索">历史记录搜索<a class="header-anchor" href="#历史记录搜索"> ❮</a></h1><p>著名的fish有个颇受称赞的功能是历史命令自动补全（见下图），在zsh里面也有对应的插件可以实现这个功能（<a href="https://github.com/zsh-users/zsh-autosuggestions">zsh-autosuggestions</a>）。但是bash由于比较辣鸡，无法支持这样的功能，因此只能另寻它法了。。<br><img src="https://spin.atomicobject.com/wp-content/uploads/20170512131543/fish-history.gif" alt="fish autosuggestion"></p><p>比较有名的方法是使用一个模糊搜索的软件<a href="https://github.com/junegunn/fzf"><strong>fzf</strong></a>。这个软件提供文件、程序和命令历史的搜索，有点类似于windows下的Listary。如果配置在shell中的话可以在按下快捷键后出现一个搜索框，搜索历史命令。这个虽然没有fish的自动补全好用，但是也非常方便了～安装fzf推荐通过<a href="https://github.com/junegunn/fzf#using-git">文档中的方法使用git安装</a>。安装过程中会提示你是否绑定终端快捷键，选择yes后在终端按下<kbd>Ctrl</kbd>+<kbd>R</kbd>就可以弹出搜索框了，非常方便～如果直接运行fzf命令的话就会进入完整的搜索界面，可以搜索文件，具体的使用方法还是参考官方文档了～</p><h1 id="Powershell美化">Powershell美化<a class="header-anchor" href="#Powershell美化"> ❮</a></h1><p>由于Powershell不是传统的sh体系，因此目前powerline还没有官方支持powershell。这里先mark几个博客，设置好了再更新上来～</p><blockquote><ul><li><a href="https://github.com/JanDeDobbeleer/oh-my-posh">https://github.com/JanDeDobbeleer/oh-my-posh</a></li><li><a href="https://blog.walterlv.com/post/beautify-powershell-like-zsh.html#%E5%AE%89%E8%A3%85-oh-my-posh">https://blog.walterlv.com/post/beautify-powershell-like-zsh.html#安装-oh-my-posh</a></li><li><a href="https://gist.github.com/jchandra74/5b0c94385175c7a8d1cb39bc5157365e">https://gist.github.com/jchandra74/5b0c94385175c7a8d1cb39bc5157365e</a></li><li><a href="https://dev.to/myleftshoe/comment/8b58">https://dev.to/myleftshoe/comment/8b58</a></li><li><a href="https://www.reddit.com/r/archlinux/comments/45lkyj/is_new_always_better_urxvt_vs_xterm_tmux_vs/">https://www.reddit.com/r/archlinux/comments/45lkyj/is_new_always_better_urxvt_vs_xterm_tmux_vs/</a></li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近由于工作需要，和终端命令行打交道的时间越来越多了，最近便查了一下美化命令行的方法，记录在此以供查阅～另外还推荐一个网站&lt;a href=&quot;https://terminalsare.sexy/&quot;&gt;terminalsare.sexy&lt;/a&gt;，提供了很多与terminal美化相关的软件。&lt;/p&gt;
&lt;h1 id=&quot;命令提示符（Prompt）美化&quot;&gt;命令提示符（Prompt）美化&lt;a class=&quot;header-anchor&quot; href=&quot;#命令提示符（Prompt）美化&quot;&gt; ❮&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;相信不少朋友也见过如下图所示美化过的命令提示符&lt;br&gt;
&lt;img src=&quot;https://raw.github.com/b-ryan/powerline-shell/master/bash-powerline-screenshot.png&quot; alt=&quot;powerline-shell&quot;&gt;这个效果的实现方式是通过安装名为&lt;strong&gt;Powerline&lt;/strong&gt;的扩展程序。Powerline是一套可拓展的状态栏提示工具，可以给各种Terminal Emulator和Vim等工具增加状态栏的提示，并且十分好用～&lt;/p&gt;
&lt;p&gt;Powerline有很多版本，有直接通过shell配置脚本实现的，也有通过独立程序进行显示的（如下列所示）。我选择的是原版powerline，安装方便，适用软件多，并且可以自行扩展。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/powerline/powerline&quot;&gt;&lt;strong&gt;powerline&lt;/strong&gt;&lt;/a&gt;: 这应该是最初的也是最全的powerline，基于Python&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/b-ryan/powerline-shell&quot;&gt;&lt;strong&gt;powerline-shell&lt;/strong&gt;&lt;/a&gt;: 这是针对美化shell的版本，同样基于Python，配置比上面的简单&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/justjanne/powerline-go&quot;&gt;&lt;strong&gt;powerline-go&lt;/strong&gt;&lt;/a&gt;: 用go语言写的版本，运行更快&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/riobard/bash-powerline&quot;&gt;&lt;strong&gt;bash-powerline&lt;/strong&gt;&lt;/a&gt;: 用bash编写的用于bash的powerline&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Trick" scheme="http://zyxin.xyz/blog/categories/Trick/"/>
    
    
    <category term="Linux" scheme="http://zyxin.xyz/blog/tags/Linux/"/>
    
    <category term="Shell" scheme="http://zyxin.xyz/blog/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>矩阵代数 — Matrix Algebra</title>
    <link href="http://zyxin.xyz/blog/2019-06/MatrixAlgebra/"/>
    <id>http://zyxin.xyz/blog/2019-06/MatrixAlgebra/</id>
    <published>2019-06-06T22:00:12.000Z</published>
    <updated>2021-07-12T02:40:53.188Z</updated>
    
    <content type="html"><![CDATA[<p>在学习线性系统以及SLAM的过程中碰到了很多矩阵的求导与积分运算，但是几乎没有系统地学习过这些知识。矩阵可以构成环，因此也有很多运算性质和推广。最近大佬发给我一本《Matrix Cookbook》，非常系统地列举了进阶矩阵运算的法则，这里贴在博客上以供参考～</p><h1 id="目录">目录<a class="header-anchor" href="#目录"> ❮</a></h1><ol><li>基础内容</li><li>求导</li><li>逆</li><li>复矩阵</li><li>求解与分解</li><li>统计与概率</li><li>多元概率分布</li><li>高斯</li><li>特殊矩阵</li><li>函数与运算符</li></ol><h1 id="来源">来源<a class="header-anchor" href="#来源"> ❮</a></h1><p>这本书可以<a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=3274">Technical University of Denmark资料网站下到</a>。如果链接失效了，<a href="/blog/uploads/misc/matrixcookbook.pdf">可以直接从此处下载</a>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在学习线性系统以及SLAM的过程中碰到了很多矩阵的求导与积分运算，但是几乎没有系统地学习过这些知识。矩阵可以构成环，因此也有很多运算性质和推广。最近大佬发给我一本《Matrix Cookbook》，非常系统地列举了进阶矩阵运算的法则，这里贴在博客上以供参考～&lt;/p&gt;
&lt;h1</summary>
      
    
    
    
    <category term="Notes" scheme="http://zyxin.xyz/blog/categories/Notes/"/>
    
    <category term="Math" scheme="http://zyxin.xyz/blog/categories/Notes/Math/"/>
    
    
    <category term="Math" scheme="http://zyxin.xyz/blog/tags/Math/"/>
    
    <category term="Matrix" scheme="http://zyxin.xyz/blog/tags/Matrix/"/>
    
  </entry>
  
  <entry>
    <title>转投Linux发行版</title>
    <link href="http://zyxin.xyz/blog/2019-04/LinuxDistroSelection/"/>
    <id>http://zyxin.xyz/blog/2019-04/LinuxDistroSelection/</id>
    <published>2019-04-26T19:22:02.000Z</published>
    <updated>2021-07-12T02:40:53.108Z</updated>
    
    <content type="html"><![CDATA[<p>由于最近工作一直在使用ROS，因此也一直在用Ubuntu。之前为了稳定性使用的是Ubuntu 16.04 LTS，而这个版本默认的桌面环境是Unity，实在是不好使，它也颇为人诟病。后来尝试了Ubuntu 18.04 LTS安装ROS Melodic，发现ROS也挺稳定的，因此18.04也用了一段时间，但是最后还是觉得不太爽，于是最终还是决定好好体验一下各种Linux选一个自己顺手的。</p><blockquote><p>这篇博客里不会贴系统的截图，因为这些在网上都可以找到，而且桌面的好看与否很大程度上取决于个人的喜好和配置结果。最好的比较方法还是自己装一个系统尝试一下</p></blockquote><p>至于如何尝试linux，我在Windows中使用的是Hyper-V。可以非常方便地安装各种镜像，动态分配资源，最方便的是vhdx硬盘格式可以直接mount到宿主机里。Hyper-V使用一些性能较差的Linux桌面环境时会比较卡，这个时候可以<a href="https://docs.microsoft.com/en-us/windows-server/remote/remote-desktop-services/rds-remotefx-vgpu">开启RemoteFX GPU（参考官方说明）</a>。注意在Win10 1809之后，Hyper-V管理器界面不提供RemoteFX的开关了，需要用Powershell命令手动开启。</p><span id="more"></span><h1 id="Linux-Distro">Linux Distro<a class="header-anchor" href="#Linux-Distro"> ❮</a></h1><p>所谓的Linux发行版，对应的是一个专有的英文单词distro。个人理解，Linux Distro就是一套Linux Kernel加上外围一些必要的软件包。之前我一直不理解发行版的意思，直到学会了Python使用上Anaconda之后，才知道发行版指的就是核心程序+预装的全家桶，这个全家桶通常包含包管理器（Package manager，简称PM。如Ubuntu的apt、Anaconda的conda）、内置软件（如Linux桌面环境、Anaconda预装的Scipy）以及一套系统逻辑。</p><p>Linux发行版中很重要的一点便是系统的PM，这个管理器还决定了系统的更新逻辑。而不同发行版之间最大的区别，在我看来就是PM（以及软件仓库repository），因此PM的特性与相性最终会决定我是否选择这套发行版。</p><p>常见的桌面Linux发行版有如下这些，我可以大概描述一下他们的特点（以PM为线索）：</p><ul><li><strong>apt</strong>: Debian、Ubuntu系<ul><li>依赖树严格，能保证软件之间正确的依赖关系</li><li>Debian和Ubuntu的软件库数量庞大，但是确实由于保守的包更新政策，它们的包比较老</li><li>apt的命令行使用非常直观</li><li>在国内，默认的仓库源下载很慢，但是国内有很多开源镜像可以使用</li></ul></li><li><strong>pacman</strong>: Arch<ul><li>滚动更新是Arch最大的特点</li><li>pacman没有严格的依赖树，而是类似于快照的概念，更新软件时整个软件池都会进行变动（个人理解）</li><li>pacman命令行参数是字母表，不便于记忆</li><li>Arch的官方软件仓库中软件较少，但是Arch有庞大的AUR体系，因此能够尝试到很多小软件和新版本，不过也要承担小白鼠的风险</li></ul></li><li><strong>yum/dnf</strong>: Fedora、CentOS、Redhat等<ul><li>使用方法和apt相似</li><li>软件仓库中的数量没有Debian和Arch多</li><li>包管理方便，中规中据，而且下载速度不慢</li></ul></li><li><strong>zypper</strong>: OpenSUSE<ul><li>由于OpenSUSE是真的比较小众，因此我也没有去尝试，就不妄自评论了</li></ul></li><li><strong>emerge</strong>: Gentoo<ul><li>同上，没尝试过<br>严格来说，上面的这些都是包分发器，而安装软件的是包安装器（dpkg,rpm等），不过前者才是我们最经常打交道的。关于这些PM以及其软件管理哲学的分析，可以<a href="https://www.zhihu.com/question/40297380">参见这个知乎问题</a>。而关于这些包管理器的一篇介绍可以<a href="https://linux.cn/article-9931-1.html">参见这篇博文</a>。</li></ul></li></ul><blockquote><p>Arch Linux的wiki上也有一篇<a href="https://wiki.archlinux.org/index.php/Arch_compared_to_other_distributions">关于发行版之间的对比</a>，这里我要吹一下Arch的wiki真的良心，还有中文版！<br><a href="https://distrowatch.com/">DistroWatch</a>是一个收集了大量Linux distro的网站，可以在上面看一下流行度排名和一些评测<br>Linux各发行版的演化历史可以参见<a href="https://commons.wikimedia.org/wiki/File:Linux_Distribution_Timeline.svg">Wiki的历史图</a>或者<a href="https://distrowatch.com/dwres.php?resource=family-tree">DistroWatch的图表</a></p></blockquote><h1 id="桌面环境">桌面环境<a class="header-anchor" href="#桌面环境"> ❮</a></h1><p>桌面环境是最终选择哪一个发行版的决定者。选择Ubuntu、Arch等只能给你决定好大方向，而最后在众多系统中作出选择的标准之一便是桌面环境。常见的桌面环境有Gnome、KDE Plasma、XFCE、LXQt等。现在众多的发行版的主要区别其实也就是PM和桌面环境的区别：</p><ul><li>Ubuntu 16.04: Ubuntu + Unity</li><li>Ubuntu 18.04: Ubuntu + Gnome</li><li>KUbuntu: Ubuntu + KDE</li><li>XUbuntu: Ubuntu + XFCE</li><li>MX Linux: Debian + XFCE</li><li>Linux Mint: Ubuntu + Cinammon/Gnome</li><li>Manjaro: Arch + KDE</li><li>Deepin: Debian + Deepin</li><li>…</li></ul><p>而这些桌面环境的特点，个人感觉如下：</p><ul><li>Gnome(w/ gdm): 基于GTK开发，默认界面比较好看，但是灵活程度不够。虽然有Gnome Tweak，但是插件很少</li><li>KDE Plasma(w/ sddm): 基于QT开发，非常灵活，而且Plasma5默认就非常好看！占用资源也比Gnome小。</li><li>Unity(w/ lightdm): 别说了，换吧</li><li>Xfce: 听人说很不错，但是我认为比较丑</li><li>LXQt(w/ sddm): 适合低配环境，也不太好看</li></ul><h1 id="个人选择">个人选择<a class="header-anchor" href="#个人选择"> ❮</a></h1><p><strong>Arch？</strong>: 在我了解Linux distro的过程中，在各种论坛、知乎问题上都有人安利Arch linux。Arch虽好，而且可以体验更新的快感，但是我本身没有太多的时间去折腾系统，或者追寻潮流，因此还是更倾向于Debian体系。同时由于我有使用ROS的需求，因此Ubuntu还是我的第一选择。</p><p><strong>商业主导 or 社区主导</strong>: 有人说Ubuntu由于是Canonical家的产品，会有商业倾向，服从公司利益。这个情况确实存在，但是就体验上来说和Arch、Fedora等等社区主导的系统并没有太多区别，因此这个并不会是决定我选择的因素。</p><p><strong>Gnome or KDE</strong>: 相比于GTK，我更喜欢Qt这套框架。另外KDE也有别人上传的很多插件和桌面（在KDE store上)，非常棒，因此我最后选择的是KDE～</p><p>综上所述，我最后决定使用KDE Neon作为平常使用的发行版，双系统安装Ubuntu 18.04作为开发系统。之后会写一篇博客来介绍KDE的折腾记录～</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;由于最近工作一直在使用ROS，因此也一直在用Ubuntu。之前为了稳定性使用的是Ubuntu 16.04 LTS，而这个版本默认的桌面环境是Unity，实在是不好使，它也颇为人诟病。后来尝试了Ubuntu 18.04 LTS安装ROS Melodic，发现ROS也挺稳定的，因此18.04也用了一段时间，但是最后还是觉得不太爽，于是最终还是决定好好体验一下各种Linux选一个自己顺手的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这篇博客里不会贴系统的截图，因为这些在网上都可以找到，而且桌面的好看与否很大程度上取决于个人的喜好和配置结果。最好的比较方法还是自己装一个系统尝试一下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;至于如何尝试linux，我在Windows中使用的是Hyper-V。可以非常方便地安装各种镜像，动态分配资源，最方便的是vhdx硬盘格式可以直接mount到宿主机里。Hyper-V使用一些性能较差的Linux桌面环境时会比较卡，这个时候可以&lt;a href=&quot;https://docs.microsoft.com/en-us/windows-server/remote/remote-desktop-services/rds-remotefx-vgpu&quot;&gt;开启RemoteFX GPU（参考官方说明）&lt;/a&gt;。注意在Win10 1809之后，Hyper-V管理器界面不提供RemoteFX的开关了，需要用Powershell命令手动开启。&lt;/p&gt;</summary>
    
    
    
    <category term="System" scheme="http://zyxin.xyz/blog/categories/System/"/>
    
    <category term="Linux" scheme="http://zyxin.xyz/blog/categories/System/Linux/"/>
    
    
    <category term="Linux" scheme="http://zyxin.xyz/blog/tags/Linux/"/>
    
    <category term="Ubuntu" scheme="http://zyxin.xyz/blog/tags/Ubuntu/"/>
    
    <category term="KDE" scheme="http://zyxin.xyz/blog/tags/KDE/"/>
    
  </entry>
  
</feed>
